{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer-decoder with no Seq2Seq component (autoregressive)\n",
    "\n",
    "# no value embedding\n",
    "# sine-cosine positional encoding on the hour, day, and month of timestamp\n",
    "# modified transformer-encoder layer for masked self-attention\n",
    "\n",
    "# conduct an architecture test similar to the one on the transformer-encoder in\n",
    "# deep_transformer_model_for_tsf_XX.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required for TFA MultiHeadAttention\n",
    "import typing\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MHA class from TensorFlow AddOns source\n",
    "# it is compatible with TF 1.15 for CloudTPU usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    r\"\"\"MultiHead Attention layer.\n",
    "    Defines the MultiHead Attention operation as described in\n",
    "    [Attention Is All You Need](https://arxiv.org/abs/1706.03762) which takes\n",
    "    in the tensors `query`, `key`, and `value`, and returns the dot-product attention\n",
    "    between them:\n",
    "    >>> mha = MultiHeadAttention(head_size=128, num_heads=12)\n",
    "    >>> query = np.random.rand(3, 5, 4) # (batch_size, query_elements, query_depth)\n",
    "    >>> key = np.random.rand(3, 6, 5) # (batch_size, key_elements, key_depth)\n",
    "    >>> value = np.random.rand(3, 6, 6) # (batch_size, key_elements, value_depth)\n",
    "    >>> attention = mha([query, key, value]) # (batch_size, query_elements, value_depth)\n",
    "    >>> attention.shape\n",
    "    TensorShape([3, 5, 6])\n",
    "    If `value` is not given then internally `value = key` will be used:\n",
    "    >>> mha = MultiHeadAttention(head_size=128, num_heads=12)\n",
    "    >>> query = np.random.rand(3, 5, 5) # (batch_size, query_elements, query_depth)\n",
    "    >>> key = np.random.rand(3, 6, 10) # (batch_size, key_elements, key_depth)\n",
    "    >>> attention = mha([query, key]) # (batch_size, query_elements, key_depth)\n",
    "    >>> attention.shape\n",
    "    TensorShape([3, 5, 10])\n",
    "    Args:\n",
    "        head_size: int, dimensionality of the `query`, `key` and `value` tensors\n",
    "            after the linear transformation.\n",
    "        num_heads: int, number of attention heads.\n",
    "        output_size: int, dimensionality of the output space, if `None` then the\n",
    "            input dimension of `value` or `key` will be used,\n",
    "            default `None`.\n",
    "        dropout: float, `rate` parameter for the dropout layer that is\n",
    "            applied to attention after softmax,\n",
    "        default `0`.\n",
    "        use_projection_bias: bool, whether to use a bias term after the linear\n",
    "            output projection.\n",
    "        return_attn_coef: bool, if `True`, return the attention coefficients as\n",
    "            an additional output argument.\n",
    "        kernel_initializer: initializer, initializer for the kernel weights.\n",
    "        kernel_regularizer: regularizer, regularizer for the kernel weights.\n",
    "        kernel_constraint: constraint, constraint for the kernel weights.\n",
    "        bias_initializer: initializer, initializer for the bias weights.\n",
    "        bias_regularizer: regularizer, regularizer for the bias weights.\n",
    "        bias_constraint: constraint, constraint for the bias weights.\n",
    "    Call Args:\n",
    "        inputs:  List of `[query, key, value]` where\n",
    "            * `query`: Tensor of shape `(..., query_elements, query_depth)`\n",
    "            * `key`: `Tensor of shape '(..., key_elements, key_depth)`\n",
    "            * `value`: Tensor of shape `(..., key_elements, value_depth)`, optional, if not given `key` will be used.\n",
    "        mask: a binary Tensor of shape `[batch_size?, num_heads?, query_elements, key_elements]`\n",
    "        which specifies which query elements can attend to which key elements,\n",
    "        `1` indicates attention and `0` indicates no attention.\n",
    "    Output shape:\n",
    "        * `(..., query_elements, output_size)` if `output_size` is given, else\n",
    "        * `(..., query_elements, value_depth)` if `value` is given, else\n",
    "        * `(..., query_elements, key_depth)`\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        head_size: int,\n",
    "        num_heads: int,\n",
    "        output_size: int = None,\n",
    "        dropout: float = 0.0,\n",
    "        use_projection_bias: bool = True,\n",
    "        return_attn_coef: bool = False,\n",
    "        kernel_initializer: typing.Union[str, typing.Callable] = \"glorot_uniform\",\n",
    "        kernel_regularizer: typing.Union[str, typing.Callable] = None,\n",
    "        kernel_constraint: typing.Union[str, typing.Callable] = None,\n",
    "        bias_initializer: typing.Union[str, typing.Callable] = \"zeros\",\n",
    "        bias_regularizer: typing.Union[str, typing.Callable] = None,\n",
    "        bias_constraint: typing.Union[str, typing.Callable] = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        warnings.warn(\n",
    "            \"`MultiHeadAttention` will be deprecated in Addons 0.13. \"\n",
    "            \"Please use `tf.keras.layers.MultiHeadAttention` instead.\",\n",
    "            DeprecationWarning,\n",
    "        )\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        if output_size is not None and output_size < 1:\n",
    "            raise ValueError(\"output_size must be a positive number\")\n",
    "\n",
    "        self.head_size = head_size\n",
    "        self.num_heads = num_heads\n",
    "        self.output_size = output_size\n",
    "        self.use_projection_bias = use_projection_bias\n",
    "        self.return_attn_coef = return_attn_coef\n",
    "\n",
    "        self.kernel_initializer = tf.keras.initializers.get(kernel_initializer)\n",
    "        self.kernel_regularizer = tf.keras.regularizers.get(kernel_regularizer)\n",
    "        self.kernel_constraint = tf.keras.constraints.get(kernel_constraint)\n",
    "        self.bias_initializer = tf.keras.initializers.get(bias_initializer)\n",
    "        self.bias_regularizer = tf.keras.regularizers.get(bias_regularizer)\n",
    "        self.bias_constraint = tf.keras.constraints.get(bias_constraint)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "        self._dropout_rate = dropout\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        num_query_features = input_shape[0][-1]\n",
    "        num_key_features = input_shape[1][-1]\n",
    "        num_value_features = (\n",
    "            input_shape[2][-1] if len(input_shape) > 2 else num_key_features\n",
    "        )\n",
    "        output_size = (\n",
    "            self.output_size if self.output_size is not None else num_value_features\n",
    "        )\n",
    "\n",
    "        self.query_kernel = self.add_weight(\n",
    "            name=\"query_kernel\",\n",
    "            shape=[self.num_heads, num_query_features, self.head_size],\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            constraint=self.kernel_constraint,\n",
    "        )\n",
    "        self.key_kernel = self.add_weight(\n",
    "            name=\"key_kernel\",\n",
    "            shape=[self.num_heads, num_key_features, self.head_size],\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            constraint=self.kernel_constraint,\n",
    "        )\n",
    "        self.value_kernel = self.add_weight(\n",
    "            name=\"value_kernel\",\n",
    "            shape=[self.num_heads, num_value_features, self.head_size],\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            constraint=self.kernel_constraint,\n",
    "        )\n",
    "        self.projection_kernel = self.add_weight(\n",
    "            name=\"projection_kernel\",\n",
    "            shape=[self.num_heads, self.head_size, output_size],\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            constraint=self.kernel_constraint,\n",
    "        )\n",
    "\n",
    "        if self.use_projection_bias:\n",
    "            self.projection_bias = self.add_weight(\n",
    "                name=\"projection_bias\",\n",
    "                shape=[output_size],\n",
    "                initializer=self.bias_initializer,\n",
    "                regularizer=self.bias_regularizer,\n",
    "                constraint=self.bias_constraint,\n",
    "            )\n",
    "        else:\n",
    "            self.projection_bias = None\n",
    "\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "\n",
    "        # einsum nomenclature\n",
    "        # ------------------------\n",
    "        # N = query elements\n",
    "        # M = key/value elements\n",
    "        # H = heads\n",
    "        # I = input features\n",
    "        # O = output features\n",
    "\n",
    "        query = inputs[0]\n",
    "        key = inputs[1]\n",
    "        value = inputs[2] if len(inputs) > 2 else key\n",
    "\n",
    "        # verify shapes\n",
    "        if key.shape[-2] != value.shape[-2]:\n",
    "            raise ValueError(\n",
    "                \"the number of elements in 'key' must be equal to the same as the number of elements in 'value'\"\n",
    "            )\n",
    "\n",
    "        if mask is not None:\n",
    "            if len(mask.shape) < 2:\n",
    "                raise ValueError(\"'mask' must have atleast 2 dimensions\")\n",
    "            if query.shape[-2] != mask.shape[-2]:\n",
    "                raise ValueError(\n",
    "                    \"mask's second to last dimension must be equal to the number of elements in 'query'\"\n",
    "                )\n",
    "            if key.shape[-2] != mask.shape[-1]:\n",
    "                raise ValueError(\n",
    "                    \"mask's last dimension must be equal to the number of elements in 'key'\"\n",
    "                )\n",
    "\n",
    "        # Linear transformations\n",
    "        query = tf.einsum(\"...NI , HIO -> ...NHO\", query, self.query_kernel)\n",
    "        key = tf.einsum(\"...MI , HIO -> ...MHO\", key, self.key_kernel)\n",
    "        value = tf.einsum(\"...MI , HIO -> ...MHO\", value, self.value_kernel)\n",
    "\n",
    "        # Scale dot-product, doing the division to either query or key\n",
    "        # instead of their product saves some computation\n",
    "        depth = tf.constant(self.head_size, dtype=query.dtype)\n",
    "        query /= tf.sqrt(depth)\n",
    "\n",
    "        # Calculate dot product attention\n",
    "        logits = tf.einsum(\"...NHO,...MHO->...HNM\", query, key)\n",
    "\n",
    "        # apply mask\n",
    "        if mask is not None:\n",
    "            mask = tf.cast(mask, tf.float32)\n",
    "\n",
    "            # possibly expand on the head dimension so broadcasting works\n",
    "            if len(mask.shape) != len(logits.shape):\n",
    "                mask = tf.expand_dims(mask, -3)\n",
    "\n",
    "            logits += -10e9 * (1.0 - mask)\n",
    "\n",
    "        attn_coef = tf.nn.softmax(logits)\n",
    "\n",
    "        # attention dropout\n",
    "        attn_coef_dropout = self.dropout(attn_coef, training=training)\n",
    "\n",
    "        # attention * value\n",
    "        multihead_output = tf.einsum(\"...HNM,...MHI->...NHI\", attn_coef_dropout, value)\n",
    "\n",
    "        # Run the outputs through another linear projection layer. Recombining heads\n",
    "        # is automatically done.\n",
    "        output = tf.einsum(\n",
    "            \"...NHI,HIO->...NO\", multihead_output, self.projection_kernel\n",
    "        )\n",
    "\n",
    "        if self.projection_bias is not None:\n",
    "            output += self.projection_bias\n",
    "\n",
    "        if self.return_attn_coef:\n",
    "            return output, attn_coef\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        num_value_features = (\n",
    "            input_shape[2][-1] if len(input_shape) > 2 else input_shape[1][-1]\n",
    "        )\n",
    "        output_size = (\n",
    "            self.output_size if self.output_size is not None else num_value_features\n",
    "        )\n",
    "\n",
    "        output_shape = input_shape[0][:-1] + (output_size,)\n",
    "\n",
    "        if self.return_attn_coef:\n",
    "            num_query_elements = input_shape[0][-2]\n",
    "            num_key_elements = input_shape[1][-2]\n",
    "            attn_coef_shape = input_shape[0][:-2] + (\n",
    "                self.num_heads,\n",
    "                num_query_elements,\n",
    "                num_key_elements,\n",
    "            )\n",
    "\n",
    "            return output_shape, attn_coef_shape\n",
    "        else:\n",
    "            return output_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "\n",
    "        config.update(\n",
    "            head_size=self.head_size,\n",
    "            num_heads=self.num_heads,\n",
    "            output_size=self.output_size,\n",
    "            dropout=self._dropout_rate,\n",
    "            use_projection_bias=self.use_projection_bias,\n",
    "            return_attn_coef=self.return_attn_coef,\n",
    "            kernel_initializer=tf.keras.initializers.serialize(self.kernel_initializer),\n",
    "            kernel_regularizer=tf.keras.regularizers.serialize(self.kernel_regularizer),\n",
    "            kernel_constraint=tf.keras.constraints.serialize(self.kernel_constraint),\n",
    "            bias_initializer=tf.keras.initializers.serialize(self.bias_initializer),\n",
    "            bias_regularizer=tf.keras.regularizers.serialize(self.bias_regularizer),\n",
    "            bias_constraint=tf.keras.constraints.serialize(self.bias_constraint),\n",
    "        )\n",
    "\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the autoregressive version of the transformer-decoder does not use the Seq2Seq intermediate layer\n",
    "# as there is no transformer-encoder component sending hidden states, therefore\n",
    "# having only a self-attention layer and a position-wise feed-forward layer,\n",
    "# the autoregressive transformer-decoder is, in fact, a transformer-encoder\n",
    "\n",
    "# the only important modification is the masked self-attention layer\n",
    "\n",
    "# masked self-attention layer seems to be already implemented in\n",
    "# MHA module from TensorFlow AddOns, then will be added to the EncoderLayer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base transformer encoder layer from # https://keras.io/examples/nlp/text_classification_with_transformer/\n",
    "# modified to include masked self attention\n",
    "\n",
    "# ToDo: get the number of timesteps from the input shape\n",
    "# in the meantime, pass this value as an argument for the encoder layer\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, n_timesteps, embed_dim, num_heads, ff_dim, dropout=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        # multi-head attention initialization\n",
    "        self.attention_layer = MultiHeadAttention(head_size=embed_dim, num_heads=num_heads)\n",
    "        self.ff_layer = tf.keras.Sequential(\n",
    "            [tf.keras.layers.Dense(ff_dim, activation=\"relu\"),\n",
    "             tf.keras.layers.Dense(embed_dim)]\n",
    "        )\n",
    "        self.add_norm_layer_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.add_norm_layer_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout_1 = tf.keras.layers.Dropout(dropout)\n",
    "        self.dropout_2 = tf.keras.layers.Dropout(dropout)\n",
    "        # mask for self-attention\n",
    "        self.mask = tf.convert_to_tensor(np.tril(np.ones([n_timesteps, n_timesteps]), 0), dtype=tf.float32)\n",
    "\n",
    "        \n",
    "    def call(self, inputs, training):\n",
    "        # mask for self-attention is passed to MHA on call\n",
    "        attention_output = self.attention_layer([inputs, inputs], mask=self.mask)\n",
    "        attention_output = self.dropout_1(attention_output, training=training)\n",
    "        input_to_ffn = self.add_norm_layer_1(inputs + attention_output)\n",
    "        ffn_output = self.ff_layer(input_to_ffn)\n",
    "        ffn_output = self.dropout_2(ffn_output, training=training)\n",
    "        return self.add_norm_layer_2(input_to_ffn + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.read_pickle(\"/home/developer/gcp/cbidmltsf/timeseries/CPE04115_H_kw_20201021084001/ts.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kw_scaled</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01 00:00:00</th>\n",
       "      <td>0.274317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 01:00:00</th>\n",
       "      <td>0.217363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 02:00:00</th>\n",
       "      <td>0.168545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 03:00:00</th>\n",
       "      <td>0.122996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 04:00:00</th>\n",
       "      <td>0.080440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     kw_scaled\n",
       "timestamp                     \n",
       "2016-01-01 00:00:00   0.274317\n",
       "2016-01-01 01:00:00   0.217363\n",
       "2016-01-01 02:00:00   0.168545\n",
       "2016-01-01 03:00:00   0.122996\n",
       "2016-01-01 04:00:00   0.080440"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22629"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# length of time series\n",
    "total_lectures = ts['kw_scaled'].count()\n",
    "total_lectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a training dataset\n",
    "# features: m consecutive lectures with their timestamps\n",
    "# target: m consecutive lectures (lectures in features, shifted by 1 to the future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the embedding dimension, the lenght of tranining, evaluation, and test datasets\n",
    "# use the most of the 22K+ lectures in the original time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of input sequence, hours in a week\n",
    "m = 168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare sine-cosine positional encoding for the input sequence\n",
    "hours_in_day = 24\n",
    "days_in_month = 30\n",
    "months_in_year = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15840.3,  4525.8,  2262.9])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_lectures*np.array([0.7, 0.2, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the previous dataset split, use the following indexes for building datasets\n",
    "\n",
    "# 15000 rows in training dataset\n",
    "train_start = 0\n",
    "train_end = 15000\n",
    "\n",
    "# 4000 rows in evaluation dataset\n",
    "eval_start = 16000\n",
    "eval_end = 20000\n",
    "\n",
    "# 1000 rows in test dataset\n",
    "test_start = 21000\n",
    "test_end = 22000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a collection of examples for training\n",
    "# use a range on the time series index\n",
    "\n",
    "train_range = np.arange(train_start, train_end)\n",
    "\n",
    "features_list = list()\n",
    "targets_list = list()\n",
    "\n",
    "for start in train_range:\n",
    "    end = start + m\n",
    "    values = np.expand_dims(ts[start:end]['kw_scaled'].values, axis=1)\n",
    "    target_values = np.expand_dims(ts[1+start:1+end]['kw_scaled'].values, axis=1)\n",
    "    \n",
    "    timestamps_hour = ts[start:end].index.hour\n",
    "    timestamps_day = ts[start:end].index.day\n",
    "    timestamps_month = ts[start:end].index.month\n",
    "    \n",
    "    sin_hour = np.expand_dims(np.sin(2*np.pi*timestamps_hour/hours_in_day), axis=1)\n",
    "    cos_hour = np.expand_dims(np.sin(2*np.pi*timestamps_hour/hours_in_day), axis=1)\n",
    "    sin_day = np.expand_dims(np.sin(2*np.pi*timestamps_day/days_in_month), axis=1)\n",
    "    cos_day = np.expand_dims(np.cos(2*np.pi*timestamps_day/days_in_month), axis=1)\n",
    "    sin_month = np.expand_dims(np.sin(2*np.pi*timestamps_month/months_in_year), axis=1)\n",
    "    cos_month = np.expand_dims(np.cos(2*np.pi*timestamps_month/months_in_year), axis=1)\n",
    "    \n",
    "    feature_row = np.concatenate((values, sin_hour, cos_hour, sin_day, cos_day, sin_month, cos_month), axis=1)    \n",
    "\n",
    "    features_list.append(feature_row)\n",
    "    targets_list.append(target_values)\n",
    "\n",
    "x_train = np.array(features_list)\n",
    "y_train = np.array(targets_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the training NumPy arrays\n",
    "with open('data/x_train.npy', 'wb') as filename:\n",
    "    np.save(filename, x_train)\n",
    "\n",
    "with open('data/y_train.npy', 'wb') as filename:\n",
    "    np.save(filename, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training NumPy arrays\n",
    "with open('data/x_train.npy', 'rb') as filename:\n",
    "    x_train = np.load(filename)\n",
    "\n",
    "with open('data/y_train.npy', 'rb') as filename:\n",
    "    y_train = np.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15000, 168, 7), (15000, 168, 1))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a collection of examples for evaluation\n",
    "# use a range on the time series index\n",
    "eval_range = np.arange(eval_start, eval_end)\n",
    "\n",
    "features_list = list()\n",
    "targets_list = list()\n",
    "\n",
    "for start in eval_range:\n",
    "    end = start + m\n",
    "    values = np.expand_dims(ts[start:end]['kw_scaled'].values, axis=1)\n",
    "    target_values = np.expand_dims(ts[1+start:1+end]['kw_scaled'].values, axis=1)\n",
    "    \n",
    "    timestamps_hour = ts[start:end].index.hour\n",
    "    timestamps_day = ts[start:end].index.day\n",
    "    timestamps_month = ts[start:end].index.month\n",
    "    \n",
    "    sin_hour = np.expand_dims(np.sin(2*np.pi*timestamps_hour/hours_in_day), axis=1)\n",
    "    cos_hour = np.expand_dims(np.sin(2*np.pi*timestamps_hour/hours_in_day), axis=1)\n",
    "    sin_day = np.expand_dims(np.sin(2*np.pi*timestamps_day/days_in_month), axis=1)\n",
    "    cos_day = np.expand_dims(np.cos(2*np.pi*timestamps_day/days_in_month), axis=1)\n",
    "    sin_month = np.expand_dims(np.sin(2*np.pi*timestamps_month/months_in_year), axis=1)\n",
    "    cos_month = np.expand_dims(np.cos(2*np.pi*timestamps_month/months_in_year), axis=1)\n",
    "    \n",
    "    feature_row = np.concatenate((values, sin_hour, cos_hour, sin_day, cos_day, sin_month, cos_month), axis=1)    \n",
    "\n",
    "    features_list.append(feature_row)\n",
    "    targets_list.append(target_values)\n",
    "\n",
    "x_eval = np.array(features_list)\n",
    "y_eval = np.array(targets_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the evaluation NumPy arrays\n",
    "with open('data/x_eval.npy', 'wb') as filename:\n",
    "    np.save(filename, x_eval)\n",
    "\n",
    "with open('data/y_eval.npy', 'wb') as filename:\n",
    "    np.save(filename, y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the evaluation NumPy arrays\n",
    "with open('data/x_eval.npy', 'rb') as filename:\n",
    "    x_eval = np.load(filename)\n",
    "\n",
    "with open('data/y_eval.npy', 'rb') as filename:\n",
    "    y_eval = np.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4000, 168, 7), (4000, 168, 1))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_eval.shape, y_eval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a collection of examples for test\n",
    "# use a range on the time series index\n",
    "test_range = np.arange(test_start, test_end)\n",
    "\n",
    "features_list = list()\n",
    "targets_list = list()\n",
    "\n",
    "for start in test_range:\n",
    "    end = start + m\n",
    "    values = np.expand_dims(ts[start:end]['kw_scaled'].values, axis=1)\n",
    "    target_values = np.expand_dims(ts[1+start:1+end]['kw_scaled'].values, axis=1)\n",
    "    \n",
    "    timestamps_hour = ts[start:end].index.hour\n",
    "    timestamps_day = ts[start:end].index.day\n",
    "    timestamps_month = ts[start:end].index.month\n",
    "    \n",
    "    sin_hour = np.expand_dims(np.sin(2*np.pi*timestamps_hour/hours_in_day), axis=1)\n",
    "    cos_hour = np.expand_dims(np.sin(2*np.pi*timestamps_hour/hours_in_day), axis=1)\n",
    "    sin_day = np.expand_dims(np.sin(2*np.pi*timestamps_day/days_in_month), axis=1)\n",
    "    cos_day = np.expand_dims(np.cos(2*np.pi*timestamps_day/days_in_month), axis=1)\n",
    "    sin_month = np.expand_dims(np.sin(2*np.pi*timestamps_month/months_in_year), axis=1)\n",
    "    cos_month = np.expand_dims(np.cos(2*np.pi*timestamps_month/months_in_year), axis=1)\n",
    "    \n",
    "    feature_row = np.concatenate((values, sin_hour, cos_hour, sin_day, cos_day, sin_month, cos_month), axis=1)    \n",
    "\n",
    "    features_list.append(feature_row)\n",
    "    targets_list.append(target_values)\n",
    "\n",
    "x_test = np.array(features_list)\n",
    "y_test = np.array(targets_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the test NumPy arrays\n",
    "with open('data/x_test.npy', 'wb') as filename:\n",
    "    np.save(filename, x_test)\n",
    "    \n",
    "with open('data/y_test.npy', 'wb') as filename:\n",
    "    np.save(filename, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the test NumPy arrays\n",
    "with open('data/x_test.npy', 'rb') as filename:\n",
    "    x_test = np.load(filename)\n",
    "\n",
    "with open('data/y_test.npy', 'rb') as filename:\n",
    "    y_test = np.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 168, 7), (1000, 168, 1))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# architecture details according to the Klingenbrunn experiment\n",
    "# (including notes to further modifications on the basic autoregressive model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of timesteps is the length of the input sequence,\n",
    "# is the embedding dimension from SLDB\n",
    "num_timesteps = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of features is the active load value (main feature)\n",
    "# plus the six components of the sine-cosine positional encoding on hour, day, month\n",
    "\n",
    "# important: there is no value embedding, therefore d_model is very low\n",
    "d_model = 7\n",
    "\n",
    "# ToDo: use value embedding to a high-dimensional space and compare results\n",
    "# ToDo: use a different positional encoding system and compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as long as there is no value embedding, neither convolutional nor dense layers are required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 168, 7) dtype=float32 (created by layer 'input_2')>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input layer for Keras functional\n",
    "input_layer = tf.keras.layers.Input(shape=(num_timesteps, d_model))\n",
    "input_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 168, 7) dtype=float32 (created by layer 'input_2')>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_to_transformer_block = input_layer\n",
    "input_to_transformer_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 2\n",
    "ff_dim = 1024\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/developer/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:74: DeprecationWarning: `MultiHeadAttention` will be deprecated in Addons 0.13. Please use `tf.keras.layers.MultiHeadAttention` instead.\n"
     ]
    }
   ],
   "source": [
    "encoder_layer_1 = EncoderLayer(n_timesteps=num_timesteps,\n",
    "                               embed_dim=d_model,\n",
    "                               num_heads=num_heads,\n",
    "                               ff_dim=ff_dim,\n",
    "                               dropout=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/developer/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:74: DeprecationWarning: `MultiHeadAttention` will be deprecated in Addons 0.13. Please use `tf.keras.layers.MultiHeadAttention` instead.\n"
     ]
    }
   ],
   "source": [
    "encoder_layer_2 = EncoderLayer(n_timesteps=num_timesteps,\n",
    "                               embed_dim=d_model,\n",
    "                               num_heads=num_heads,\n",
    "                               ff_dim=ff_dim,\n",
    "                               dropout=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 168, 7) dtype=float32 (created by layer 'encoder_layer_2')>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_from_encoder_1 = encoder_layer_1(input_to_transformer_block)\n",
    "output_from_encoder_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 168, 7) dtype=float32 (created by layer 'encoder_layer_3')>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_from_encoder_2 = encoder_layer_2(output_from_encoder_1)\n",
    "output_from_encoder_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klingenbrunn uses a linear layer to decode the output_from_encoder\n",
    "# from (?, num_timesteps, num_features) to (?, num_timesteps, 1)\n",
    "\n",
    "# the equivalent operation in TensorFlow is a TimeDistributed Dense layer to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "units_in_first_dense = 1\n",
    "first_dense = tf.keras.layers.Dense(units_in_first_dense, activation=\"sigmoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 168, 1) dtype=float32 (created by layer 'time_distributed_1')>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distributed_first_dense = tf.keras.layers.TimeDistributed(first_dense)(output_from_encoder_2)\n",
    "distributed_first_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=input_layer, outputs=distributed_first_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\"adam\", \"mse\", metrics=[tf.keras.metrics.RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "469/469 [==============================] - 65s 133ms/step - loss: 0.0231 - root_mean_squared_error: 0.1494 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0619\n",
      "Epoch 2/100\n",
      "469/469 [==============================] - 63s 133ms/step - loss: 0.0064 - root_mean_squared_error: 0.0797 - val_loss: 0.0024 - val_root_mean_squared_error: 0.0493\n",
      "Epoch 3/100\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0024 - val_root_mean_squared_error: 0.0494\n",
      "Epoch 4/100\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 0.0034 - root_mean_squared_error: 0.0585 - val_loss: 0.0027 - val_root_mean_squared_error: 0.0520\n",
      "Epoch 5/100\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 0.0031 - root_mean_squared_error: 0.0557 - val_loss: 0.0021 - val_root_mean_squared_error: 0.0456\n",
      "Epoch 6/100\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 0.0028 - root_mean_squared_error: 0.0528 - val_loss: 0.0027 - val_root_mean_squared_error: 0.0522\n",
      "Epoch 7/100\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 0.0027 - root_mean_squared_error: 0.0524 - val_loss: 0.0021 - val_root_mean_squared_error: 0.0459\n",
      "Epoch 8/100\n",
      "469/469 [==============================] - 65s 138ms/step - loss: 0.0025 - root_mean_squared_error: 0.0503 - val_loss: 0.0023 - val_root_mean_squared_error: 0.0476\n",
      "Epoch 9/100\n",
      "469/469 [==============================] - 66s 140ms/step - loss: 0.0025 - root_mean_squared_error: 0.0496 - val_loss: 0.0022 - val_root_mean_squared_error: 0.0469\n",
      "Epoch 10/100\n",
      "469/469 [==============================] - 66s 140ms/step - loss: 0.0024 - root_mean_squared_error: 0.0485 - val_loss: 0.0023 - val_root_mean_squared_error: 0.0478\n",
      "Epoch 11/100\n",
      "469/469 [==============================] - 66s 141ms/step - loss: 0.0023 - root_mean_squared_error: 0.0479 - val_loss: 0.0020 - val_root_mean_squared_error: 0.0450\n",
      "Epoch 12/100\n",
      "469/469 [==============================] - 66s 141ms/step - loss: 0.0022 - root_mean_squared_error: 0.0472 - val_loss: 0.0022 - val_root_mean_squared_error: 0.0467\n",
      "Epoch 13/100\n",
      "469/469 [==============================] - 67s 142ms/step - loss: 0.0022 - root_mean_squared_error: 0.0464 - val_loss: 0.0021 - val_root_mean_squared_error: 0.0464\n",
      "Epoch 14/100\n",
      "469/469 [==============================] - 66s 142ms/step - loss: 0.0021 - root_mean_squared_error: 0.0455 - val_loss: 0.0021 - val_root_mean_squared_error: 0.0463\n",
      "Epoch 15/100\n",
      "469/469 [==============================] - 67s 142ms/step - loss: 0.0020 - root_mean_squared_error: 0.0452 - val_loss: 0.0023 - val_root_mean_squared_error: 0.0476\n",
      "Epoch 16/100\n",
      "469/469 [==============================] - 67s 143ms/step - loss: 0.0020 - root_mean_squared_error: 0.0446 - val_loss: 0.0025 - val_root_mean_squared_error: 0.0498\n",
      "Epoch 17/100\n",
      "469/469 [==============================] - 67s 143ms/step - loss: 0.0019 - root_mean_squared_error: 0.0439 - val_loss: 0.0030 - val_root_mean_squared_error: 0.0545\n",
      "Epoch 18/100\n",
      "469/469 [==============================] - 67s 143ms/step - loss: 0.0020 - root_mean_squared_error: 0.0443 - val_loss: 0.0030 - val_root_mean_squared_error: 0.0548\n",
      "Epoch 19/100\n",
      "469/469 [==============================] - 67s 143ms/step - loss: 0.0019 - root_mean_squared_error: 0.0433 - val_loss: 0.0029 - val_root_mean_squared_error: 0.0543\n",
      "Epoch 20/100\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 0.0018 - root_mean_squared_error: 0.0428 - val_loss: 0.0025 - val_root_mean_squared_error: 0.0498\n",
      "Epoch 21/100\n",
      "469/469 [==============================] - 67s 144ms/step - loss: 0.0018 - root_mean_squared_error: 0.0424 - val_loss: 0.0024 - val_root_mean_squared_error: 0.0491\n",
      "Epoch 22/100\n",
      "469/469 [==============================] - 67s 143ms/step - loss: 0.0018 - root_mean_squared_error: 0.0421 - val_loss: 0.0026 - val_root_mean_squared_error: 0.0506\n",
      "Epoch 23/100\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 0.0018 - root_mean_squared_error: 0.0420 - val_loss: 0.0024 - val_root_mean_squared_error: 0.0493\n",
      "Epoch 24/100\n",
      "469/469 [==============================] - 67s 144ms/step - loss: 0.0017 - root_mean_squared_error: 0.0414 - val_loss: 0.0022 - val_root_mean_squared_error: 0.0473\n",
      "Epoch 25/100\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 0.0017 - root_mean_squared_error: 0.0410 - val_loss: 0.0027 - val_root_mean_squared_error: 0.0520\n",
      "Epoch 26/100\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 0.0017 - root_mean_squared_error: 0.0407 - val_loss: 0.0032 - val_root_mean_squared_error: 0.0568\n",
      "Epoch 27/100\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 0.0017 - root_mean_squared_error: 0.0412 - val_loss: 0.0024 - val_root_mean_squared_error: 0.0493\n",
      "Epoch 28/100\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 0.0016 - root_mean_squared_error: 0.0405 - val_loss: 0.0023 - val_root_mean_squared_error: 0.0478\n",
      "Epoch 29/100\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 0.0016 - root_mean_squared_error: 0.0404 - val_loss: 0.0027 - val_root_mean_squared_error: 0.0519\n",
      "Epoch 30/100\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 0.0016 - root_mean_squared_error: 0.0399 - val_loss: 0.0026 - val_root_mean_squared_error: 0.0514\n",
      "Epoch 31/100\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 0.0016 - root_mean_squared_error: 0.0400 - val_loss: 0.0023 - val_root_mean_squared_error: 0.0482\n",
      "Epoch 32/100\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 0.0016 - root_mean_squared_error: 0.0401 - val_loss: 0.0024 - val_root_mean_squared_error: 0.0492\n",
      "Epoch 33/100\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 0.0016 - root_mean_squared_error: 0.0399 - val_loss: 0.0023 - val_root_mean_squared_error: 0.0484\n",
      "Epoch 34/100\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 0.0016 - root_mean_squared_error: 0.0397 - val_loss: 0.0029 - val_root_mean_squared_error: 0.0536\n",
      "Epoch 35/100\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 0.0016 - root_mean_squared_error: 0.0396 - val_loss: 0.0030 - val_root_mean_squared_error: 0.0552\n",
      "Epoch 36/100\n",
      "469/469 [==============================] - 68s 146ms/step - loss: 0.0016 - root_mean_squared_error: 0.0396 - val_loss: 0.0024 - val_root_mean_squared_error: 0.0487\n",
      "Epoch 37/100\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 0.0016 - root_mean_squared_error: 0.0395 - val_loss: 0.0024 - val_root_mean_squared_error: 0.0494\n",
      "Epoch 38/100\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 0.0015 - root_mean_squared_error: 0.0387 - val_loss: 0.0028 - val_root_mean_squared_error: 0.0533\n",
      "Epoch 39/100\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 0.0015 - root_mean_squared_error: 0.0388 - val_loss: 0.0025 - val_root_mean_squared_error: 0.0504\n",
      "Epoch 40/100\n",
      "469/469 [==============================] - 68s 146ms/step - loss: 0.0015 - root_mean_squared_error: 0.0393 - val_loss: 0.0025 - val_root_mean_squared_error: 0.0497\n",
      "Epoch 41/100\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 0.0015 - root_mean_squared_error: 0.0390 - val_loss: 0.0022 - val_root_mean_squared_error: 0.0470\n",
      "Epoch 42/100\n",
      "469/469 [==============================] - 69s 147ms/step - loss: 0.0015 - root_mean_squared_error: 0.0389 - val_loss: 0.0025 - val_root_mean_squared_error: 0.0502\n",
      "Epoch 43/100\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 0.0015 - root_mean_squared_error: 0.0389 - val_loss: 0.0032 - val_root_mean_squared_error: 0.0562\n",
      "Epoch 44/100\n",
      "469/469 [==============================] - 69s 147ms/step - loss: 0.0015 - root_mean_squared_error: 0.0388 - val_loss: 0.0025 - val_root_mean_squared_error: 0.0500\n",
      "Epoch 45/100\n",
      "469/469 [==============================] - 74s 158ms/step - loss: 0.0015 - root_mean_squared_error: 0.0381 - val_loss: 0.0023 - val_root_mean_squared_error: 0.0480\n",
      "Epoch 46/100\n",
      "469/469 [==============================] - 77s 164ms/step - loss: 0.0015 - root_mean_squared_error: 0.0382 - val_loss: 0.0023 - val_root_mean_squared_error: 0.0475\n",
      "Epoch 47/100\n",
      "469/469 [==============================] - 75s 161ms/step - loss: 0.0015 - root_mean_squared_error: 0.0382 - val_loss: 0.0023 - val_root_mean_squared_error: 0.0485\n",
      "Epoch 48/100\n",
      "469/469 [==============================] - 76s 161ms/step - loss: 0.0015 - root_mean_squared_error: 0.0382 - val_loss: 0.0025 - val_root_mean_squared_error: 0.0497\n",
      "Epoch 49/100\n",
      "469/469 [==============================] - 75s 161ms/step - loss: 0.0014 - root_mean_squared_error: 0.0380 - val_loss: 0.0026 - val_root_mean_squared_error: 0.0508\n",
      "Epoch 50/100\n",
      "469/469 [==============================] - 76s 161ms/step - loss: 0.0014 - root_mean_squared_error: 0.0376 - val_loss: 0.0026 - val_root_mean_squared_error: 0.0506\n",
      "Epoch 51/100\n",
      "469/469 [==============================] - 75s 161ms/step - loss: 0.0014 - root_mean_squared_error: 0.0379 - val_loss: 0.0023 - val_root_mean_squared_error: 0.0478\n",
      "Epoch 52/100\n",
      "469/469 [==============================] - 76s 161ms/step - loss: 0.0014 - root_mean_squared_error: 0.0372 - val_loss: 0.0030 - val_root_mean_squared_error: 0.0551\n",
      "Epoch 53/100\n",
      "469/469 [==============================] - 76s 161ms/step - loss: 0.0015 - root_mean_squared_error: 0.0385 - val_loss: 0.0022 - val_root_mean_squared_error: 0.0472\n",
      "Epoch 54/100\n",
      "469/469 [==============================] - 76s 161ms/step - loss: 0.0014 - root_mean_squared_error: 0.0374 - val_loss: 0.0024 - val_root_mean_squared_error: 0.0494\n",
      "Epoch 55/100\n",
      "469/469 [==============================] - 76s 161ms/step - loss: 0.0014 - root_mean_squared_error: 0.0375 - val_loss: 0.0022 - val_root_mean_squared_error: 0.0473\n",
      "Epoch 56/100\n",
      "469/469 [==============================] - 75s 161ms/step - loss: 0.0014 - root_mean_squared_error: 0.0368 - val_loss: 0.0024 - val_root_mean_squared_error: 0.0493\n",
      "Epoch 57/100\n",
      "469/469 [==============================] - 76s 161ms/step - loss: 0.0014 - root_mean_squared_error: 0.0373 - val_loss: 0.0022 - val_root_mean_squared_error: 0.0470\n",
      "Epoch 58/100\n",
      "469/469 [==============================] - 75s 159ms/step - loss: 0.0014 - root_mean_squared_error: 0.0379 - val_loss: 0.0024 - val_root_mean_squared_error: 0.0489\n",
      "Epoch 59/100\n",
      "469/469 [==============================] - 64s 137ms/step - loss: 0.0014 - root_mean_squared_error: 0.0370 - val_loss: 0.0021 - val_root_mean_squared_error: 0.0462\n",
      "Epoch 60/100\n",
      "469/469 [==============================] - 66s 141ms/step - loss: 0.0014 - root_mean_squared_error: 0.0371 - val_loss: 0.0020 - val_root_mean_squared_error: 0.0447\n",
      "Epoch 61/100\n",
      "469/469 [==============================] - 66s 141ms/step - loss: 0.0014 - root_mean_squared_error: 0.0371 - val_loss: 0.0021 - val_root_mean_squared_error: 0.0454\n",
      "Epoch 62/100\n",
      "469/469 [==============================] - 67s 143ms/step - loss: 0.0013 - root_mean_squared_error: 0.0365 - val_loss: 0.0023 - val_root_mean_squared_error: 0.0480\n",
      "Epoch 63/100\n",
      "469/469 [==============================] - 67s 143ms/step - loss: 0.0013 - root_mean_squared_error: 0.0367 - val_loss: 0.0022 - val_root_mean_squared_error: 0.0467\n",
      "Epoch 64/100\n",
      "469/469 [==============================] - 67s 143ms/step - loss: 0.0013 - root_mean_squared_error: 0.0367 - val_loss: 0.0023 - val_root_mean_squared_error: 0.0480\n",
      "Epoch 65/100\n",
      "469/469 [==============================] - 67s 142ms/step - loss: 0.0013 - root_mean_squared_error: 0.0365 - val_loss: 0.0030 - val_root_mean_squared_error: 0.0548\n",
      "Epoch 66/100\n",
      "469/469 [==============================] - 67s 144ms/step - loss: 0.0013 - root_mean_squared_error: 0.0367 - val_loss: 0.0021 - val_root_mean_squared_error: 0.0454\n",
      "Epoch 67/100\n",
      "469/469 [==============================] - 67s 144ms/step - loss: 0.0013 - root_mean_squared_error: 0.0365 - val_loss: 0.0024 - val_root_mean_squared_error: 0.0493\n",
      "Epoch 68/100\n",
      "469/469 [==============================] - 67s 143ms/step - loss: 0.0013 - root_mean_squared_error: 0.0363 - val_loss: 0.0025 - val_root_mean_squared_error: 0.0497\n",
      "Epoch 69/100\n",
      "469/469 [==============================] - 67s 144ms/step - loss: 0.0014 - root_mean_squared_error: 0.0369 - val_loss: 0.0020 - val_root_mean_squared_error: 0.0452\n",
      "Epoch 70/100\n",
      "469/469 [==============================] - 67s 143ms/step - loss: 0.0013 - root_mean_squared_error: 0.0360 - val_loss: 0.0023 - val_root_mean_squared_error: 0.0478\n",
      "Epoch 71/100\n",
      "469/469 [==============================] - 67s 143ms/step - loss: 0.0013 - root_mean_squared_error: 0.0366 - val_loss: 0.0023 - val_root_mean_squared_error: 0.0479\n",
      "Epoch 72/100\n",
      "469/469 [==============================] - 67s 142ms/step - loss: 0.0013 - root_mean_squared_error: 0.0361 - val_loss: 0.0022 - val_root_mean_squared_error: 0.0468\n",
      "Epoch 73/100\n",
      "469/469 [==============================] - 66s 142ms/step - loss: 0.0013 - root_mean_squared_error: 0.0364 - val_loss: 0.0027 - val_root_mean_squared_error: 0.0523\n",
      "Epoch 74/100\n",
      "469/469 [==============================] - 67s 143ms/step - loss: 0.0013 - root_mean_squared_error: 0.0366 - val_loss: 0.0022 - val_root_mean_squared_error: 0.0474\n",
      "Epoch 75/100\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 0.0013 - root_mean_squared_error: 0.0359 - val_loss: 0.0023 - val_root_mean_squared_error: 0.0478\n",
      "Epoch 76/100\n",
      "469/469 [==============================] - 67s 144ms/step - loss: 0.0013 - root_mean_squared_error: 0.0357 - val_loss: 0.0030 - val_root_mean_squared_error: 0.0543\n",
      "Epoch 77/100\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 0.0013 - root_mean_squared_error: 0.0360 - val_loss: 0.0020 - val_root_mean_squared_error: 0.0444\n",
      "Epoch 78/100\n",
      "469/469 [==============================] - 67s 144ms/step - loss: 0.0013 - root_mean_squared_error: 0.0360 - val_loss: 0.0026 - val_root_mean_squared_error: 0.0509\n",
      "Epoch 79/100\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 0.0013 - root_mean_squared_error: 0.0360 - val_loss: 0.0022 - val_root_mean_squared_error: 0.0473\n",
      "Epoch 80/100\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 0.0013 - root_mean_squared_error: 0.0360 - val_loss: 0.0026 - val_root_mean_squared_error: 0.0510\n",
      "Epoch 81/100\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 0.0013 - root_mean_squared_error: 0.0354 - val_loss: 0.0021 - val_root_mean_squared_error: 0.0459\n",
      "Epoch 82/100\n",
      "469/469 [==============================] - 68s 144ms/step - loss: 0.0013 - root_mean_squared_error: 0.0355 - val_loss: 0.0025 - val_root_mean_squared_error: 0.0503\n",
      "Epoch 83/100\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 0.0013 - root_mean_squared_error: 0.0355 - val_loss: 0.0020 - val_root_mean_squared_error: 0.0452\n",
      "Epoch 84/100\n",
      "469/469 [==============================] - 74s 157ms/step - loss: 0.0012 - root_mean_squared_error: 0.0352 - val_loss: 0.0021 - val_root_mean_squared_error: 0.0457\n",
      "Epoch 85/100\n",
      "469/469 [==============================] - 76s 161ms/step - loss: 0.0012 - root_mean_squared_error: 0.0353 - val_loss: 0.0021 - val_root_mean_squared_error: 0.0459\n",
      "Epoch 86/100\n",
      "469/469 [==============================] - 76s 161ms/step - loss: 0.0013 - root_mean_squared_error: 0.0354 - val_loss: 0.0023 - val_root_mean_squared_error: 0.0477\n",
      "Epoch 87/100\n",
      "469/469 [==============================] - 75s 161ms/step - loss: 0.0012 - root_mean_squared_error: 0.0352 - val_loss: 0.0020 - val_root_mean_squared_error: 0.0445\n",
      "Epoch 88/100\n",
      "469/469 [==============================] - 76s 161ms/step - loss: 0.0012 - root_mean_squared_error: 0.0353 - val_loss: 0.0022 - val_root_mean_squared_error: 0.0474\n",
      "Epoch 89/100\n",
      "469/469 [==============================] - 75s 161ms/step - loss: 0.0012 - root_mean_squared_error: 0.0353 - val_loss: 0.0025 - val_root_mean_squared_error: 0.0501\n",
      "Epoch 90/100\n",
      "469/469 [==============================] - 76s 162ms/step - loss: 0.0013 - root_mean_squared_error: 0.0354 - val_loss: 0.0025 - val_root_mean_squared_error: 0.0498\n",
      "Epoch 91/100\n",
      "469/469 [==============================] - 77s 164ms/step - loss: 0.0012 - root_mean_squared_error: 0.0351 - val_loss: 0.0024 - val_root_mean_squared_error: 0.0487\n",
      "Epoch 92/100\n",
      "469/469 [==============================] - 77s 165ms/step - loss: 0.0012 - root_mean_squared_error: 0.0353 - val_loss: 0.0023 - val_root_mean_squared_error: 0.0481\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 82s 175ms/step - loss: 0.0012 - root_mean_squared_error: 0.0350 - val_loss: 0.0024 - val_root_mean_squared_error: 0.0488\n",
      "Epoch 94/100\n",
      "469/469 [==============================] - 79s 168ms/step - loss: 0.0012 - root_mean_squared_error: 0.0348 - val_loss: 0.0026 - val_root_mean_squared_error: 0.0510\n",
      "Epoch 95/100\n",
      "469/469 [==============================] - 76s 161ms/step - loss: 0.0012 - root_mean_squared_error: 0.0353 - val_loss: 0.0019 - val_root_mean_squared_error: 0.0430\n",
      "Epoch 96/100\n",
      "469/469 [==============================] - 76s 161ms/step - loss: 0.0012 - root_mean_squared_error: 0.0349 - val_loss: 0.0020 - val_root_mean_squared_error: 0.0450\n",
      "Epoch 97/100\n",
      "469/469 [==============================] - 76s 161ms/step - loss: 0.0012 - root_mean_squared_error: 0.0350 - val_loss: 0.0022 - val_root_mean_squared_error: 0.0471\n",
      "Epoch 98/100\n",
      "469/469 [==============================] - 75s 161ms/step - loss: 0.0012 - root_mean_squared_error: 0.0347 - val_loss: 0.0021 - val_root_mean_squared_error: 0.0455\n",
      "Epoch 99/100\n",
      "469/469 [==============================] - 76s 161ms/step - loss: 0.0012 - root_mean_squared_error: 0.0348 - val_loss: 0.0022 - val_root_mean_squared_error: 0.0471\n",
      "Epoch 100/100\n",
      "469/469 [==============================] - 76s 162ms/step - loss: 0.0012 - root_mean_squared_error: 0.0353 - val_loss: 0.0022 - val_root_mean_squared_error: 0.0466\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train, batch_size=32, epochs=100, validation_data=(x_eval, y_eval)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference process on unseen data, that means on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a forecast window to guide the iterative prediction process\n",
    "# start with a hourly, day-ahead process\n",
    "forecast_window = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use naming conventions from Klingenbrunn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 168, 7])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the true active load values, plus the six positional encodings\n",
    "# in the first row of the test dataset features (original ts indexes are 21000-21167)\n",
    "src = tf.expand_dims(x_test[0, :, :], axis=0)\n",
    "src.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the true active load values, plus the six positional encodings\n",
    "# in the forecast-window-sized timesteps following the source (original ts indexes are 21168-21191)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 24, 7])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = tf.expand_dims(x_test[168, :forecast_window, :], axis=0)\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify that active load values in the source and the target are contiguous in the time series\n",
    "# that means, target is composed with the first timesteps of features\n",
    "# in the rows 168-191 of test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26612255, 0.23641237, 0.24432548, 0.32326286, 0.36856605,\n",
       "       0.45449848, 0.56519907, 0.68640037, 0.74005594, 0.84452149,\n",
       "       0.86219931, 0.86331182, 0.87358708, 0.94115296, 0.89783385,\n",
       "       0.90333212, 0.8544241 , 0.89447384, 0.90186633, 0.83024086,\n",
       "       0.67798756, 0.54712923, 0.42006322, 0.33738621])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[168:192, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(24,), dtype=float64, numpy=\n",
       "array([0.26612255, 0.23641237, 0.24432548, 0.32326286, 0.36856605,\n",
       "       0.45449848, 0.56519907, 0.68640037, 0.74005594, 0.84452149,\n",
       "       0.86219931, 0.86331182, 0.87358708, 0.94115296, 0.89783385,\n",
       "       0.90333212, 0.8544241 , 0.89447384, 0.90186633, 0.83024086,\n",
       "       0.67798756, 0.54712923, 0.42006322, 0.33738621])>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[0, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# therefore, source and target tensors are ready for inference process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_input_model = src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not use the all_predictions array from Klingenbrunn, just the predictions on the forecast window\n",
    "predictions_list = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once tested, put the following lines on an iterative cycle\n",
    "# for i in range(forecast_window -1): ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(forecast_window):\n",
    "    \n",
    "    # get a prediction (1, 168, 1) from input (1, 168, 7)\n",
    "    prediction = model.predict(\n",
    "        next_input_model, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10,\n",
    "        workers=1, use_multiprocessing=False\n",
    "    )\n",
    "    \n",
    "    # get the value of the most recent prediction (last timestep) into the predictions list\n",
    "    predictions_list.append(prediction[:, -1, :][0][0])\n",
    "    \n",
    "    # from the source tensor, get the positional encodings for ti+1 to t167 (that is 168-i-1 values)\n",
    "    pos_encoding_old_values = src[:, i+1:, 1:]\n",
    "\n",
    "    # from target tensor, get the positional encodings for t168 to t168+i (that is i+1 values)\n",
    "    pos_encoding_new_val = target[:, :i+1, 1:]\n",
    "\n",
    "    # build new positional encodings with 168 values\n",
    "    pos_encodings = tf.concat([pos_encoding_old_values, pos_encoding_new_val], axis=1)\n",
    "    pos_encodings = tf.cast(pos_encodings, dtype=tf.float32)\n",
    "\n",
    "    # build the values feature for the next input to the model\n",
    "    # pop i+1 values at the beginning of the previous input\n",
    "    value_feature_old_values = tf.expand_dims(src[:, i+1:, 0], axis=-1)\n",
    "    value_feature_old_values = tf.cast(value_feature_old_values, dtype=tf.float32)\n",
    "\n",
    "    # current predictions_list to NumPy array\n",
    "    value_feature_new_values = np.array(predictions_list[:i+1])\n",
    "\n",
    "    # current prediction array to tensor\n",
    "    value_feature_new_values = tf.convert_to_tensor(value_feature_new_values)\n",
    "\n",
    "    # expand dimensions of current prediction tensor to single-value feature\n",
    "    value_feature_new_values = tf.expand_dims(value_feature_new_values, axis=-1)\n",
    "\n",
    "    # expand dimensions of current prediction tensor to single-value batch\n",
    "    value_feature_new_values = tf.expand_dims(value_feature_new_values, axis=0)\n",
    "    \n",
    "    # build the value feature tensor\n",
    "    next_input_model = tf.concat([value_feature_old_values, value_feature_new_values], axis=1)\n",
    "    \n",
    "    # build the next input tensor for the model\n",
    "    next_input_model = tf.concat([next_input_model, pos_encodings], axis=2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.27063882, 0.24955139, 0.26786205, 0.32904452, 0.3623683 ,\n",
       "       0.40988988, 0.4909711 , 0.5777742 , 0.65716684, 0.73376966,\n",
       "       0.78400385, 0.82222307, 0.8517444 , 0.8649932 , 0.8633987 ,\n",
       "       0.8349567 , 0.8171438 , 0.82490766, 0.8359086 , 0.7671213 ,\n",
       "       0.6175975 , 0.47953865, 0.37069687, 0.31055808], dtype=float32)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(predictions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26612255, 0.23641237, 0.24432548, 0.32326286, 0.36856605,\n",
       "       0.45449848, 0.56519907, 0.68640037, 0.74005594, 0.84452149,\n",
       "       0.86219931, 0.86331182, 0.87358708, 0.94115296, 0.89783385,\n",
       "       0.90333212, 0.8544241 , 0.89447384, 0.90186633, 0.83024086,\n",
       "       0.67798756, 0.54712923, 0.42006322, 0.33738621])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(target[0, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# symmetrical mean absolute percentage error\n",
    "def smape(targets, predictions):\n",
    "    '''\n",
    "    predictions: a list with the predicted values\n",
    "    targets: a list with the actual values\n",
    "    '''\n",
    "    import numpy as np\n",
    "    # lists to NumPy arrays\n",
    "    targets, predictions = np.array(targets), np.array(predictions)\n",
    "    # verify predictions and targets have the same shape\n",
    "    if predictions.shape == targets.shape:\n",
    "            return(np.sum(2*np.abs(predictions - targets) /\n",
    "                          (np.abs(targets) + np.abs(predictions)))/predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08151349767533242"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smape(np.array(target[0, :, 0]), np.array(predictions_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
