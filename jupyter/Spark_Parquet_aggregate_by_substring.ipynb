{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "José Luis García Nava\n",
    "DEPFIE-SCOM\n",
    "Cloud-based Implementation of Distributed Machine Learning Algorithms for Time Series Forecasting\n",
    "Parquet Archive as Time Series Database Management System\n",
    "Updated from MIRD-related research to Spark 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARQUET_PATH = '/home/developer/On_Premises/complete_20160101000000_to_20180809114000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESOLUTION = 'hourly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = ['CPE04015']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for device in devices:\n",
    "    path= '{}/{}/{}.parquet'.format(PARQUET_PATH, RESOLUTION, devices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change timestamp from string to datetime\n",
    "# from pyspark.sql.functions import unix_timestamp\n",
    "from pyspark.sql.functions import to_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Van', 'Vbn', 'Vcn', 'Vav', 'ia', 'ib', 'ic', 'iav', 'kw', 'kvar', 'kwan', 'kwbn', 'kwcn', 'kvaran', 'kvarbn', 'kvarcn', 'f', 'fp', 'thdvan', 'thdvbn', 'thdvcn', 'thdia', 'thdib', 'thdic', 'desbV', 'desbI', 'kwhE', 'kwhR', 'kvarhDel', 'kvarhrec', 'kvarhq3', 'kvarhq4\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a nice trick to get a string with remaining columns, for copy and paste\n",
    "\"', '\".join(df.columns[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 is a Spark DataFrame with timestamp as datetime\n",
    "# use a Spark DataFrame operation instead of a Spark SQL query\n",
    "df2 = df.select(to_timestamp(df.timestamp, 'yyyy-MM-dd HH:mm:ss').alias('timestamp'), 'Van', 'Vbn', 'Vcn', 'Vav', \\\n",
    "                'ia', 'ib', 'ic', 'iav', 'kw', 'kvar', 'kwan', 'kwbn', 'kwcn', 'kvaran', 'kvarbn', 'kvarcn', \\\n",
    "                'f', 'fp', 'thdvan', 'thdvbn', 'thdvcn', 'thdia', 'thdib', 'thdic', 'desbV', 'desbI', \\\n",
    "                'kwhE', 'kwhR', 'kvarhDel', 'kvarhrec', 'kvarhq3', 'kvarhq4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+------+------+------+-----+--------+------+------+------+------+------+------+------+------+-----+----+--------+--------+-------+-------+\n",
      "|          timestamp|    Van|    Vbn|    Vcn|    Vav|     ia|     ib|     ic|    iav|     kw|   kvar|   kwan|   kwbn|   kwcn|kvaran|kvarbn|kvarcn|    f|      fp|thdvan|thdvbn|thdvcn| thdia| thdib| thdic| desbV| desbI| kwhE|kwhR|kvarhDel|kvarhrec|kvarhq3|kvarhq4|\n",
      "+-------------------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+------+------+------+-----+--------+------+------+------+------+------+------+------+------+-----+----+--------+--------+-------+-------+\n",
      "|2016-01-01 00:00:00|7955.98|7950.79|7921.85|13741.2|  61.65|59.5756| 52.035|57.7535|1351.37|227.231|484.352|464.021|402.994|62.129|83.767|81.334|59.99|0.986156|0.0098|0.0097|0.0099|0.0925|0.0906|0.0697|3.0E-4|0.0099|113.0| 0.0|    19.0|     0.0|    0.0|    0.0|\n",
      "|2016-01-01 00:10:00|7963.04| 7957.0|7929.89|13753.5|60.4452|58.5288| 51.128|56.7006|1328.89| 217.37|475.327|456.357|397.208|60.326|81.545|75.497|59.99|0.986885|0.0099|0.0099|0.0099| 0.094|0.0911|0.0712|2.0E-4|0.0098|111.0| 0.0|    18.0|     0.0|    0.0|    0.0|\n",
      "|2016-01-01 00:20:00|7964.61|7958.55|7931.08|13755.9|60.8048|59.4637|51.1535|57.1407|1339.19|221.391|478.076|463.805|397.312|62.295|82.623|76.472|59.98|0.986609|0.0098|  0.01|0.0099| 0.093|0.0901|0.0703|2.0E-4|0.0105|112.0| 0.0|    18.0|     0.0|    0.0|    0.0|\n",
      "|2016-01-01 00:30:00|7970.75|7965.75|7937.12|13767.1| 60.395|58.4002|50.7144|56.5032| 1325.0|220.028|475.326|455.829|393.848|60.801|81.631|77.594|59.99|0.986491|0.0098|0.0101|0.0101|0.0936|0.0909|0.0708|2.0E-4|0.0102|110.0| 0.0|    18.0|     0.0|    0.0|    0.0|\n",
      "|2016-01-01 00:40:00|7950.22|7946.37|7916.46|13732.2|59.9408|58.0374|50.3584|56.1122|1311.81|223.057|470.327|451.882|389.605|62.513|81.293| 79.25|59.99| 0.98585|0.0098|0.0101|  0.01| 0.092|0.0899|0.0703|3.0E-4|0.0102|109.0| 0.0|    18.0|     0.0|    0.0|    0.0|\n",
      "|2016-01-01 00:50:00|7938.02|7934.97|7904.84|13711.9|58.5344|57.0354|50.0512| 55.207|1289.16|215.465|458.915|443.142|387.099|57.815| 81.31|76.338|59.99|0.986319|0.0097|  0.01|0.0099|0.0938|  0.09|0.0708|3.0E-4|0.0093|107.0| 0.0|    18.0|     0.0|    0.0|    0.0|\n",
      "+-------------------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+------+------+------+-----+--------+------+------+------+------+------+------+------+------+-----+----+--------+--------+-------+-------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- Van: double (nullable = true)\n",
      " |-- Vbn: double (nullable = true)\n",
      " |-- Vcn: double (nullable = true)\n",
      " |-- Vav: double (nullable = true)\n",
      " |-- ia: double (nullable = true)\n",
      " |-- ib: double (nullable = true)\n",
      " |-- ic: double (nullable = true)\n",
      " |-- iav: double (nullable = true)\n",
      " |-- kw: double (nullable = true)\n",
      " |-- kvar: double (nullable = true)\n",
      " |-- kwan: double (nullable = true)\n",
      " |-- kwbn: double (nullable = true)\n",
      " |-- kwcn: double (nullable = true)\n",
      " |-- kvaran: double (nullable = true)\n",
      " |-- kvarbn: double (nullable = true)\n",
      " |-- kvarcn: double (nullable = true)\n",
      " |-- f: double (nullable = true)\n",
      " |-- fp: double (nullable = true)\n",
      " |-- thdvan: double (nullable = true)\n",
      " |-- thdvbn: double (nullable = true)\n",
      " |-- thdvcn: double (nullable = true)\n",
      " |-- thdia: double (nullable = true)\n",
      " |-- thdib: double (nullable = true)\n",
      " |-- thdic: double (nullable = true)\n",
      " |-- desbV: double (nullable = true)\n",
      " |-- desbI: double (nullable = true)\n",
      " |-- kwhE: double (nullable = true)\n",
      " |-- kwhR: double (nullable = true)\n",
      " |-- kvarhDel: double (nullable = true)\n",
      " |-- kvarhrec: double (nullable = true)\n",
      " |-- kvarhq3: double (nullable = true)\n",
      " |-- kvarhq4: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# now timestamp column in Spark DataFrame is really a timestamp\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(timestamp=datetime.datetime(2016, 1, 1, 0, 0), Van=7955.98, Vbn=7950.79, Vcn=7921.85, Vav=13741.2, ia=61.65, ib=59.5756, ic=52.035, iav=57.7535, kw=1351.37, kvar=227.231, kwan=484.352, kwbn=464.021, kwcn=402.994, kvaran=62.129, kvarbn=83.767, kvarcn=81.334, f=59.99, fp=0.986156, thdvan=0.0098, thdvbn=0.0097, thdvcn=0.0099, thdia=0.0925, thdib=0.0906, thdic=0.0697, desbV=0.0003, desbI=0.0099, kwhE=113.0, kwhR=0.0, kvarhDel=19.0, kvarhrec=0.0, kvarhq3=0.0, kvarhq4=0.0),\n",
       " Row(timestamp=datetime.datetime(2016, 1, 1, 0, 10), Van=7963.04, Vbn=7957.0, Vcn=7929.89, Vav=13753.5, ia=60.4452, ib=58.5288, ic=51.128, iav=56.7006, kw=1328.89, kvar=217.37, kwan=475.327, kwbn=456.357, kwcn=397.208, kvaran=60.326, kvarbn=81.545, kvarcn=75.497, f=59.99, fp=0.986885, thdvan=0.0099, thdvbn=0.0099, thdvcn=0.0099, thdia=0.094, thdib=0.0911, thdic=0.0712, desbV=0.0002, desbI=0.0098, kwhE=111.0, kwhR=0.0, kvarhDel=18.0, kvarhrec=0.0, kvarhq3=0.0, kvarhq4=0.0),\n",
       " Row(timestamp=datetime.datetime(2016, 1, 1, 0, 20), Van=7964.61, Vbn=7958.55, Vcn=7931.08, Vav=13755.9, ia=60.8048, ib=59.4637, ic=51.1535, iav=57.1407, kw=1339.19, kvar=221.391, kwan=478.076, kwbn=463.805, kwcn=397.312, kvaran=62.295, kvarbn=82.623, kvarcn=76.472, f=59.98, fp=0.986609, thdvan=0.0098, thdvbn=0.01, thdvcn=0.0099, thdia=0.093, thdib=0.0901, thdic=0.0703, desbV=0.0002, desbI=0.0105, kwhE=112.0, kwhR=0.0, kvarhDel=18.0, kvarhrec=0.0, kvarhq3=0.0, kvarhq4=0.0),\n",
       " Row(timestamp=datetime.datetime(2016, 1, 1, 0, 30), Van=7970.75, Vbn=7965.75, Vcn=7937.12, Vav=13767.1, ia=60.395, ib=58.4002, ic=50.7144, iav=56.5032, kw=1325.0, kvar=220.028, kwan=475.326, kwbn=455.829, kwcn=393.848, kvaran=60.801, kvarbn=81.631, kvarcn=77.594, f=59.99, fp=0.986491, thdvan=0.0098, thdvbn=0.0101, thdvcn=0.0101, thdia=0.0936, thdib=0.0909, thdic=0.0708, desbV=0.0002, desbI=0.0102, kwhE=110.0, kwhR=0.0, kvarhDel=18.0, kvarhrec=0.0, kvarhq3=0.0, kvarhq4=0.0),\n",
       " Row(timestamp=datetime.datetime(2016, 1, 1, 0, 40), Van=7950.22, Vbn=7946.37, Vcn=7916.46, Vav=13732.2, ia=59.9408, ib=58.0374, ic=50.3584, iav=56.1122, kw=1311.81, kvar=223.057, kwan=470.327, kwbn=451.882, kwcn=389.605, kvaran=62.513, kvarbn=81.293, kvarcn=79.25, f=59.99, fp=0.98585, thdvan=0.0098, thdvbn=0.0101, thdvcn=0.01, thdia=0.092, thdib=0.0899, thdic=0.0703, desbV=0.0003, desbI=0.0102, kwhE=109.0, kwhR=0.0, kvarhDel=18.0, kvarhrec=0.0, kvarhq3=0.0, kvarhq4=0.0)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(timestamp=datetime.datetime(2018, 8, 9, 9, 40), Van=7883.34, Vbn=7858.93, Vcn=7845.2, Vav=13602.1, ia=28.0719, ib=25.5269, ic=24.1443, iav=25.9144, kw=576.914, kvar=176.199, kwan=211.61, kwbn=188.143, kwcn=177.16, kvaran=57.219, kvarbn=59.923, kvarcn=59.055, f=60.0, fp=0.956389, thdvan=1.12, thdvbn=1.1, thdvcn=1.17, thdia=12.45, thdib=12.62, thdic=12.87, desbV=0.3, desbI=8.3259, kwhE=49.0, kwhR=0.0, kvarhDel=16.0, kvarhrec=0.0, kvarhq3=0.0, kvarhq4=0.0),\n",
       " Row(timestamp=datetime.datetime(2018, 8, 9, 9, 50), Van=7872.36, Vbn=7848.83, Vcn=7833.02, Vav=13582.9, ia=28.0939, ib=27.0049, ic=26.1431, iav=27.0806, kw=595.677, kvar=202.243, kwan=208.978, kwbn=196.613, kwcn=190.086, kvaran=64.426, kvarbn=69.669, kvarcn=68.147, f=60.0, fp=0.946912, thdvan=1.13, thdvbn=1.08, thdvcn=1.16, thdia=13.11, thdib=12.87, thdic=12.88, desbV=0.3, desbI=3.7416, kwhE=49.0, kwhR=0.0, kvarhDel=16.0, kvarhrec=0.0, kvarhq3=0.0, kvarhq4=0.0),\n",
       " Row(timestamp=datetime.datetime(2018, 8, 9, 10, 0), Van=7858.72, Vbn=7837.37, Vcn=7820.7, Vav=13561.4, ia=28.9594, ib=27.5185, ic=26.7211, iav=27.733, kw=618.32, kvar=178.171, kwan=217.883, kwbn=203.766, kwcn=196.67, kvaran=57.246, kvarbn=59.236, kvarcn=61.689, f=60.0, fp=0.960902, thdvan=1.14, thdvbn=1.11, thdvcn=1.22, thdia=12.35, thdib=11.86, thdic=11.92, desbV=0.3, desbI=4.4221, kwhE=53.0, kwhR=0.0, kvarhDel=15.0, kvarhrec=0.0, kvarhq3=0.0, kvarhq4=0.0),\n",
       " Row(timestamp=datetime.datetime(2018, 8, 9, 10, 10), Van=7860.59, Vbn=7839.83, Vcn=7823.71, Vav=13565.6, ia=28.5068, ib=27.3543, ic=25.7914, iav=27.2175, kw=607.058, kvar=172.989, kwan=214.395, kwbn=203.344, kwcn=189.318, kvaran=56.151, kvarbn=55.68, kvarcn=61.157, f=60.0, fp=0.961715, thdvan=1.17, thdvbn=1.11, thdvcn=1.25, thdia=12.64, thdib=12.49, thdic=12.14, desbV=0.3, desbI=5.2396, kwhE=50.0, kwhR=0.0, kvarhDel=13.0, kvarhrec=0.0, kvarhq3=0.0, kvarhq4=0.0),\n",
       " Row(timestamp=datetime.datetime(2018, 8, 9, 10, 20), Van=7848.07, Vbn=7828.68, Vcn=7810.56, Vav=13544.3, ia=27.9445, ib=26.4501, ic=26.0439, iav=26.8128, kw=592.263, kvar=186.29, kwan=208.626, kwbn=194.387, kwcn=189.248, kvaran=59.214, kvarbn=60.255, kvarcn=66.82, f=59.97, fp=0.953924, thdvan=1.12, thdvbn=1.1, thdvcn=1.2, thdia=13.49, thdib=13.27, thdic=12.33, desbV=0.3, desbI=4.2207, kwhE=49.0, kwhR=0.0, kvarhDel=16.0, kvarhrec=0.0, kvarhq3=0.0, kvarhq4=0.0)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now aggregate on the hour, in Spark SQL\n",
    "# first, create the temporary view on the Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.createOrReplaceTempView('df2_view')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hourly_df aggregates by average on the timestamp substring up to the hours\n",
    "hourly_df = spark.sql('select substring(timestamp, 1, 13) as timestamp, \\\n",
    "                              avg(kw) as kw, \\\n",
    "                              avg(kvar) as kvar \\\n",
    "                       from df2_view group by substring(timestamp, 1, 13) \\\n",
    "                       order by substring(timestamp, 1, 13)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+------------------+\n",
      "|    timestamp|                kw|              kvar|\n",
      "+-------------+------------------+------------------+\n",
      "|2016-01-01 00|1324.2366666666667|220.75699999999998|\n",
      "|2016-01-01 01|1245.2316666666666|           209.205|\n",
      "|2016-01-01 02|1145.6866666666667|204.01933333333332|\n",
      "|2016-01-01 03|1044.6466666666668|203.31083333333333|\n",
      "|2016-01-01 04| 960.6921666666667|203.21000000000004|\n",
      "|2016-01-01 05| 911.6516666666666|206.02883333333332|\n",
      "|2016-01-01 06| 871.7088333333332|204.23850000000002|\n",
      "|2016-01-01 07| 775.2703333333334|175.20466666666664|\n",
      "|2016-01-01 08| 756.7946666666667|177.70766666666665|\n",
      "|2016-01-01 09| 821.0078333333332|197.10816666666665|\n",
      "|2016-01-01 10| 876.7158333333333|221.21666666666667|\n",
      "|2016-01-01 11| 948.4540000000001|          238.8455|\n",
      "|2016-01-01 12| 971.0126666666666|252.04816666666667|\n",
      "|2016-01-01 13| 996.5504999999999|261.66316666666665|\n",
      "|2016-01-01 14| 995.3193333333334| 267.0518333333333|\n",
      "|2016-01-01 15|1002.3786666666666|279.30649999999997|\n",
      "|2016-01-01 16|1010.3699999999999|287.18683333333337|\n",
      "|2016-01-01 17|          1033.005| 279.1076666666667|\n",
      "|2016-01-01 18|1188.4233333333334| 263.7861666666667|\n",
      "|2016-01-01 19|1478.9833333333333|274.95633333333336|\n",
      "|2016-01-01 20|1545.6049999999998|          260.4195|\n",
      "|2016-01-01 21|1530.3500000000001| 257.8671666666666|\n",
      "|2016-01-01 22|1409.9350000000002|237.84983333333335|\n",
      "|2016-01-01 23|1228.8816666666664|217.44949999999997|\n",
      "+-------------+------------------+------------------+\n",
      "only showing top 24 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hourly_df.show(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22832"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many hourly lectures?\n",
    "hourly_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# daily_df aggregates by average on the timestamp substring up to the days\n",
    "daily_df = spark.sql('select substring(timestamp, 1, 10) as timestamp, \\\n",
    "                             avg(kw) as kw, \\\n",
    "                             avg(kvar) as kvar \\\n",
    "                      from df2_view group by substring(timestamp, 1, 10) \\\n",
    "                      order by substring(timestamp, 1, 10)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(timestamp='2016-01-01', kw=1086.3713125000004, kvar=233.3143680555556),\n",
       " Row(timestamp='2016-01-02', kw=1200.5221527777771, kvar=300.293076388889),\n",
       " Row(timestamp='2016-01-03', kw=1221.886097222223, kvar=301.4926458333335),\n",
       " Row(timestamp='2016-01-04', kw=1305.6660486111114, kvar=330.3745347222223),\n",
       " Row(timestamp='2016-01-05', kw=1288.524930555556, kvar=299.83156249999996)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(timestamp='2018-08-05', kw=560.1146666666665, kvar=134.8094097222222),\n",
       " Row(timestamp='2018-08-06', kw=583.6787013888888, kvar=125.56082638888898),\n",
       " Row(timestamp='2018-08-07', kw=507.14459027777804, kvar=101.7959097222222),\n",
       " Row(timestamp='2018-08-08', kw=585.0994791666665, kvar=131.99879861111114),\n",
       " Row(timestamp='2018-08-09', kw=515.6958571428573, kvar=120.03050793650792)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "952"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many daily lectures?\n",
    "daily_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: trim this dataset to 2018-07-31 23:50:00 to adjust lenght to entire months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: save the dataset to 952 folders named after the date"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
