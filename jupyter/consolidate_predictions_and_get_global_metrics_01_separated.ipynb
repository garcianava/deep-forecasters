{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## consolidate predictions detail and get global metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# symmetric mean absolute percentage error\n",
    "def symmetric_mean_absolute_percentage_error(targets, predictions):\n",
    "    '''\n",
    "    predictions: a list with the predicted values\n",
    "    targets: a list with the actual values\n",
    "    '''\n",
    "    import numpy as np\n",
    "    # lists to NumPy arrays\n",
    "    targets, predictions = np.array(targets), np.array(predictions)\n",
    "    # verify predictions and targets have the same shape\n",
    "    if predictions.shape == targets.shape:\n",
    "            return(np.sum(2*np.abs(predictions - targets) /\n",
    "                          (np.abs(targets) + np.abs(predictions)))/predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = '/home/developer/gcp/cbidmltsf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# during batch prediction, the model identifier is obtained via Abseil Flags\n",
    "# remember this notebook is based on local execution,\n",
    "# therefore model directory must be downloaded from GS before running the notebook\n",
    "model_id = 'BSCTRFM_TPU_021'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# during batch prediction, the SLDB identifier is obtained via Abseil Flags\n",
    "# THE SLDB FOR INFERENCE MUST BE THE SAME USED FOR TRAINING! (THE ONE SETUP IN THE CONFIGURATION FILE)\n",
    "sldb_id = 'LD2011-2014_SEPARATED_MT_320-MT_330_BSCTRFM_168_168_07DB_MMX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# during batch prediction, the dataset name is obtained via Abseil Flags\n",
    "dataset = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a forecast window to guide the iterative prediction process\n",
    "# start with a hourly, day-ahead process\n",
    "forecast_window = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD AN INFERENCE IDENTIFIER, BECAUSE FOR TRANSFORMER-BASED MODELS, DIFFERENT INFERENCES\n",
    "# CAN BE PRODUCED FROM A SINGLE SAVED MODEL (USUALLY TO PRODUCE DIFFERENT FORECAST WINDOWS)\n",
    "# during batch prediction, the inference identifier should be obtained via Abseil Flags\n",
    "inference = '{:03d}'.format(forecast_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a path to the SLDB json file\n",
    "data_dir = '{}/{}/{}'.format(PROJECT_ROOT, 'sldbs', sldb_id)\n",
    "\n",
    "# then get the ts_identifier from the json file in the sldb directory\n",
    "sldb_json_file = '{}/sldb.json'.format(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the json file\n",
    "with open(sldb_json_file, 'r') as inputfile:\n",
    "    sldb_dict = json.load(inputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LD2011-2014_SEPARATED_MT_320-MT_330'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and get the time series identifier\n",
    "ts_identifier = sldb_dict['ts']\n",
    "ts_identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the SLDB parameters for the forecasting model\n",
    "config_json_file = '{}/{}/{}.json'.format(PROJECT_ROOT,\n",
    "                                          'parameters',\n",
    "                                          model_id)\n",
    "\n",
    "# recover the sldb dictionary from the json file in parameters/\n",
    "with open(config_json_file, 'r') as inputfile:\n",
    "    configuration = json.load(inputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = sldb_dict['embedding']['hourly']\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = sldb_dict['no_targets']\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('BSCTRFM_TPU_021', 'test', '024')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify the values of the variables for batch inference\n",
    "model_id, dataset, inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load predictions detail dataframes from the database directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a list with customer_ids\n",
    "start, end = 320, 330\n",
    "\n",
    "customer_ids = ['MT_{:03d}'.format(token_id) for token_id in np.arange(start, end + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all available saved models from the model_id, execution combinations\n",
    "saved_models = os.listdir('{}/models/{}_{:02d}/export/exporter'.format(PROJECT_ROOT, model_id, execution))\n",
    "\n",
    "# sort the list\n",
    "saved_models.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1633995397', '1633995589', '1633995770', '1633995965', '1633996143']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary to load predictions detail into, use saved models as primary keys\n",
    "predictions_detail = dict()\n",
    "\n",
    "for saved_model in saved_models:\n",
    "    predictions_detail[saved_model] = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded predictions from 1633995397 saved model over MT_320 event 00\n",
      "Loaded predictions from 1633995397 saved model over MT_321 event 00\n",
      "Loaded predictions from 1633995397 saved model over MT_322 event 00\n",
      "Loaded predictions from 1633995397 saved model over MT_323 event 00\n",
      "Loaded predictions from 1633995397 saved model over MT_324 event 00\n",
      "Loaded predictions from 1633995397 saved model over MT_325 event 00\n",
      "Loaded predictions from 1633995397 saved model over MT_326 event 00\n",
      "Loaded predictions from 1633995397 saved model over MT_327 event 00\n",
      "Loaded predictions from 1633995397 saved model over MT_328 event 00\n",
      "Loaded predictions from 1633995397 saved model over MT_329 event 00\n",
      "Loaded predictions from 1633995397 saved model over MT_330 event 00\n",
      "Loaded predictions from 1633995589 saved model over MT_320 event 00\n",
      "Loaded predictions from 1633995589 saved model over MT_321 event 00\n",
      "Loaded predictions from 1633995589 saved model over MT_322 event 00\n",
      "Loaded predictions from 1633995589 saved model over MT_323 event 00\n",
      "Loaded predictions from 1633995589 saved model over MT_324 event 00\n",
      "Loaded predictions from 1633995589 saved model over MT_325 event 00\n",
      "Loaded predictions from 1633995589 saved model over MT_326 event 00\n",
      "Loaded predictions from 1633995589 saved model over MT_327 event 00\n",
      "Loaded predictions from 1633995589 saved model over MT_328 event 00\n",
      "Loaded predictions from 1633995589 saved model over MT_329 event 00\n",
      "Loaded predictions from 1633995589 saved model over MT_330 event 00\n",
      "Loaded predictions from 1633995770 saved model over MT_320 event 00\n",
      "Loaded predictions from 1633995770 saved model over MT_321 event 00\n",
      "Loaded predictions from 1633995770 saved model over MT_322 event 00\n",
      "Loaded predictions from 1633995770 saved model over MT_323 event 00\n",
      "Loaded predictions from 1633995770 saved model over MT_324 event 00\n",
      "Loaded predictions from 1633995770 saved model over MT_325 event 00\n",
      "Loaded predictions from 1633995770 saved model over MT_326 event 00\n",
      "Loaded predictions from 1633995770 saved model over MT_327 event 00\n",
      "Loaded predictions from 1633995770 saved model over MT_328 event 00\n",
      "Loaded predictions from 1633995770 saved model over MT_329 event 00\n",
      "Loaded predictions from 1633995770 saved model over MT_330 event 00\n",
      "Loaded predictions from 1633995965 saved model over MT_320 event 00\n",
      "Loaded predictions from 1633995965 saved model over MT_321 event 00\n",
      "Loaded predictions from 1633995965 saved model over MT_322 event 00\n",
      "Loaded predictions from 1633995965 saved model over MT_323 event 00\n",
      "Loaded predictions from 1633995965 saved model over MT_324 event 00\n",
      "Loaded predictions from 1633995965 saved model over MT_325 event 00\n",
      "Loaded predictions from 1633995965 saved model over MT_326 event 00\n",
      "Loaded predictions from 1633995965 saved model over MT_327 event 00\n",
      "Loaded predictions from 1633995965 saved model over MT_328 event 00\n",
      "Loaded predictions from 1633995965 saved model over MT_329 event 00\n",
      "Loaded predictions from 1633995965 saved model over MT_330 event 00\n",
      "Loaded predictions from 1633996143 saved model over MT_320 event 00\n",
      "Loaded predictions from 1633996143 saved model over MT_321 event 00\n",
      "Loaded predictions from 1633996143 saved model over MT_322 event 00\n",
      "Loaded predictions from 1633996143 saved model over MT_323 event 00\n",
      "Loaded predictions from 1633996143 saved model over MT_324 event 00\n",
      "Loaded predictions from 1633996143 saved model over MT_325 event 00\n",
      "Loaded predictions from 1633996143 saved model over MT_326 event 00\n",
      "Loaded predictions from 1633996143 saved model over MT_327 event 00\n",
      "Loaded predictions from 1633996143 saved model over MT_328 event 00\n",
      "Loaded predictions from 1633996143 saved model over MT_329 event 00\n",
      "Loaded predictions from 1633996143 saved model over MT_330 event 00\n"
     ]
    }
   ],
   "source": [
    "# iterate on saved_models and customer_ids to load all predictions detail dataframes\n",
    "for saved_model in saved_models:\n",
    "    for customer_id in customer_ids:\n",
    "        detail_pickle_path = '{}/{}/{}/{}_{:02d}_{}_{}_{}_{:02d}.pkl'.format(\n",
    "            PROJECT_ROOT,\n",
    "            'database',\n",
    "            'predictions_detail',\n",
    "            model_id,\n",
    "            execution,\n",
    "            saved_model,\n",
    "            # for electricity dataset, replace dataset with customer_id\n",
    "            customer_id,\n",
    "            inference,\n",
    "            event)\n",
    "\n",
    "        predictions_detail[saved_model][customer_id] = pd.read_pickle(detail_pickle_path)\n",
    "        print('Loaded predictions from {} saved model over {} event {:02d}'.format(saved_model,\n",
    "                                                                               customer_id,\n",
    "                                                                               event))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get a global, unique value for ND and NRSME for the 7 days in the test dataset,\n",
    "# from a single saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting timestamps to predict over a complete day\n",
    "start_row_ids = [0, 24, 48, 72, 96, 120, 144]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dictionary to manage global predictions dataframes, by saved model\n",
    "summary = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for saved_model in saved_models:\n",
    "    \n",
    "    summary[saved_model] = pd.DataFrame(\n",
    "        columns=['saved_model', 'customer_id', 'timestamp', 'prediction', 'target'])\n",
    "    \n",
    "    for customer_id in customer_ids:\n",
    "\n",
    "        # for each customer, iterate on starting rows for each day\n",
    "        for start_row_id in start_row_ids:\n",
    "            # make a buffer dataframe for one-day predictions\n",
    "            buffer_df = pd.DataFrame()\n",
    "\n",
    "            # populate the buffer dataframe\n",
    "\n",
    "            # build a 24-time repeated list for the saved_model column\n",
    "            buffer_df['saved_model'] = 24*[saved_model]\n",
    "\n",
    "            # build a 24-time repeated list for the customer_id column\n",
    "            buffer_df['customer_id'] = 24*[customer_id]\n",
    "            # remember that predictions_detail dataframe stores lists,\n",
    "            # then the index required to retrieve the list contents is the row index (find out why, later...)\n",
    "            buffer_df['timestamp'] = pd.to_datetime(\n",
    "                predictions_detail[saved_model][customer_id]['string_timestamps'][start_row_id:start_row_id+1][start_row_id]\n",
    "            )\n",
    "            buffer_df['prediction'] = \\\n",
    "                predictions_detail[saved_model][customer_id]['predictions'][start_row_id:start_row_id+1][start_row_id]\n",
    "\n",
    "            buffer_df['target'] = \\\n",
    "                predictions_detail[saved_model][customer_id]['targets'][start_row_id:start_row_id+1][start_row_id]\n",
    "\n",
    "            # buffer_df = buffer_df.set_index('timestamp')\n",
    "\n",
    "            summary[saved_model] = pd.concat([summary[saved_model], buffer_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### over the 7 days of the test dataset, daily forecasting windows, starting at midnight (2014-09-0X 00:00:00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 1633995397: ND 0.07484296127067461 NRMSE 0.1583037843628051 SMAPE 0.06507185802244647\n",
      "For 1633995589: ND 0.06471731266358517 NRMSE 0.1363525991052468 SMAPE 0.06083652014707437\n",
      "For 1633995770: ND 0.07326104517228291 NRMSE 0.15251369089598868 SMAPE 0.0675747892241711\n",
      "For 1633995965: ND 0.07488216190979485 NRMSE 0.15431331374334814 SMAPE 0.07127139097970446\n",
      "For 1633996143: ND 0.07729011302015971 NRMSE 0.1583506110288202 SMAPE 0.0719994150362771\n"
     ]
    }
   ],
   "source": [
    "for saved_model in saved_models:\n",
    "    mae = mean_absolute_error(summary[saved_model]['prediction'], summary[saved_model]['target'])\n",
    "    true_values_average = np.mean(summary[saved_model]['target'])\n",
    "    nd = mae/true_values_average\n",
    "    rmse = sqrt(mean_squared_error(summary[saved_model]['prediction'], summary[saved_model]['target']))\n",
    "    nrmse = rmse/true_values_average\n",
    "    # ToDo: adjust the function to naming convention in other metric functions\n",
    "    smape = symmetric_mean_absolute_percentage_error(\n",
    "        summary[saved_model]['prediction'], summary[saved_model]['target'])\n",
    "    \n",
    "    print('For {}: ND {} NRMSE {} SMAPE {}'.format(saved_model, nd, nrmse, smape))\n",
    "    \n",
    "# BSCTRFM_TPU_021_00\n",
    "# pos encoding 7-D (B) (age, hour-of-day, day-of-week)\n",
    "# d_model = 256\n",
    "# scaler MinMax\n",
    "# base_learning_rate = 0.00250\n",
    "# 10, 20, 30, 40, 50 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 1633965741: ND 0.06156267478797082 NRMSE 0.1289781077508348 SMAPE 0.06422151281136641\n",
      "For 1633965933: ND 0.07697785753365227 NRMSE 0.15092006319443982 SMAPE 0.07943247518617652\n",
      "For 1633966116: ND 0.0877389815836313 NRMSE 0.17053787392683492 SMAPE 0.0883111652444393\n",
      "For 1633966307: ND 0.08962859261778565 NRMSE 0.17454572322578543 SMAPE 0.09124919544884065\n",
      "For 1633966487: ND 0.09512947614911729 NRMSE 0.18250538380550954 SMAPE 0.09408561453714227\n"
     ]
    }
   ],
   "source": [
    "for saved_model in saved_models:\n",
    "    mae = mean_absolute_error(summary[saved_model]['prediction'], summary[saved_model]['target'])\n",
    "    true_values_average = np.mean(summary[saved_model]['target'])\n",
    "    nd = mae/true_values_average\n",
    "    rmse = sqrt(mean_squared_error(summary[saved_model]['prediction'], summary[saved_model]['target']))\n",
    "    nrmse = rmse/true_values_average\n",
    "    # ToDo: adjust the function to naming convention in other metric functions\n",
    "    smape = symmetric_mean_absolute_percentage_error(\n",
    "        summary[saved_model]['prediction'], summary[saved_model]['target'])\n",
    "    \n",
    "    print('For {}: ND {} NRMSE {} SMAPE {}'.format(saved_model, nd, nrmse, smape))\n",
    "    \n",
    "# BSCTRFM_TPU_020_00\n",
    "# pos encoding 7-D (A) (hour-of-day, day-of-week, day-of-year)\n",
    "# d_model = 256\n",
    "# scaler MinMax\n",
    "# base_learning_rate = 0.00250\n",
    "# 10, 20, 30, 40, 50 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 1633866439: ND 0.15985262313005602 NRMSE 0.3000182473019328 SMAPE 0.18693156145690695\n",
      "For 1633866672: ND 0.1587508481301783 NRMSE 0.29904159843923855 SMAPE 0.18639390111785156\n",
      "For 1633866885: ND 0.15925643548480703 NRMSE 0.3003315165142588 SMAPE 0.18650515084476996\n",
      "For 1633867090: ND 0.1594465960781185 NRMSE 0.3000147902470114 SMAPE 0.18663029155234018\n",
      "For 1633867289: ND 0.1591792981771819 NRMSE 0.299726724167925 SMAPE 0.18656579880701007\n"
     ]
    }
   ],
   "source": [
    "for saved_model in saved_models:\n",
    "    mae = mean_absolute_error(summary[saved_model]['prediction'], summary[saved_model]['target'])\n",
    "    true_values_average = np.mean(summary[saved_model]['target'])\n",
    "    nd = mae/true_values_average\n",
    "    rmse = sqrt(mean_squared_error(summary[saved_model]['prediction'], summary[saved_model]['target']))\n",
    "    nrmse = rmse/true_values_average\n",
    "    # ToDo: adjust the function to naming convention in other metric functions\n",
    "    smape = symmetric_mean_absolute_percentage_error(\n",
    "        summary[saved_model]['prediction'], summary[saved_model]['target'])\n",
    "    \n",
    "    print('For {}: ND {} NRMSE {} SMAPE {}'.format(saved_model, nd, nrmse, smape))\n",
    "    \n",
    "# BSCTRFM_TPU_019_00\n",
    "# d_model = 256\n",
    "# pos encoding 11-D (age, hour-of-day, day-of-week, day-of-month, day-of-year)\n",
    "# scaler Standard\n",
    "# base_learning_rate = 0.00250\n",
    "# 20, 40, 60, 80, 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 1633702824: ND 0.0955685046522273 NRMSE 0.2124706560386861 SMAPE 0.08539946691424563\n",
      "For 1633703035: ND 0.09666513709062684 NRMSE 0.21353028669336147 SMAPE 0.08713840624908574\n",
      "For 1633703239: ND 0.09251758831339751 NRMSE 0.1998163642227151 SMAPE 0.08430812133642535\n",
      "For 1633703442: ND 0.09358557458156151 NRMSE 0.20535866916626308 SMAPE 0.08440183695615831\n",
      "For 1633703649: ND 0.09164572499476527 NRMSE 0.1955614999164243 SMAPE 0.08218987608043318\n"
     ]
    }
   ],
   "source": [
    "for saved_model in saved_models:\n",
    "    mae = mean_absolute_error(summary[saved_model]['prediction'], summary[saved_model]['target'])\n",
    "    true_values_average = np.mean(summary[saved_model]['target'])\n",
    "    nd = mae/true_values_average\n",
    "    rmse = sqrt(mean_squared_error(summary[saved_model]['prediction'], summary[saved_model]['target']))\n",
    "    nrmse = rmse/true_values_average\n",
    "    # ToDo: adjust the function to naming convention in other metric functions\n",
    "    smape = symmetric_mean_absolute_percentage_error(\n",
    "        summary[saved_model]['prediction'], summary[saved_model]['target'])\n",
    "    \n",
    "    print('For {}: ND {} NRMSE {} SMAPE {}'.format(saved_model, nd, nrmse, smape))\n",
    "    \n",
    "# BSCTRFM_TPU_018_01\n",
    "# pos encoding 11-D (age, hour-of-day, day-of-week, day-of-month, day-of-year)\n",
    "# d_model = 256\n",
    "# scaler MinMax\n",
    "# base_learning_rate = 0.00250\n",
    "# 20, 40, 60, 80, 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 1633701798: ND 0.0941519998088359 NRMSE 0.19424650703835225 SMAPE 0.08430341009566043\n",
      "For 1633702002: ND 0.09750998147935375 NRMSE 0.1959272821139588 SMAPE 0.08764841440694712\n",
      "For 1633702207: ND 0.09548022028712001 NRMSE 0.19556656884903484 SMAPE 0.08468963750948486\n",
      "For 1633702423: ND 0.09896150024850345 NRMSE 0.1985769558610708 SMAPE 0.08789245902112117\n",
      "For 1633702633: ND 0.09652474413864003 NRMSE 0.19616918847708367 SMAPE 0.08530757772254514\n"
     ]
    }
   ],
   "source": [
    "for saved_model in saved_models:\n",
    "    mae = mean_absolute_error(summary[saved_model]['prediction'], summary[saved_model]['target'])\n",
    "    true_values_average = np.mean(summary[saved_model]['target'])\n",
    "    nd = mae/true_values_average\n",
    "    rmse = sqrt(mean_squared_error(summary[saved_model]['prediction'], summary[saved_model]['target']))\n",
    "    nrmse = rmse/true_values_average\n",
    "    # ToDo: adjust the function to naming convention in other metric functions\n",
    "    smape = symmetric_mean_absolute_percentage_error(\n",
    "        summary[saved_model]['prediction'], summary[saved_model]['target'])\n",
    "    \n",
    "    print('For {}: ND {} NRMSE {} SMAPE {}'.format(saved_model, nd, nrmse, smape))\n",
    "    \n",
    "# BSCTRFM_TPU_018_00\n",
    "# pos encoding 11-D (age, hour-of-day, day-of-week, day-of-month, day-of-year)\n",
    "# d_model = 256\n",
    "# scaler MinMax\n",
    "# base_learning_rate = 0.00250\n",
    "# 20, 40, 60, 80, 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 1633532109: ND 0.08391968908023607 NRMSE 0.17308211279928934 SMAPE 0.08098911367533751\n",
      "For 1633532387: ND 0.08247158391330808 NRMSE 0.17175445896947505 SMAPE 0.07789510358854744\n",
      "For 1633532611: ND 0.08373632470080083 NRMSE 0.1757226438318765 SMAPE 0.07659722293803967\n",
      "For 1633532845: ND 0.08943910885790138 NRMSE 0.18770457151282385 SMAPE 0.07845570142924825\n",
      "For 1633533083: ND 0.08563218078525504 NRMSE 0.1809419067948103 SMAPE 0.07538160878360324\n"
     ]
    }
   ],
   "source": [
    "for saved_model in saved_models:\n",
    "    mae = mean_absolute_error(summary[saved_model]['prediction'], summary[saved_model]['target'])\n",
    "    true_values_average = np.mean(summary[saved_model]['target'])\n",
    "    nd = mae/true_values_average\n",
    "    rmse = sqrt(mean_squared_error(summary[saved_model]['prediction'], summary[saved_model]['target']))\n",
    "    nrmse = rmse/true_values_average\n",
    "    # ToDo: adjust the function to naming convention in other metric functions\n",
    "    smape = symmetric_mean_absolute_percentage_error(\n",
    "        summary[saved_model]['prediction'], summary[saved_model]['target'])\n",
    "    \n",
    "    print('For {}: ND {} NRMSE {} SMAPE {}'.format(saved_model, nd, nrmse, smape))\n",
    "    \n",
    "# BSCTRFM_TPU_017_00\n",
    "# pos encoding 9-D (hour-of-day, day-of-week, day-of-month, day-of-year)\n",
    "# d_model = 512\n",
    "# scaler MinMax\n",
    "# base_learning_rate = 0.00125\n",
    "# 20, 40, 60, 80, 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 1633530953: ND 0.08341669712207045 NRMSE 0.16672929151702992 SMAPE 0.08262868805490758\n",
      "For 1633531183: ND 0.07944599314612216 NRMSE 0.16264175093007396 SMAPE 0.07736881092321744\n",
      "For 1633531426: ND 0.07898689855531715 NRMSE 0.16146557623058522 SMAPE 0.0781048874007399\n",
      "For 1633531652: ND 0.08532505922027828 NRMSE 0.1738145026053602 SMAPE 0.07989042103000737\n",
      "For 1633531877: ND 0.08225182547980808 NRMSE 0.16825302801119876 SMAPE 0.07867756105630087\n"
     ]
    }
   ],
   "source": [
    "for saved_model in saved_models:\n",
    "    mae = mean_absolute_error(summary[saved_model]['prediction'], summary[saved_model]['target'])\n",
    "    true_values_average = np.mean(summary[saved_model]['target'])\n",
    "    nd = mae/true_values_average\n",
    "    rmse = sqrt(mean_squared_error(summary[saved_model]['prediction'], summary[saved_model]['target']))\n",
    "    nrmse = rmse/true_values_average\n",
    "    # ToDo: adjust the function to naming convention in other metric functions\n",
    "    smape = symmetric_mean_absolute_percentage_error(\n",
    "        summary[saved_model]['prediction'], summary[saved_model]['target'])\n",
    "    \n",
    "    print('For {}: ND {} NRMSE {} SMAPE {}'.format(saved_model, nd, nrmse, smape))\n",
    "\n",
    "# BSCTRFM_TPU_016_00\n",
    "# pos encoding 9-D (hour-of-day, day-of-week, day-of-month, day-of-year)\n",
    "# d_model = 512\n",
    "# scaler MinMax\n",
    "# base_learning_rate = 0.00250\n",
    "# 20, 40, 60, 80, 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 1633474201: ND 0.07375831660536315 NRMSE 0.15230470970086646 SMAPE 0.07137588257117915\n",
      "For 1633474404: ND 0.07895120337066364 NRMSE 0.16923699614029766 SMAPE 0.0714609550542299\n",
      "For 1633474605: ND 0.08218558863158312 NRMSE 0.17675654988116618 SMAPE 0.07256537008866383\n",
      "For 1633474816: ND 0.08300970968684897 NRMSE 0.17948334228814225 SMAPE 0.07250197376985855\n",
      "For 1633475020: ND 0.08001419853662056 NRMSE 0.17538226051637926 SMAPE 0.07126670351220397\n",
      "For 1633475219: ND 0.07982681697878112 NRMSE 0.17475582968455947 SMAPE 0.07032845461160454\n",
      "For 1633475426: ND 0.08008514367999972 NRMSE 0.17473123265209445 SMAPE 0.06960701521577986\n",
      "For 1633475628: ND 0.08292089939378991 NRMSE 0.1840270460315019 SMAPE 0.07026546935420891\n",
      "For 1633475832: ND 0.08265426789303487 NRMSE 0.17979784469048696 SMAPE 0.07169182791765653\n",
      "For 1633476036: ND 0.08401720637508019 NRMSE 0.18601580742665286 SMAPE 0.0706546648203347\n"
     ]
    }
   ],
   "source": [
    "for saved_model in saved_models:\n",
    "    mae = mean_absolute_error(summary[saved_model]['prediction'], summary[saved_model]['target'])\n",
    "    true_values_average = np.mean(summary[saved_model]['target'])\n",
    "    nd = mae/true_values_average\n",
    "    rmse = sqrt(mean_squared_error(summary[saved_model]['prediction'], summary[saved_model]['target']))\n",
    "    nrmse = rmse/true_values_average\n",
    "    # ToDo: adjust the function to naming convention in other metric functions\n",
    "    smape = symmetric_mean_absolute_percentage_error(\n",
    "        summary[saved_model]['prediction'], summary[saved_model]['target'])\n",
    "    \n",
    "    print('For {}: ND {} NRMSE {} SMAPE {}'.format(saved_model, nd, nrmse, smape))\n",
    "\n",
    "# BSCTRFM_TPU_015_02\n",
    "# pos encoding 9-D (hour-of-day, day-of-week, day-of-month, day-of-year)\n",
    "# d_model = 256\n",
    "# scaler MinMax\n",
    "# base_learning_rate = 0.00250\n",
    "# 20, 40, 60, 80, 100, 120, 140, 160, 200 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 1633196871: ND 0.08412829704166151 NRMSE 0.17959798252230771 SMAPE 0.08071277302305699\n",
      "For 1633197126: ND 0.08178093963423284 NRMSE 0.17079970153772212 SMAPE 0.07781654540046554\n",
      "For 1633197345: ND 0.08265768871755412 NRMSE 0.18418564602796936 SMAPE 0.0764088103296674\n",
      "For 1633197575: ND 0.07746174995853501 NRMSE 0.16554976676107486 SMAPE 0.0746029714810412\n",
      "For 1633197797: ND 0.07678363903143116 NRMSE 0.15833885384093913 SMAPE 0.07427194099791928\n",
      "For 1633198016: ND 0.08012344564720517 NRMSE 0.1678176502012755 SMAPE 0.07584769045565051\n",
      "For 1633198227: ND 0.08236143555660547 NRMSE 0.1720318129905628 SMAPE 0.07529189986950587\n",
      "For 1633198439: ND 0.07895855667595755 NRMSE 0.1619844851494527 SMAPE 0.07387324516995354\n",
      "For 1633198645: ND 0.08111112175667977 NRMSE 0.1665733658166654 SMAPE 0.07406590245136283\n",
      "For 1633198846: ND 0.07947216189815492 NRMSE 0.16195942604251842 SMAPE 0.07333527973799918\n"
     ]
    }
   ],
   "source": [
    "for saved_model in saved_models:\n",
    "    mae = mean_absolute_error(summary[saved_model]['prediction'], summary[saved_model]['target'])\n",
    "    true_values_average = np.mean(summary[saved_model]['target'])\n",
    "    nd = mae/true_values_average\n",
    "    rmse = sqrt(mean_squared_error(summary[saved_model]['prediction'], summary[saved_model]['target']))\n",
    "    nrmse = rmse/true_values_average\n",
    "    # ToDo: adjust the function to naming convention in other metric functions\n",
    "    smape = symmetric_mean_absolute_percentage_error(\n",
    "        summary[saved_model]['prediction'], summary[saved_model]['target'])\n",
    "    \n",
    "    print('For {}: ND {} NRMSE {} SMAPE {}'.format(saved_model, nd, nrmse, smape))\n",
    "\n",
    "# BSCTRFM_TPU_015_00\n",
    "# pos encoding 9-D (hour-of-day, day-of-week, day-of-month, day-of-year)\n",
    "# d_model = 256\n",
    "# scaler MinMax\n",
    "# base_learning_rate = 0.00250\n",
    "# 20, 40, 60, 80, 100, 120, 140, 160, 200 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
