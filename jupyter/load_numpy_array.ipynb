{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve data sets from data arrays path\n",
    "Xadj_train = np.load('../data/arrays/Xadj_train.npy')\n",
    "y_train = np.load('../data/arrays/y_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8995, 24, 1), (8995, 168))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xadj_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train array keeps 168 possible targets, one for each hour in the week\n",
    "# get only targets for the first model (first-step-ahead)\n",
    "n = 0\n",
    "ytarget_train = y_train[:,n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required for input_fn's\n",
    "ytarget_train = ytarget_train.reshape(ytarget_train.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8995, 24, 1), (8995, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xadj_train.shape, ytarget_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: verify if labels can be declared as a Feature, as done with the feature vector\n",
    "# later, now just run with the previous, working code\n",
    "# def train_input_fn():\n",
    "#     dataset = (\n",
    "#         tf.data.Dataset.from_tensor_slices(\n",
    "#             (\n",
    "#                 {\n",
    "#                     'adjacent_hours': tf.cast(Xadj_train, tf.float32),\n",
    "#                     'labels': tf.cast(ytarget_train, tf.float32) \n",
    "#                 }\n",
    "#             )\n",
    "#         )\n",
    "#     )\n",
    "#     dataset = dataset.shuffle(buffer_size=9000).repeat(count=1).batch(batch_size=32)    \n",
    "#     return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn():\n",
    "    dataset = (\n",
    "        tf.data.Dataset.from_tensor_slices(\n",
    "            (\n",
    "                {\n",
    "                    'adjacent_hours': tf.cast(Xadj_train, tf.float32)\n",
    "                },\n",
    "                tf.cast(ytarget_train, tf.float32)\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    dataset = dataset.shuffle(buffer_size=9000).repeat(count=1).batch(batch_size=32)    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: (?, 24, 1), types: tf.float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_fn().map(lambda features, labels: features['adjacent_hours'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the dataset to a variable, then try to save it in TFRecord file format\n",
    "dataset = train_input_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ({adjacent_hours: (?, 24, 1)}, (?, 1)), types: ({adjacent_hours: tf.float32}, tf.float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset is ready to be saved into a TFRecord file\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _float_feature(value):\n",
    "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.FloatList(value=[value]) requires a list with the targets on the inner value\n",
    "# verify NumPy array to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.58097166],\n",
       "       [0.62753036],\n",
       "       [0.66801619],\n",
       "       [0.65384615],\n",
       "       [0.67611336],\n",
       "       [0.74089069],\n",
       "       [0.68623482],\n",
       "       [0.57692308],\n",
       "       [0.55263158],\n",
       "       [0.53036437],\n",
       "       [0.58704453],\n",
       "       [0.51214575],\n",
       "       [0.46153846],\n",
       "       [0.55668016],\n",
       "       [0.62550607],\n",
       "       [0.64979757],\n",
       "       [0.63562753],\n",
       "       [0.63562753],\n",
       "       [0.50202429],\n",
       "       [0.37854251],\n",
       "       [0.36032389],\n",
       "       [0.46153846],\n",
       "       [0.47773279],\n",
       "       [0.53238866]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xadj_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5809716599190284,\n",
       " 0.6275303643724696,\n",
       " 0.6680161943319839,\n",
       " 0.6538461538461539,\n",
       " 0.6761133603238868,\n",
       " 0.7408906882591094,\n",
       " 0.6862348178137652,\n",
       " 0.576923076923077,\n",
       " 0.5526315789473685,\n",
       " 0.5303643724696356,\n",
       " 0.5870445344129555,\n",
       " 0.5121457489878541,\n",
       " 0.4615384615384615,\n",
       " 0.5566801619433198,\n",
       " 0.625506072874494,\n",
       " 0.6497975708502025,\n",
       " 0.6356275303643725,\n",
       " 0.6356275303643726,\n",
       " 0.5020242914979758,\n",
       " 0.3785425101214574,\n",
       " 0.36032388663967607,\n",
       " 0.4615384615384616,\n",
       " 0.4777327935222673,\n",
       " 0.5323886639676113]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_values = [lecture[0] for lecture in Xadj_train[0]]\n",
    "list_of_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _float_feature_from_list_of_values(list_of_values):\n",
    "  \"\"\"Returns a float_list from a list of floats / doubles.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=list_of_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float_list {\n",
       "  value: 0.5809716582298279\n",
       "  value: 0.6275303363800049\n",
       "  value: 0.6680161952972412\n",
       "  value: 0.6538461446762085\n",
       "  value: 0.6761133670806885\n",
       "  value: 0.7408906817436218\n",
       "  value: 0.6862348318099976\n",
       "  value: 0.5769230723381042\n",
       "  value: 0.5526315569877625\n",
       "  value: 0.5303643941879272\n",
       "  value: 0.5870445370674133\n",
       "  value: 0.5121457576751709\n",
       "  value: 0.4615384638309479\n",
       "  value: 0.5566801428794861\n",
       "  value: 0.6255060434341431\n",
       "  value: 0.6497975587844849\n",
       "  value: 0.6356275081634521\n",
       "  value: 0.6356275081634521\n",
       "  value: 0.5020242929458618\n",
       "  value: 0.3785425126552582\n",
       "  value: 0.36032387614250183\n",
       "  value: 0.4615384638309479\n",
       "  value: 0.4777328073978424\n",
       "  value: 0.5323886871337891\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjacent_hours = _float_feature_from_list_of_values(list_of_values)\n",
    "adjacent_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float_list {\n",
       "  value: 0.6336032152175903\n",
       "}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_float_feature(ytarget_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features {\n",
      "  feature {\n",
      "    key: \"adjacent_hours\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.5809716582298279\n",
      "        value: 0.6275303363800049\n",
      "        value: 0.6680161952972412\n",
      "        value: 0.6538461446762085\n",
      "        value: 0.6761133670806885\n",
      "        value: 0.7408906817436218\n",
      "        value: 0.6862348318099976\n",
      "        value: 0.5769230723381042\n",
      "        value: 0.5526315569877625\n",
      "        value: 0.5303643941879272\n",
      "        value: 0.5870445370674133\n",
      "        value: 0.5121457576751709\n",
      "        value: 0.4615384638309479\n",
      "        value: 0.5566801428794861\n",
      "        value: 0.6255060434341431\n",
      "        value: 0.6497975587844849\n",
      "        value: 0.6356275081634521\n",
      "        value: 0.6356275081634521\n",
      "        value: 0.5020242929458618\n",
      "        value: 0.3785425126552582\n",
      "        value: 0.36032387614250183\n",
      "        value: 0.4615384638309479\n",
      "        value: 0.4777328073978424\n",
      "        value: 0.5323886871337891\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"target\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.6336032152175903\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a TFRecord example for just the first row in the dataset\n",
    "example = tf.train.Example(\n",
    "    # features within the example\n",
    "    features=tf.train.Features(\n",
    "        # individual feature definition\n",
    "        feature={'adjacent_hours': _float_feature_from_list_of_values([lecture[0] for lecture in Xadj_train[0]]),\n",
    "                 'target': _float_feature(ytarget_train[0]),\n",
    "                }\n",
    "    )\n",
    ")\n",
    "\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\n\\x8c\\x01\\nv\\n\\x0eadjacent_hours\\x12d\\x12b\\n`\\x8f\\xba\\x14?\\xd4\\xa5 ?\\x1c\\x03+?vb\\'?\\xc4\\x15-?\\x03\\xab=?\\x16\\xad/?;\\xb1\\x13?Cy\\r?\\xf6\\xc5\\x07?\\x8dH\\x16?\\xfc\\x1b\\x03?\\xc5N\\xec>\\x97\\x82\\x0e?*! ?\"Y&?|\\xb8\"?|\\xb8\"?\\xaa\\x84\\x00?S\\xd0\\xc1>_|\\xb8>\\xc5N\\xec>e\\x99\\xf4>\\xa0J\\x08?\\n\\x12\\n\\x06target\\x12\\x08\\x12\\x06\\n\\x04\\xd23\"?'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the basic `tf.Example` (only the first row of adjacent hours training set) to a file\n",
    "with tf.io.TFRecordWriter('../data/tfrecord/first_row.tfrecord') as writer:\n",
    "    serialized_example = example.SerializeToString()\n",
    "    writer.write(serialized_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so far, so good... now try to read and recover the first row of the dataset\n",
    "# use deprecated, but functional, code found in\n",
    "# http://medium.com/mostly-ai/tensorflow-records-what-they-are-and-how-to-use-them-c46bc4bbb564"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-23-88ed4149de48>:6: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
      "WARNING:tensorflow:From <ipython-input-23-88ed4149de48>:7: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /home/developer/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/input.py:276: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /home/developer/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/input.py:188: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From /home/developer/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/input.py:197: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/developer/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/input.py:197: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From <ipython-input-23-88ed4149de48>:22: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "adjacent_hours: SparseTensorValue(indices=array([[ 0],\n",
      "       [ 1],\n",
      "       [ 2],\n",
      "       [ 3],\n",
      "       [ 4],\n",
      "       [ 5],\n",
      "       [ 6],\n",
      "       [ 7],\n",
      "       [ 8],\n",
      "       [ 9],\n",
      "       [10],\n",
      "       [11],\n",
      "       [12],\n",
      "       [13],\n",
      "       [14],\n",
      "       [15],\n",
      "       [16],\n",
      "       [17],\n",
      "       [18],\n",
      "       [19],\n",
      "       [20],\n",
      "       [21],\n",
      "       [22],\n",
      "       [23]]), values=array([0.58097166, 0.62753034, 0.6680162 , 0.65384614, 0.67611337,\n",
      "       0.7408907 , 0.68623483, 0.5769231 , 0.55263156, 0.5303644 ,\n",
      "       0.58704454, 0.51214576, 0.46153846, 0.55668014, 0.62550604,\n",
      "       0.64979756, 0.6356275 , 0.6356275 , 0.5020243 , 0.3785425 ,\n",
      "       0.36032388, 0.46153846, 0.4777328 , 0.5323887 ], dtype=float32), dense_shape=array([24]))\n",
      "target: 0.6336032152175903\n"
     ]
    }
   ],
   "source": [
    "# read and print data:\n",
    "# ToDo: the following line might need to be changed when running a script\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# read TFRecord file\n",
    "reader = tf.TFRecordReader()\n",
    "filename_queue = tf.train.string_input_producer(['../data/tfrecord/first_row.tfrecord'])\n",
    "\n",
    "_, serialized_example = reader.read(filename_queue)\n",
    "\n",
    "# define features\n",
    "read_features = {\n",
    "    'adjacent_hours': tf.VarLenFeature(dtype=tf.float32),\n",
    "    'target': tf.FixedLenFeature([], dtype=tf.float32)}\n",
    "\n",
    "# extract features from serialized data\n",
    "read_data = tf.parse_single_example(serialized=serialized_example,\n",
    "                                    features=read_features)\n",
    "\n",
    "# important! many tf.train functions use tf.train.QueueRunner,\n",
    "# so we need to start it before we read\n",
    "tf.train.start_queue_runners(sess)\n",
    "\n",
    "# Print features\n",
    "for name, tensor in read_data.items():\n",
    "    print('{}: {}'.format(name, tensor.eval()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TFRecordDataset shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now read the dataset from TFRecord file using non-deprecated methods from tf.data module\n",
    "first_row_train_raw_dataset = tf.data.TFRecordDataset('../data/tfrecord/first_row.tfrecord')\n",
    "first_row_train_raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.string"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_row_train_raw_dataset.output_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_row_train_raw_dataset.output_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\n\\x8c\\x01\\nv\\n\\x0eadjacent_hours\\x12d\\x12b\\n`\\x8f\\xba\\x14?\\xd4\\xa5 ?\\x1c\\x03+?vb\\'?\\xc4\\x15-?\\x03\\xab=?\\x16\\xad/?;\\xb1\\x13?Cy\\r?\\xf6\\xc5\\x07?\\x8dH\\x16?\\xfc\\x1b\\x03?\\xc5N\\xec>\\x97\\x82\\x0e?*! ?\"Y&?|\\xb8\"?|\\xb8\"?\\xaa\\x84\\x00?S\\xd0\\xc1>_|\\xb8>\\xc5N\\xec>e\\x99\\xf4>\\xa0J\\x08?\\n\\x12\\n\\x06target\\x12\\x08\\x12\\x06\\n\\x04\\xd23\"?'\n"
     ]
    }
   ],
   "source": [
    "# can I access to the binary, string-based, raw dataset using a one-shot iterator?\n",
    "iterator = first_row_train_raw_dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "# there is only one row in the raw dataset\n",
    "value = sess.run(next_element)\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: put more than one row in the tf.Dataset before serializing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is required to parse the recovered dataset, from string to original types and shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing operator without deprecated tr.io methods has failed, review more tutorials tomorrow..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://towardsdatascience.com/how-to-use-dataset-in-tensorflow-c758ef9e4428"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adjacent_hours': VarLenFeature(dtype=tf.float32),\n",
       " 'target': FixedLenFeature(shape=[], dtype=tf.float32, default_value=None)}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: {adjacent_hours: (?,), target: ()}, types: {adjacent_hours: tf.float32, target: tf.float32}>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _parse_dataset_function(example_proto):\n",
    "  # parse the input tf.Example proto using the dictionary above.\n",
    "  return tf.io.parse_single_example(example_proto, read_features)\n",
    "\n",
    "parsed_dataset = first_row_train_raw_dataset.map(_parse_dataset_function)\n",
    "parsed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.58097166 0.62753034 0.6680162  0.65384614 0.67611337 0.7408907\n",
      " 0.68623483 0.5769231  0.55263156 0.5303644  0.58704454 0.51214576\n",
      " 0.46153846 0.55668014 0.62550604 0.64979756 0.6356275  0.6356275\n",
      " 0.5020243  0.3785425  0.36032388 0.46153846 0.4777328  0.5323887 ] (24,)\n"
     ]
    }
   ],
   "source": [
    "iterator = parsed_dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "# there is only one row in the raw dataset\n",
    "value = sess.run(next_element)\n",
    "print(value['adjacent_hours'].values, value['adjacent_hours'].values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ({adjacent_hours: (?, 1)}, (1,)), types: ({adjacent_hours: tf.float32}, tf.float32)>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST WITH DIFFERENT PARSING FUNCTIONS\n",
    "def _parse_dataset_function(example_proto):\n",
    "    # parse the input tf.Example proto using the dictionary above\n",
    "    row = tf.io.parse_single_example(example_proto, read_features)\n",
    "    adjacent_hours = tf.reshape(row['adjacent_hours'].values, [-1, 1])\n",
    "    target = tf.reshape(row['target'], [1,])\n",
    "    \n",
    "    return ({'adjacent_hours': adjacent_hours}, target)\n",
    "    \n",
    "\n",
    "parsed_dataset = first_row_train_raw_dataset.map(_parse_dataset_function)\n",
    "parsed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'adjacent_hours': array([[0.58097166],\n",
      "       [0.62753034],\n",
      "       [0.6680162 ],\n",
      "       [0.65384614],\n",
      "       [0.67611337],\n",
      "       [0.7408907 ],\n",
      "       [0.68623483],\n",
      "       [0.5769231 ],\n",
      "       [0.55263156],\n",
      "       [0.5303644 ],\n",
      "       [0.58704454],\n",
      "       [0.51214576],\n",
      "       [0.46153846],\n",
      "       [0.55668014],\n",
      "       [0.62550604],\n",
      "       [0.64979756],\n",
      "       [0.6356275 ],\n",
      "       [0.6356275 ],\n",
      "       [0.5020243 ],\n",
      "       [0.3785425 ],\n",
      "       [0.36032388],\n",
      "       [0.46153846],\n",
      "       [0.4777328 ],\n",
      "       [0.5323887 ]], dtype=float32)}, array([0.6336032], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "iterator = parsed_dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "# there is only one row in the raw dataset\n",
    "value = sess.run(next_element)\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'adjacent_hours': TensorShape([Dimension(None)]), 'target': TensorShape([])},\n",
       " {'adjacent_hours': tf.float32, 'target': tf.float32})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_dataset = first_row_train_raw_dataset.map(lambda example_proto: tf.io.parse_single_example(example_proto,\n",
    "                                                                                 read_features))\n",
    "parsed_dataset.output_shapes, parsed_dataset.output_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.58097166 0.62753034 0.6680162  0.65384614 0.67611337 0.7408907\n",
      " 0.68623483 0.5769231  0.55263156 0.5303644  0.58704454 0.51214576\n",
      " 0.46153846 0.55668014 0.62550604 0.64979756 0.6356275  0.6356275\n",
      " 0.5020243  0.3785425  0.36032388 0.46153846 0.4777328  0.5323887 ] (24,)\n"
     ]
    }
   ],
   "source": [
    "iterator = parsed_dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "# there is only one row in the raw dataset\n",
    "value = sess.run(next_element)\n",
    "print(value['adjacent_hours'].values, value['adjacent_hours'].values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(None)]), tf.float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_dataset = first_row_train_raw_dataset.map(lambda example_proto: tf.io.parse_single_example(example_proto,\n",
    "                                                                                                  read_features)['adjacent_hours'].values)\n",
    "\n",
    "parsed_dataset.output_shapes, parsed_dataset.output_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.58097166 0.62753034 0.6680162  0.65384614 0.67611337 0.7408907\n",
      " 0.68623483 0.5769231  0.55263156 0.5303644  0.58704454 0.51214576\n",
      " 0.46153846 0.55668014 0.62550604 0.64979756 0.6356275  0.6356275\n",
      " 0.5020243  0.3785425  0.36032388 0.46153846 0.4777328  0.5323887 ] (24,)\n"
     ]
    }
   ],
   "source": [
    "iterator = parsed_dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "# there is only one row in the raw dataset\n",
    "value = sess.run(next_element)\n",
    "print(value, value.shape)\n",
    "# print(value.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_array = first_row_train_raw_dataset.map(lambda example_proto: tf.io.parse_single_example(example_proto,\n",
    "                                                                                                  read_features)['adjacent_hours'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.58097166 0.62753034 0.6680162  0.65384614 0.67611337 0.7408907\n",
      " 0.68623483 0.5769231  0.55263156 0.5303644  0.58704454 0.51214576\n",
      " 0.46153846 0.55668014 0.62550604 0.64979756 0.6356275  0.6356275\n",
      " 0.5020243  0.3785425  0.36032388 0.46153846 0.4777328  0.5323887 ] (24,)\n"
     ]
    }
   ],
   "source": [
    "iterator = parsed_array.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "# there is only one row in the raw dataset\n",
    "value = sess.run(next_element)\n",
    "print(value, value.shape)\n",
    "# print(value.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "must be str, not int",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-78b91ebc13f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparsed_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls)\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \"\"\"\n\u001b[1;32m   1037\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mParallelMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism)\u001b[0m\n\u001b[1;32m   2609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2610\u001b[0m     wrapped_func = StructuredFunctionWrapper(\n\u001b[0;32m-> 2611\u001b[0;31m         map_func, \"Dataset.map()\", input_dataset)\n\u001b[0m\u001b[1;32m   2612\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2613\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_shapes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, add_to_graph, experimental_nested_dataset_support)\u001b[0m\n\u001b[1;32m   1858\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_data_structured_function_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1859\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1861\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m       \u001b[0;31m# Use the private method that will execute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/function.py\u001b[0m in \u001b[0;36madd_to_graph\u001b[0;34m(self, g)\u001b[0m\n\u001b[1;32m    477\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;34m\"\"\"Adds this function into the graph g.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_definition_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Adds this function into 'g'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/function.py\u001b[0m in \u001b[0;36m_create_definition_if_needed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;34m\"\"\"Creates the function definition if it's not created yet.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_definition_if_needed_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_definition_if_needed_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/function.py\u001b[0m in \u001b[0;36m_create_definition_if_needed_impl\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    342\u001b[0m     temp_graph = func_graph_from_py_func(\n\u001b[1;32m    343\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_arg_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_arg_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m         self._capture_by_value, self._caller_device)\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extra_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/function.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(func, arg_names, arg_types, name, capture_by_value, device, colocation_stack, container, collections_ref, arg_shapes)\u001b[0m\n\u001b[1;32m    862\u001b[0m     \u001b[0;31m# Call func and gather the output tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 864\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m     \u001b[0;31m# There is no way of distinguishing between a function not returning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mtf_data_structured_function_wrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   1792\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1794\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1795\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1796\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-78b91ebc13f8>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(features)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparsed_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m       \u001b[0mbegin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m       \u001b[0mend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m       \u001b[0mstrides\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m       \u001b[0mshrink_axis_mask\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m<<\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: must be str, not int"
     ]
    }
   ],
   "source": [
    "parsed_dataset.map(lambda features: features['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-e4aa46c5ff22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# there is only one row in the raw dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'adjacent_hours'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'adjacent_hours'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "iterator = parsed_dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "# there is only one row in the raw dataset\n",
    "value = sess.run(next_element)\n",
    "print(value['adjacent_hours'].values, value['adjacent_hours'].values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-acf84567207b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparsed_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'adjacent_hours'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "parsed_array = value['adjacent_hours'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parsed_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-d3fa1119a35c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparsed_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'parsed_array' is not defined"
     ]
    }
   ],
   "source": [
    "parsed_array.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adjacent_hours': tf.float32, 'target': tf.float32}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_dataset.output_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adjacent_hours': TensorShape([Dimension(None)]), 'target': TensorShape([])}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_dataset.output_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so far, so good, now compare the previous result with the output of ...from_tensor_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
