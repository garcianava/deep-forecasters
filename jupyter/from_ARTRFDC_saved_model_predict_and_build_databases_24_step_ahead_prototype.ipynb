{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook for prediction and evaluation of multi-step forecasting ARTRFDC models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# uncomment the following line for compatibility with TensorFlow 1.15 (on GCP)\n",
    "# import tensorflow.compat.v1 as tf\n",
    "# uncomment the following line for TensorFlow 2.X (local execution)\n",
    "import tensorflow as tf\n",
    "\n",
    "# forecast model was saved in TensorFlow 1.15\n",
    "# but, in order to make predictions locally, has to be loaded with TensorFlow 2\n",
    "from tensorflow.saved_model import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# symmetrical mean absolute percentage error\n",
    "def smape(targets, predictions):\n",
    "    '''\n",
    "    predictions: a list with the predicted values\n",
    "    targets: a list with the actual values\n",
    "    '''\n",
    "    import numpy as np\n",
    "    # lists to NumPy arrays\n",
    "    targets, predictions = np.array(targets), np.array(predictions)\n",
    "    # verify predictions and targets have the same shape\n",
    "    if predictions.shape == targets.shape:\n",
    "            return(np.sum(2*np.abs(predictions - targets) /\n",
    "                          (np.abs(targets) + np.abs(predictions)))/predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = '/home/developer/gcp/cbidmltsf'\n",
    "\n",
    "# during batch prediction, the SLDB identifier is obtained via Abseil Flags\n",
    "sldb_id = 'CPE04115_H_kw_20201021084001_ARTRFDC_168'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a path to the SLDB json file\n",
    "data_dir = '{}/{}/{}'.format(PROJECT_ROOT, 'sldbs', sldb_id)\n",
    "\n",
    "# then get the ts_identifier from the json file in the sldb directory\n",
    "sldb_json_file = '{}/sldb.json'.format(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the json file\n",
    "with open(sldb_json_file, 'r') as inputfile:\n",
    "    sldb_dict = json.load(inputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and get the time series identifier\n",
    "ts_identifier = sldb_dict['ts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler loaded for time series CPE04115_H_kw_20201021084001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/developer/anaconda3/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.22.1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# use the time series identifier to obtain the SK-Learn scaler used on it\n",
    "scaler = joblib.load('{}/{}/{}/scaler.save'.format(PROJECT_ROOT,\n",
    "                                                    'timeseries',\n",
    "                                                    ts_identifier))\n",
    "\n",
    "print('Scaler loaded for time series {}'.format(ts_identifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code block will be imported as the _parse_dataset_function\n",
    "\n",
    "read_features = {\n",
    "    'source': tf.io.VarLenFeature(dtype=tf.float32),\n",
    "    'target': tf.io.VarLenFeature(dtype=tf.float32)\n",
    "}\n",
    "\n",
    "\n",
    "def _parse_dataset_function(example_proto, objective_shapes, parse_timestamp):\n",
    "    # parse the input tf.Example proto using the dictionary above\n",
    "    row = tf.io.parse_single_example(example_proto, read_features)\n",
    "    \n",
    "    # pass objective shape as a list of lists [hourly_shape, daily_shape, weekly_shape]\n",
    "    source = tf.reshape(row['source'].values, objective_shapes['source'])\n",
    "    target = tf.reshape(row['target'].values, objective_shapes['target'])\n",
    "\n",
    "    # the parsed dataset must have the shape {features}, target!!!\n",
    "    # so:\n",
    "    feature_dict = {\n",
    "        'source': source\n",
    "    }\n",
    "    \n",
    "    # Do not parse the timestamp for training!!! Strings are not supported in TPUs!!!,\n",
    "    # or parse it as a number\n",
    "    if parse_timestamp:\n",
    "        feature_dict['timestamp'] = timestamp\n",
    "\n",
    "    # _parse_dataset_function returns:\n",
    "    # features as a dictionary, and\n",
    "    # target as a float vector\n",
    "    return feature_dict, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass all the code to a single notebook cell, then to a function, later..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# during batch prediction, the model identifier is obtained via Abseil Flags\n",
    "model_id = 'ARTRFDC_TPU_000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# during batch prediction, the dataset name is obtained via Abseil Flags\n",
    "dataset = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# during batch prediction, the execution identifier is obtained via Abseil Flags\n",
    "execution = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use model identifier and execution number to build the model directory string\n",
    "model_dir = '{}_{:02d}'.format(model_id, execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the path to the saved model main directory\n",
    "saved_model_path = '{}/{}/{}/export/exporter'.format(PROJECT_ROOT,\n",
    "                                                     'models',\n",
    "                                                     model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the files in the saved model path, to find the most recent one\n",
    "all_files = os.listdir(saved_model_path)\n",
    "# get the path to the most recent saved model\n",
    "latest_saved_model_id = sorted(all_files)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported model path is /home/developer/gcp/cbidmltsf/models/ARTRFDC_TPU_000_00/export/exporter/1621431330\n"
     ]
    }
   ],
   "source": [
    "# build the full path for the latest saved model dir\n",
    "export_dir = '{}/{}'.format(saved_model_path, latest_saved_model_id)\n",
    "print ('Exported model path is {}'.format(export_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the saved model and the prediction function\n",
    "imported = load(export_dir=export_dir, tags='serve')\n",
    "predict_fn = imported.signatures[\"serving_default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on DMSLSTM or EDALSTM, predictions are obtained by applying the prediction function\n",
    "# directly on the TFRECORD file, over th features of the test dataset, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a path to the dataset for prediction\n",
    "dataset_path = '{}/{}.tfrecord'.format(data_dir, dataset)\n",
    "\n",
    "# load the dataset\n",
    "tfrecord_dataset = tf.data.TFRecordDataset(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list to store prediction values\n",
    "predictions_list = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow 2 eager execution allows to iterate over a dataset\n",
    "for element in tfrecord_dataset:\n",
    "    predictions_list.append(predict_fn(element))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get prediction values from predictions list\n",
    "predictions = [p['forecast'][0] for p in predictions_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2095, TensorShape([168, 1]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm the number of predictions and the tensor shape\n",
    "len(predictions), predictions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from now on, inferences for ARTRFDC are produced in a very different way\n",
    "# from the used for DMSLSTM or EDALSTM models (prediction process has to be iterative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each predicted row is a sequence of n_timesteps values,\n",
    "# but only the first element in this sequence is used, as the first prediction,\n",
    "# then it is added (along with its positional encodings) to the end of the input sequence\n",
    "# (first entry of the input sequence is discarded to keep tensor shape)\n",
    "# to get the second prediction, and so on up to the n_timesteps-th prediction,\n",
    "# which completes the n_timesteps prediction sequence (the forecast window)\n",
    "# that starts immediately after the source input sequence ends (in time dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the SLDB parameters for the forecasting model\n",
    "config_json_file = '{}/{}/{}.json'.format(PROJECT_ROOT,\n",
    "                                          'parameters',\n",
    "                                          model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recover the sldb dictionary from the json file in parameters/\n",
    "with open(config_json_file, 'r') as inputfile:\n",
    "    configuration = json.load(inputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': [168, 7], 'target': [168, 7]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the objective shapes for reshaping tensors in a dictionary\n",
    "_EXTRACTING_OBJECTIVE_SHAPES = {\n",
    "    'source': [configuration['num_timesteps'], configuration['model_dimension']],\n",
    "    'target': [configuration['num_timesteps'], configuration['model_dimension']]\n",
    "}\n",
    "\n",
    "_EXTRACTING_OBJECTIVE_SHAPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the test dataset from the TFRecord file\n",
    "# and use its features to produce predictions in a different way\n",
    "\n",
    "parsed_dataset = tfrecord_dataset.map(\n",
    "    lambda row: _parse_dataset_function(\n",
    "        example_proto=row,\n",
    "        objective_shapes=_EXTRACTING_OBJECTIVE_SHAPES,\n",
    "        # ToDo: parse the timestamps for plotting or additional positional encoding, later...\n",
    "        parse_timestamp=False\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ({source: (168, 7)}, (168, 7)), types: ({source: tf.float32}, tf.float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the iterative process for inference over the ARTRFDC saved model can be initiated now:\n",
    "# source feature (?, 168, 7) (unseen data) is on parsed_dataset[0]['source']\n",
    "# target feature (?, 168, 7) (unseen data) is on parsed_dataset[1]\n",
    "\n",
    "# uncomment and run the following two cells to confirm that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for element in parsed_dataset:\n",
    "#     print (element[0]['source'])\n",
    "\n",
    "# confirmed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for element in parsed_dataset:\n",
    "#     print (element[1])\n",
    "    \n",
    "# confirmed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is not possible to iterate over a segment of a dataset, as required by iterative inference\n",
    "# then the complete test dataset will be passed to two NumPy arrays:\n",
    "\n",
    "# source_array, with shape (n_rows, n_timesteps, n_features), in this example (2095, 168, 7), and\n",
    "# target_array, with shape (n_rows, n_timesteps, n_features), in this example (2095, 168, 7)\n",
    "\n",
    "# remember source_array[1:, :, :] = target_array[:-2, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_list = list()\n",
    "target_list = list()\n",
    "\n",
    "for element in parsed_dataset:\n",
    "    source_list.append(element[0]['source'])\n",
    "    target_list.append(element[1])\n",
    "\n",
    "source_array = np.array(source_list)\n",
    "target_array = np.array(target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2095, 168, 7), (2095, 168, 7))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify shape of resulting arrays\n",
    "source_array.shape, target_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now follow the inference process detailed in Klingenbrunn to:\n",
    "# predict over the forecast window,\n",
    "# calculate prediction error metrics, and\n",
    "# plot prediction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a forecast window to guide the iterative prediction process\n",
    "# start with a hourly, day-ahead process\n",
    "forecast_window = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first source or input to the model is the first source row\n",
    "# that means, the true variable value, plus the six positional encodings for the timestamp\n",
    "# in the first row of the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the following line to get the source as a tensor with TensorShape([1, 168, 7])\n",
    "# source_tensor = tf.expand_dims(source_array[0, :, :], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 168, 7)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in order to use the predict_fn built for TFRecords,\n",
    "# it is better to keep the source as a NumPy array\n",
    "source = source_array[:1, :, :]\n",
    "source.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break Klingenbrunn naming conventions here:\n",
    "# the forecast-window-size array with true values (1, 24, 7)\n",
    "# will not be called 'target', but 'prediction_target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: include timestamps in train, eval, and test datasets to easily keep tracking of prediction dates!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 24, 7)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the prediction target from the first row of the test dataset\n",
    "prediction_target = target_array[:1, :forecast_window, :]\n",
    "prediction_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the variable values of source and prediction_target\n",
    "# prediction_target should be equal to source, trimmed to forecast window and shifted right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.63997614, 0.6179838 , 0.61890036, 0.6585131 , 0.695615  ,\n",
       "        0.6312844 , 0.52303356, 0.40595847, 0.2784648 , 0.20911317,\n",
       "        0.15208519, 0.14222518, 0.1461949 , 0.19253159, 0.22639433,\n",
       "        0.2271737 , 0.28913516, 0.37109476, 0.4790466 , 0.6021724 ,\n",
       "        0.63034314, 0.64071214, 0.6699102 , 0.65957916]], dtype=float32)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source[:, :forecast_window, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6179838 , 0.61890036, 0.6585131 , 0.695615  , 0.6312844 ,\n",
       "        0.52303356, 0.40595847, 0.2784648 , 0.20911317, 0.15208519,\n",
       "        0.14222518, 0.1461949 , 0.19253159, 0.22639433, 0.2271737 ,\n",
       "        0.28913516, 0.37109476, 0.4790466 , 0.6021724 , 0.63034314,\n",
       "        0.64071214, 0.6699102 , 0.65957916, 0.6380292 ]], dtype=float32)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_target[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# therefore, source and prediction_target arrays are ready for inference process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# however, predict_fn from saved model signatures only works with TFRecord datasets as input!\n",
    "\n",
    "# basic question: how to get a prediction from a saved-model prediction function\n",
    "# that expects as input example protocol-buffer rows from a TFRecord dataset\n",
    "# when the data is dynamically obtained from a NumPy array???\n",
    "\n",
    "# here is the answer from the ML-pipeline specialist I have turned into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1176,)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first, flat the NumPy array to pass it to a protobuffer example\n",
    "flat_array = source.flatten()\n",
    "flat_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to encode float values for serialized examples\n",
    "def _float_feature_from_list_of_values(list_of_values):\n",
    "    \"\"\"Returns a float_list from a list of floats / doubles.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=list_of_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second, build the protobuffer example\n",
    "example = tf.train.Example(\n",
    "    # features within the example\n",
    "    features=tf.train.Features(\n",
    "        # individual feature definition\n",
    "        feature={'source': _float_feature_from_list_of_values(flat_array)\n",
    "                 # 'target': _float_feature_from_list_of_values(results[stage]['target'][row].flatten())\n",
    "                 }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third, serialize the example dictionary to a string\n",
    "serialized_example = example.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fourth, wrap the serialized example as a NumPy-string array\n",
    "numpy_example = np.array(serialized_example, dtype='S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fifth, wrap the NumPy-string array as a string tensor\n",
    "tensor_example = tf.convert_to_tensor(numpy_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 6, 1), dtype=float32, numpy=\n",
       "array([[[0.6134994 ],\n",
       "        [0.59551287],\n",
       "        [0.70238775],\n",
       "        [0.65899956],\n",
       "        [0.61110747],\n",
       "        [0.48638266]]], dtype=float32)>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we can use the prediction function from the saved model\n",
    "# on the generated tensor example, and get the prediction (1, 168, 1)\n",
    "# show only a few of the 168 timesteps\n",
    "predict_fn(tensor_example)['forecast'][:, :6, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as I said, I have turned into a serious ML-pipeline specialist (dark glasses with pixelated shine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now please code all the complicated previous stuff into an easy Python function, would you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important, the inference cycle was coded for tensors, not for NumPy arrays\n",
    "# then use source and prediction tensors and translate to tensor examples from float tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 168, 7])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# then again, build the initial source tensor\n",
    "source_tensor = tf.expand_dims(source_array[0, :, :], axis=0)\n",
    "source_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 24, 7])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and build the initial prediction tensor\n",
    "prediction_tensor = tf.expand_dims(target_array[0, :forecast_window, :], axis=0)\n",
    "prediction_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to encode float values for serialized examples\n",
    "def _float_feature_from_list_of_values(list_of_values):\n",
    "    \"\"\"Returns a float_list from a list of floats / doubles.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=list_of_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_tensor_example(float_tensor):\n",
    "    # first, pass the float tensor to NumPy array, then flatten it\n",
    "    flat_array = float_tensor.numpy().flatten()\n",
    "    # second, build the protobuffer example\n",
    "    example = tf.train.Example(\n",
    "        # features within the example\n",
    "        features=tf.train.Features(\n",
    "            # individual feature definition\n",
    "            feature={'source': _float_feature_from_list_of_values(flat_array)}\n",
    "        )\n",
    "    )    \n",
    "    # third, serialize the example dictionary to a string\n",
    "    serialized_example = example.SerializeToString()\n",
    "    # fourth, wrap the serialized example as a NumPy-string array\n",
    "    numpy_example = np.array(serialized_example, dtype='S')\n",
    "    # fifth, wrap the NumPy-string array as a string tensor\n",
    "    tensor_example = tf.convert_to_tensor(numpy_example)\n",
    "\n",
    "    return tensor_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_input_model = source_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-initialize the prediction list previously used for prediction over TFRecords\n",
    "predictions_list = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(forecast_window):\n",
    "    \n",
    "    # from the current next_input_model tensor (1, 168, 7)\n",
    "    # get a prediction as NumPy array (1, 168, 1)\n",
    "    prediction = predict_fn(tensor_to_tensor_example(next_input_model))['forecast'].numpy()\n",
    "    \n",
    "    # get the value of the most recent prediction (last timestep) into the predictions list\n",
    "    predictions_list.append(prediction[:, -1, :][0][0])\n",
    "    \n",
    "    # from the source tensor, get the positional encodings for ti+1 to t167 (that is 168-i-1 values)\n",
    "    pos_encoding_old_values = source_tensor[:, i+1:, 1:]\n",
    "\n",
    "    # from target tensor, get the positional encodings for t168 to t168+i (that is i+1 values)\n",
    "    pos_encoding_new_val = prediction_tensor[:, :i+1, 1:]\n",
    "\n",
    "    # build new positional encodings with 168 values\n",
    "    pos_encodings = tf.concat([pos_encoding_old_values, pos_encoding_new_val], axis=1)\n",
    "    pos_encodings = tf.cast(pos_encodings, dtype=tf.float32)\n",
    "\n",
    "    # build the values feature for the next input to the model\n",
    "    # pop i+1 values at the beginning of the previous input\n",
    "    value_feature_old_values = tf.expand_dims(source_tensor[:, i+1:, 0], axis=-1)\n",
    "    value_feature_old_values = tf.cast(value_feature_old_values, dtype=tf.float32)\n",
    "\n",
    "    # current predictions_list to NumPy array\n",
    "    value_feature_new_values = np.array(predictions_list[:i+1])\n",
    "\n",
    "    # current prediction array to tensor\n",
    "    value_feature_new_values = tf.convert_to_tensor(value_feature_new_values)\n",
    "\n",
    "    # expand dimensions of current prediction tensor to single-value feature\n",
    "    value_feature_new_values = tf.expand_dims(value_feature_new_values, axis=-1)\n",
    "\n",
    "    # expand dimensions of current prediction tensor to single-value batch\n",
    "    value_feature_new_values = tf.expand_dims(value_feature_new_values, axis=0)\n",
    "    \n",
    "    # build the value feature tensor\n",
    "    next_input_model = tf.concat([value_feature_old_values, value_feature_new_values], axis=1)\n",
    "    \n",
    "    # build the next input tensor for the model\n",
    "    next_input_model = tf.concat([next_input_model, pos_encodings], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.63384354, 0.3797493 , 0.3085147 , 0.27068666, 0.22977859,\n",
       "       0.19375685, 0.16552916, 0.14017448, 0.11583665, 0.10005224,\n",
       "       0.09879532, 0.10349613, 0.12018436, 0.14141637, 0.16745162,\n",
       "       0.19853613, 0.23117605, 0.25464848, 0.2710778 , 0.28217995,\n",
       "       0.28996986, 0.2943427 , 0.29726797, 0.3010141 ], dtype=float32)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iterative predictions over the forecast window reside in predictions_list\n",
    "np.array(predictions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(24,), dtype=float32, numpy=\n",
       "array([0.6179838 , 0.61890036, 0.6585131 , 0.695615  , 0.6312844 ,\n",
       "       0.52303356, 0.40595847, 0.2784648 , 0.20911317, 0.15208519,\n",
       "       0.14222518, 0.1461949 , 0.19253159, 0.22639433, 0.2271737 ,\n",
       "       0.28913516, 0.37109476, 0.4790466 , 0.6021724 , 0.63034314,\n",
       "       0.64071214, 0.6699102 , 0.65957916, 0.6380292 ], dtype=float32)>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and the true values remain in the prediction tensor\n",
    "prediction_tensor[0, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5981172323226929"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smape(prediction_tensor[0, :, 0], np.array(predictions_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
