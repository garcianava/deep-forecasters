{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing arguments for batch execution\n",
    "import argparse\n",
    "# JSON persistence\n",
    "import json\n",
    "# directory-read operations\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manage directory-read operations using Posix paths\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just a temporary workaround\n",
    "# pass this code to the setup.py file of the final module\n",
    "import sys\n",
    "_ROOT_DIR = '{0}/gcp/cbidmltsf'.format(os.getenv(\"HOME\"))\n",
    "sys.path.append(_ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dplstm.data import make_input_fn\n",
    "from dplstm.model import DPLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build parameters dictionary for interactive execution\n",
    "# in batch execution, this dictionary comes from parsed cli arguments\n",
    "\n",
    "parameters = {\n",
    "    'model_dir': 'lstm_60',\n",
    "    'learning_rate': 0.01,\n",
    "    'num_epochs': 20,  # NOT REQUIRED IN DISTRIBUTED MODE, IT IS OVERRIDDEN BY MAX_TRAIN_STEPS\n",
    "    'max_train_steps': 20000,\n",
    "    'train_batch_size': 32,\n",
    "    'eval_interval': 300,\n",
    "    'keep_checkpoint_max': 3,\n",
    "    'eval_steps': None,\n",
    "    'eval_batch_size': 2**16,\n",
    "    'start_delay_secs': 600,\n",
    "    'throttle_secs': 600,\n",
    "    'train_data_path': '{0}/data/tfrecord/train.tfrecord'.format(_ROOT_DIR),\n",
    "    'eval_data_path': '{0}/data/tfrecord/val.tfrecord'.format(_ROOT_DIR),\n",
    "    'test_data_path': '{0}/data/tfrecord/test.tfrecord'.format(_ROOT_DIR),    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support for log files\n",
    "import logging\n",
    "\n",
    "# advanced numerical operations\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "_LOG_PATH = '{0}/logs'.format(_ROOT_DIR)\n",
    "logging.basicConfig(filename='{}/test.log'.format(_LOG_PATH),\n",
    "                    level=logging.INFO,\n",
    "                    format='%(asctime)s - %(name)s - %(threadName)s -  %(levelname)s - %(message)s')\n",
    "\n",
    "logging.info('Logging to {}/test.log.'.format(_LOG_PATH))\n",
    "\n",
    "# ToDo: pass a complex dictionary as a starting point for the LSTM network chromosome\n",
    "'''\n",
    "    Deep/Parallel LSTM network chromosome includes:\n",
    "    m_hour: [24, 12, 8, etc], tau=1, implement this variable later and work now with m_hour=24\n",
    "    m_day: [7, 14, etc], tau=7, implement this variable later and work now with m_day=7\n",
    "    m_week: [4, 8, 12, etc], tau=168, implement this variable later and work now with m_week=4\n",
    "    hidden_hour: number of hidden units at hour-resolution\n",
    "    hidden_day: number of hidden units at day-resolution\n",
    "    hidden_week: number of hidden units at week-resolution\n",
    "    levels_hour: number of levels in stacked LSTM for prediction at hour-resolution\n",
    "    levels_day: number of levels in stacked LSTM for prediction at day-resolution\n",
    "    levels_week: number of levels in stacked LSTM for prediction at week-resolution\n",
    "'''\n",
    "\n",
    "_LOG_PATH = '{0}/logs'.format(_ROOT_DIR)\n",
    "logging.basicConfig(filename='{}/test.log'.format(_LOG_PATH),\n",
    "                    level=logging.INFO,\n",
    "                    format='%(asctime)s - %(name)s - %(threadName)s -  %(levelname)s - %(message)s')\n",
    "\n",
    "logging.info('Logging to {}/test.log.'.format(_LOG_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start notebook from batch script, but first\n",
    "# remove main function and transfer everything to first-level code cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_forecaster(features, labels, mode):\n",
    "    '''\n",
    "    this is the custom estimator\n",
    "    '''\n",
    "    # instantiate network topology from the corresponding class\n",
    "    forecaster_topology = DPLSTM()\n",
    "\n",
    "    # ToDo: global_step variable might be moved to TRAIN scope\n",
    "    global_step = tf.train.get_global_step()\n",
    "\n",
    "    # call operator to forecaster_topology, over features\n",
    "    forecast = forecaster_topology(features)\n",
    "\n",
    "    # predictions are stored in a dictionary for further use at inference stage\n",
    "    predictions = {\n",
    "        \"forecast\": forecast\n",
    "    }\n",
    "\n",
    "    # CHANGE MODEL FUNCTION STRUCTURE ACCORDING TO GILLARD'S ARCHITECTURE\n",
    "\n",
    "    # Estimator in TRAIN or EVAL mode\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN or mode == tf.estimator.ModeKeys.EVAL:\n",
    "        # use labels and predictions to define training loss and evaluation loss\n",
    "        # generate summaries for TensorBoard\n",
    "        with tf.name_scope('loss'):\n",
    "            mean_squared_error = tf.losses.mean_squared_error(\n",
    "                labels=labels, predictions=forecast, scope='loss')\n",
    "            tf.summary.scalar('loss', mean_squared_error)\n",
    "\n",
    "        with tf.name_scope('val_loss'):\n",
    "            val_loss = tf.metrics.mean_squared_error(\n",
    "                labels=labels, predictions=forecast, name='mse')\n",
    "            tf.summary.scalar('val_loss', val_loss[1])\n",
    "\n",
    "        # this is only required for PREDICT mode\n",
    "        prediction_hooks = None\n",
    "\n",
    "        # Estimator in TRAIN mode ONLY\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            # This is needed for batch normalization, but has no effect otherwise\n",
    "            update_ops = tf.get_collection(key=tf.GraphKeys.UPDATE_OPS)\n",
    "            with tf.control_dependencies(control_inputs=update_ops):\n",
    "                train_op = tf.contrib.layers.optimize_loss(\n",
    "                    loss=mean_squared_error,\n",
    "                    global_step=global_step,\n",
    "                    learning_rate=parameters['learning_rate'],\n",
    "                    optimizer=\"Adam\")\n",
    "            # Create a hook to print acc, loss & global step every 100 iter\n",
    "            train_hook_list = []\n",
    "            train_tensors_log = {'val_loss': val_loss[1],\n",
    "                                 'loss': mean_squared_error,\n",
    "                                 'global_step': global_step}\n",
    "            train_hook_list.append(tf.train.LoggingTensorHook(\n",
    "                tensors=train_tensors_log, every_n_iter=100))\n",
    "\n",
    "            predictions = None  # this is not required in TRAIN mode\n",
    "            loss = mean_squared_error\n",
    "            eval_metric_ops = None\n",
    "            training_hooks = train_hook_list\n",
    "            evaluation_hooks = None\n",
    "\n",
    "        else:  # Estimator in EVAL mode ONLY\n",
    "            loss = mean_squared_error\n",
    "            train_op = None\n",
    "            training_hooks = None\n",
    "            eval_metric_ops = {'val_loss': val_loss}\n",
    "            evaluation_hooks = None\n",
    "\n",
    "    # Estimator in PREDICT mode ONLY\n",
    "    else:\n",
    "        loss = None\n",
    "        train_op = None\n",
    "        eval_metric_ops = None\n",
    "        training_hooks = None\n",
    "        evaluation_hooks = None\n",
    "        prediction_hooks = None  # this might change as we are in PREDICT mode\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=predictions,\n",
    "        loss=loss,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops=eval_metric_ops,\n",
    "        # export_outputs=not_used_yet (for TensorFlow Serving, redirected from predictions if omitted)\n",
    "        # training_chief_hooks=not_used_yet\n",
    "        # ToDo: verify use of training_hooks\n",
    "        # temporarily disable training hooks\n",
    "        # training_hooks=training_hooks,\n",
    "        training_hooks=training_hooks,\n",
    "        # scaffold=not_used_yet\n",
    "        evaluation_hooks=evaluation_hooks,\n",
    "        prediction_hooks=prediction_hooks\n",
    "    )\n",
    "\n",
    "# ToDo: evaluate the convenience of packaging execution in a tf.app\n",
    "# in the meantime, run the estimator outside tf.app package\n",
    "# tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure file writer cache is clear for TensorBoard events file\n",
    "# ToDo: verify if this operation is required\n",
    "tf.summary.FileWriterCache.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters required for RunConfig()\n",
    "# _EVAL_INTERVAL = 300  # how often checkpoints are written out, given in seconds\n",
    "# _KEEP_CHECKPOINT_MAX = 3  # how many checkpoints to keep\n",
    "# _MAX_TRAIN_STEPS = 16000\n",
    "# _TRAIN_BATCH_SIZE = 2**5\n",
    "# _EVAL_STEPS = None  # if None, evaluate on entire dataset\n",
    "# _EVAL_BATCH_SIZE = 2**16\n",
    "# _START_DELAY_SECONDS = 600\n",
    "# _THROTTLE_SECONDS = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_tf_random_seed': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb73ae91d68>, '_log_step_count_steps': 100, '_is_chief': True, '_save_summary_steps': 100, '_service': None, '_train_distribute': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_save_checkpoints_secs': 300, '_master': '', '_protocol': None, '_experimental_max_worker_delay_secs': None, '_save_checkpoints_steps': None, '_num_ps_replicas': 0, '_device_fn': None, '_keep_checkpoint_every_n_hours': 10000, '_task_type': 'worker', '_eval_distribute': None, '_evaluation_master': '', '_task_id': 0, '_keep_checkpoint_max': 3, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_model_dir': '/home/jupyter/gcp/cbidmltsf/dplstm/lstm_50', '_global_id_in_cluster': 0, '_session_creation_timeout_secs': 7200}\n"
     ]
    }
   ],
   "source": [
    "# instantiate base estimator class for custom model function\n",
    "tsf_estimator = tf.estimator.Estimator(\n",
    "    model_fn=time_series_forecaster,\n",
    "    # no parameters passed at this point\n",
    "    # params=hparams,\n",
    "    # parameters passed in original model include: train_data_path, batch_size, augment, train_steps\n",
    "    config=tf.estimator.RunConfig(\n",
    "        save_checkpoints_secs=parameters['eval_interval'],\n",
    "        keep_checkpoint_max=parameters['keep_checkpoint_max']\n",
    "    ),\n",
    "    model_dir='{0}/dplstm/{1}'.format(_ROOT_DIR, parameters['model_dir']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set estimator's train_spec to use train_input_fn and train it for many, many steps\n",
    "train_spec = tf.estimator.TrainSpec(\n",
    "    input_fn=make_input_fn(\n",
    "        tfrecord_path=parameters['train_data_path'],\n",
    "        batch_size=parameters['train_batch_size'],\n",
    "        mode=tf.estimator.ModeKeys.TRAIN\n",
    "    ),\n",
    "    max_steps=parameters['max_train_steps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ready to create a new serving input function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features dictionary for parsing TFrecord files\n",
    "read_features = {\n",
    "    'hourly': tf.io.VarLenFeature(dtype=tf.float32),\n",
    "    'daily': tf.io.VarLenFeature(dtype=tf.float32),\n",
    "    'weekly': tf.io.VarLenFeature(dtype=tf.float32),\n",
    "    'target': tf.io.FixedLenFeature([], dtype=tf.float32)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_dataset_function(example_proto, objective_shape):\n",
    "    # parse the input tf.Example proto using the dictionary called read_features (above defined)\n",
    "    row = tf.io.parse_single_example(example_proto, read_features)\n",
    "    # pass objective shape as a list of lists [hourly_shape, daily_shape, weekly_shape]\n",
    "    hourly = tf.reshape(row['hourly'].values, objective_shape[0])\n",
    "    daily = tf.reshape(row['daily'].values, objective_shape[1])\n",
    "    weekly = tf.reshape(row['weekly'].values, objective_shape[2])\n",
    "    target = tf.reshape(row['target'], [1, ])\n",
    "    return {'hourly': hourly, 'daily': daily, 'weekly': weekly}, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_fn():\n",
    "    # it handles only one example at a time\n",
    "    # TPU are not optimized for serving, so it is assumed the predictions server is CPU or GPU-based\n",
    "    # inputs is equivalent to example protocol buffers\n",
    "    feature_placeholders = {'example_bytes': tf.placeholder(tf.string, shape=())}\n",
    "    _SERVING_OBJECTIVE_SHAPES = [[1, 24, 1], [1, 7, 1], [1, 4, 1]]\n",
    "    # the serving input function does not require the label\n",
    "    features, _ = _parse_dataset_function(feature_placeholders['example_bytes'], _SERVING_OBJECTIVE_SHAPES)\n",
    "    # re-shape to original model spec\n",
    "    \n",
    "    return tf.estimator.export.ServingInputReceiver(features, feature_placeholders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create exporter that uses serving_input_fn to create saved_model for serving\n",
    "exporter = tf.estimator.LatestExporter(\n",
    "    name = \"exporter\", \n",
    "    serving_input_receiver_fn = serving_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set estimator's eval_spec to use eval_input_fn and export saved_model\n",
    "eval_spec = tf.estimator.EvalSpec(\n",
    "    input_fn=make_input_fn(\n",
    "        tfrecord_path=parameters['eval_data_path'],\n",
    "        batch_size=parameters['eval_batch_size'],\n",
    "        mode=tf.estimator.ModeKeys.EVAL\n",
    "    ),\n",
    "    steps=parameters['eval_steps'],  # use None to evaluate on the entire dataset\n",
    "    exporters=exporter,\n",
    "    start_delay_secs=parameters['start_delay_secs'],  # delay first evaluation\n",
    "    throttle_secs=parameters['throttle_secs']  # evaluate at a different rate (usually longer) than checkpoint\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 300.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /home/jupyter/gcp/cbidmltsf/dplstm/data.py:92: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/jupyter/gcp/cbidmltsf/dplstm/lstm_50/model.ckpt-16208\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 16208 into /home/jupyter/gcp/cbidmltsf/dplstm/lstm_50/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.0051809303, step = 16209\n",
      "INFO:tensorflow:global_step = 16209, loss = 0.0051809303, val_loss = 0.0051809303\n",
      "INFO:tensorflow:global_step/sec: 2.44146\n",
      "INFO:tensorflow:loss = 0.0023113135, step = 16309 (40.967 sec)\n",
      "INFO:tensorflow:global_step = 16309, loss = 0.0023113135, val_loss = 0.003746122 (40.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.1211\n",
      "INFO:tensorflow:loss = 0.0043325317, step = 16409 (32.037 sec)\n",
      "INFO:tensorflow:global_step = 16409, loss = 0.0043325317, val_loss = 0.003941592 (32.037 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.09473\n",
      "INFO:tensorflow:loss = 0.0110279545, step = 16509 (32.311 sec)\n",
      "INFO:tensorflow:global_step = 16509, loss = 0.0110279545, val_loss = 0.0057131825 (32.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.12287\n",
      "INFO:tensorflow:loss = 0.0047658407, step = 16609 (32.022 sec)\n",
      "INFO:tensorflow:global_step = 16609, loss = 0.0047658407, val_loss = 0.0055237142 (32.022 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.03195\n",
      "INFO:tensorflow:loss = 0.0036562316, step = 16709 (32.983 sec)\n",
      "INFO:tensorflow:global_step = 16709, loss = 0.0036562316, val_loss = 0.005212467 (32.984 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76192\n",
      "INFO:tensorflow:loss = 0.00419372, step = 16809 (36.207 sec)\n",
      "INFO:tensorflow:global_step = 16809, loss = 0.00419372, val_loss = 0.0050669317 (36.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.76458\n",
      "INFO:tensorflow:loss = 0.0036787312, step = 16909 (36.172 sec)\n",
      "INFO:tensorflow:global_step = 16909, loss = 0.0036787312, val_loss = 0.0048934068 (36.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.77096\n",
      "INFO:tensorflow:loss = 0.004530483, step = 17009 (36.089 sec)\n",
      "INFO:tensorflow:global_step = 17009, loss = 0.004530483, val_loss = 0.004853082 (36.088 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 17035 into /home/jupyter/gcp/cbidmltsf/dplstm/lstm_50/model.ckpt.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-01-13T15:50:04Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/jupyter/gcp/cbidmltsf/dplstm/lstm_50/model.ckpt-17035\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-01-13-15:50:07\n",
      "INFO:tensorflow:Saving dict for global step 17035: global_step = 17035, loss = 0.009359165, val_loss = 0.009359165\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 17035: /home/jupyter/gcp/cbidmltsf/dplstm/lstm_50/model.ckpt-17035\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
      "INFO:tensorflow:Restoring parameters from /home/jupyter/gcp/cbidmltsf/dplstm/lstm_50/model.ckpt-17035\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /home/jupyter/gcp/cbidmltsf/dplstm/lstm_50/export/exporter/temp-b'1578930608'/saved_model.pb\n",
      "INFO:tensorflow:global_step/sec: 3.07149\n",
      "INFO:tensorflow:loss = 0.007070876, step = 17109 (32.558 sec)\n",
      "INFO:tensorflow:global_step = 17109, loss = 0.007070876, val_loss = 0.0050748615 (32.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.81181\n",
      "INFO:tensorflow:loss = 0.003337228, step = 17209 (20.782 sec)\n",
      "INFO:tensorflow:global_step = 17209, loss = 0.003337228, val_loss = 0.0049168947 (20.783 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.97312\n",
      "INFO:tensorflow:loss = 0.004918853, step = 17309 (20.108 sec)\n",
      "INFO:tensorflow:global_step = 17309, loss = 0.004918853, val_loss = 0.0049170577 (20.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.87829\n",
      "INFO:tensorflow:loss = 0.004427408, step = 17409 (20.504 sec)\n",
      "INFO:tensorflow:global_step = 17409, loss = 0.004427408, val_loss = 0.0048793927 (20.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.98168\n",
      "INFO:tensorflow:loss = 0.004637443, step = 17509 (20.069 sec)\n",
      "INFO:tensorflow:global_step = 17509, loss = 0.004637443, val_loss = 0.0048621106 (20.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.98138\n",
      "INFO:tensorflow:loss = 0.0055272114, step = 17609 (20.078 sec)\n",
      "INFO:tensorflow:global_step = 17609, loss = 0.0055272114, val_loss = 0.004906451 (20.076 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.88413\n",
      "INFO:tensorflow:loss = 0.0041454793, step = 17709 (20.472 sec)\n",
      "INFO:tensorflow:global_step = 17709, loss = 0.0041454793, val_loss = 0.00485889 (20.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.85141\n",
      "INFO:tensorflow:loss = 0.00358149, step = 17809 (20.616 sec)\n",
      "INFO:tensorflow:global_step = 17809, loss = 0.00358149, val_loss = 0.0047837486 (20.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.86\n",
      "INFO:tensorflow:loss = 0.0087054465, step = 17909 (20.572 sec)\n",
      "INFO:tensorflow:global_step = 17909, loss = 0.0087054465, val_loss = 0.005001621 (20.571 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.85271\n",
      "INFO:tensorflow:loss = 0.0055502527, step = 18009 (20.611 sec)\n",
      "INFO:tensorflow:global_step = 18009, loss = 0.0055502527, val_loss = 0.005030496 (20.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.96876\n",
      "INFO:tensorflow:loss = 0.00336852, step = 18109 (20.122 sec)\n",
      "INFO:tensorflow:global_step = 18109, loss = 0.00336852, val_loss = 0.004947397 (20.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.86932\n",
      "INFO:tensorflow:loss = 0.003583802, step = 18209 (20.538 sec)\n",
      "INFO:tensorflow:global_step = 18209, loss = 0.003583802, val_loss = 0.004882464 (20.539 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.843\n",
      "INFO:tensorflow:loss = 0.006862592, step = 18309 (20.646 sec)\n",
      "INFO:tensorflow:global_step = 18309, loss = 0.006862592, val_loss = 0.00497247 (20.648 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.89047\n",
      "INFO:tensorflow:loss = 0.005497434, step = 18409 (20.449 sec)\n",
      "INFO:tensorflow:global_step = 18409, loss = 0.005497434, val_loss = 0.0049952944 (20.447 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 18463 into /home/jupyter/gcp/cbidmltsf/dplstm/lstm_50/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:global_step/sec: 4.64191\n",
      "INFO:tensorflow:loss = 0.007215889, step = 18509 (21.542 sec)\n",
      "INFO:tensorflow:global_step = 18509, loss = 0.007215889, val_loss = 0.0050878194 (21.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.86408\n",
      "INFO:tensorflow:loss = 0.003305732, step = 18609 (20.563 sec)\n",
      "INFO:tensorflow:global_step = 18609, loss = 0.003305732, val_loss = 0.0050165355 (20.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.95808\n",
      "INFO:tensorflow:loss = 0.014460261, step = 18709 (20.165 sec)\n",
      "INFO:tensorflow:global_step = 18709, loss = 0.014460261, val_loss = 0.005379756 (20.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.16282\n",
      "INFO:tensorflow:loss = 0.006270605, step = 18809 (19.370 sec)\n",
      "INFO:tensorflow:global_step = 18809, loss = 0.006270605, val_loss = 0.0054127504 (19.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.87674\n",
      "INFO:tensorflow:loss = 0.0034296005, step = 18909 (20.505 sec)\n",
      "INFO:tensorflow:global_step = 18909, loss = 0.0034296005, val_loss = 0.005341924 (20.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.78823\n",
      "INFO:tensorflow:loss = 0.005743336, step = 19009 (20.884 sec)\n",
      "INFO:tensorflow:global_step = 19009, loss = 0.005743336, val_loss = 0.0053557656 (20.886 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.81641\n",
      "INFO:tensorflow:loss = 0.002979234, step = 19109 (20.763 sec)\n",
      "INFO:tensorflow:global_step = 19109, loss = 0.002979234, val_loss = 0.0052765477 (20.761 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.95439\n",
      "INFO:tensorflow:loss = 0.001969055, step = 19209 (20.188 sec)\n",
      "INFO:tensorflow:global_step = 19209, loss = 0.001969055, val_loss = 0.0051698545 (20.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.81656\n",
      "INFO:tensorflow:loss = 0.0046764724, step = 19309 (20.757 sec)\n",
      "INFO:tensorflow:global_step = 19309, loss = 0.0046764724, val_loss = 0.0051544365 (20.759 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.74397\n",
      "INFO:tensorflow:loss = 0.0031065573, step = 19409 (21.084 sec)\n",
      "INFO:tensorflow:global_step = 19409, loss = 0.0031065573, val_loss = 0.0050923796 (21.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.01185\n",
      "INFO:tensorflow:loss = 0.0051305005, step = 19509 (19.953 sec)\n",
      "INFO:tensorflow:global_step = 19509, loss = 0.0051305005, val_loss = 0.005093501 (19.953 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.79853\n",
      "INFO:tensorflow:loss = 0.0032591168, step = 19609 (20.839 sec)\n",
      "INFO:tensorflow:global_step = 19609, loss = 0.0032591168, val_loss = 0.0050410903 (20.839 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.00379\n",
      "INFO:tensorflow:loss = 0.00960769, step = 19709 (19.980 sec)\n",
      "INFO:tensorflow:global_step = 19709, loss = 0.00960769, val_loss = 0.00516794 (19.980 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.73458\n",
      "INFO:tensorflow:loss = 0.003395487, step = 19809 (21.126 sec)\n",
      "INFO:tensorflow:global_step = 19809, loss = 0.003395487, val_loss = 0.0051200357 (21.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.17533\n",
      "INFO:tensorflow:loss = 0.003559698, step = 19909 (19.318 sec)\n",
      "INFO:tensorflow:global_step = 19909, loss = 0.003559698, val_loss = 0.005078974 (19.318 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 19932 into /home/jupyter/gcp/cbidmltsf/dplstm/lstm_50/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-01-13T16:00:04Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/jupyter/gcp/cbidmltsf/dplstm/lstm_50/model.ckpt-19932\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-01-13-16:00:07\n",
      "INFO:tensorflow:Saving dict for global step 19932: global_step = 19932, loss = 0.0056947228, val_loss = 0.0056947228\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 19932: /home/jupyter/gcp/cbidmltsf/dplstm/lstm_50/model.ckpt-19932\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
      "INFO:tensorflow:Restoring parameters from /home/jupyter/gcp/cbidmltsf/dplstm/lstm_50/model.ckpt-19932\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /home/jupyter/gcp/cbidmltsf/dplstm/lstm_50/export/exporter/temp-b'1578931207'/saved_model.pb\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into /home/jupyter/gcp/cbidmltsf/dplstm/lstm_50/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-01-13T16:00:24Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /home/jupyter/gcp/cbidmltsf/dplstm/lstm_50/model.ckpt-20000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-01-13-16:00:27\n",
      "INFO:tensorflow:Saving dict for global step 20000: global_step = 20000, loss = 0.007421616, val_loss = 0.007421616\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20000: /home/jupyter/gcp/cbidmltsf/dplstm/lstm_50/model.ckpt-20000\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
      "INFO:tensorflow:Restoring parameters from /home/jupyter/gcp/cbidmltsf/dplstm/lstm_50/model.ckpt-20000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /home/jupyter/gcp/cbidmltsf/dplstm/lstm_50/export/exporter/temp-b'1578931227'/saved_model.pb\n",
      "INFO:tensorflow:Loss for final step: 0.005642011.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'global_step': 20000, 'loss': 0.007421616, 'val_loss': 0.007421616},\n",
       " [b'/home/jupyter/gcp/cbidmltsf/dplstm/lstm_50/export/exporter/1578931227'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run train_and_evaluate loop\n",
    "tf.estimator.train_and_evaluate(\n",
    "    estimator=tsf_estimator,\n",
    "    train_spec=train_spec,\n",
    "    eval_spec=eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the directory of the latest saved model\n",
    "_SAVED_MODEL_DIR = '{0}/dplstm/{1}/export/exporter'.format(_ROOT_DIR, parameters['model_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdirs = [x for x in Path(_SAVED_MODEL_DIR).iterdir()\n",
    "           if x.is_dir() and 'temp' not in str(x)]\n",
    "_LATEST_SAVED_MODEL_DIR = str(sorted(subdirs)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/gcp/cbidmltsf/dplstm/lstm_50/export/exporter/1578931227'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_LATEST_SAVED_MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/contrib/predictor/saved_model_predictor.py:153: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "INFO:tensorflow:Restoring parameters from /home/jupyter/gcp/cbidmltsf/dplstm/lstm_50/export/exporter/1578931227/variables/variables\n"
     ]
    }
   ],
   "source": [
    "# build a prediction function\n",
    "predict_fn = tf.contrib.predictor.from_saved_model(_LATEST_SAVED_MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: ORGANIZE ALL SHAPES TO AVOID UNNECESSARY RE-SHAPING OPERATIONS!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/gcp/cbidmltsf/data/tfrecord/test.tfrecord'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now locate TFRecord test dataset and load it, need to parse the examples to a dictionary\n",
    "test_dataset_filename = '{0}/data/tfrecord/test.tfrecord'.format(_ROOT_DIR)\n",
    "test_dataset_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TFRecordDatasetV1 shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now read the dataset from TFRecord file using non-deprecated methods from tf.data module\n",
    "test_raw_dataset = tf.data.TFRecordDataset(test_dataset_filename)\n",
    "test_raw_dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable the interactive session as it is not longer required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can I access to the binary, string-based, raw dataset using a one-shot iterator?\n",
    "# iterator = test_raw_dataset.make_one_shot_iterator()\n",
    "# next_element = iterator.get_next()\n",
    "\n",
    "# there is only one row in the raw dataset\n",
    "# single_example = sess.run(next_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_prediction = predict_fn({'example_bytes': single_example})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_prediction['forecast'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, how to serve the saved model over the complete test dataset?\n",
    "# must review software projects again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = test_raw_dataset.map(lambda row: row)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refine this iterator\n",
    "# it is extremely slow!!!\n",
    "# load to memory?\n",
    "predictions_list = []\n",
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        while True:\n",
    "            example = sess.run(next_element)\n",
    "            predictions_list.append(predict_fn({'example_bytes': example}))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# why is the previous code cell so slow?\n",
    "# it must be a better way to create the predictions list once the trained model is saved!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'forecast': array([[0.5199028]], dtype=float32)},\n",
       " {'forecast': array([[0.5460328]], dtype=float32)},\n",
       " {'forecast': array([[0.56626]], dtype=float32)},\n",
       " {'forecast': array([[0.56715137]], dtype=float32)},\n",
       " {'forecast': array([[0.5959195]], dtype=float32)},\n",
       " {'forecast': array([[0.60846704]], dtype=float32)},\n",
       " {'forecast': array([[0.61072195]], dtype=float32)},\n",
       " {'forecast': array([[0.60524976]], dtype=float32)},\n",
       " {'forecast': array([[0.59112555]], dtype=float32)},\n",
       " {'forecast': array([[0.55812615]], dtype=float32)}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict based on saved model and plot results with Bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anaconda Interactive Visualization\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.plotting import output_file, save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator MinMaxScaler from version 0.19.1 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# persistence for the scaler located in $DATA/scalers\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# reload scaler fitted model here\n",
    "scaler = joblib.load('{0}/data/scalers/ci_LSTM_scaler.save'.format(_ROOT_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "566"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move to array and re-scale\n",
    "predictions = [p['forecast'][0][0] for p in predictions_list]\n",
    "predictions = np.asarray(predictions)\n",
    "pred_ci = scaler.inverse_transform(predictions.reshape(-1, 1))\n",
    "pred_ci = np.squeeze(pred_ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.2805333, 4.49567  , 4.662207 , 4.669546 , 4.906404 , 5.009712 ,\n",
       "       5.0282774, 4.983223 , 4.866934 , 4.5952387], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ci[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo: get ytarget_test array from test.tfrecord dataset to perform the following operation\n",
    "# temporarily get the array from disk\n",
    "y_test = np.load('{0}/data/arrays/y_test.npy'.format(_ROOT_DIR))\n",
    "n = 0  # first step ahead\n",
    "ytarget_test = y_test[:, n]\n",
    "ytarget_test = ytarget_test.reshape(ytarget_test.shape[0], 1)\n",
    "\n",
    "actual_ci = scaler.inverse_transform(ytarget_test)\n",
    "actual_ci = np.squeeze(actual_ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "_EQUIPMENT = 'CPE04105'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n",
      "BokehDeprecationWarning: 'legend' keyword is deprecated, use explicit 'legend_label', 'legend_field', or 'legend_group' keywords instead\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/gcp/cbidmltsf/plots/lstm_50.html'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ci_predictions_fig = figure(title='Predicted Current Imbalance for ' + _EQUIPMENT,\n",
    "                            background_fill_color='#E8DDCB',\n",
    "                            plot_width=1800, plot_height=450, x_axis_type='datetime')\n",
    "\n",
    "# ToDo: yts_test array is required to get timestamps for plot, then wire it now and get it from TFRecord later...\n",
    "yts_test = np.load('{0}/data/arrays/yts_test.npy'.format(_ROOT_DIR), allow_pickle=True)\n",
    "\n",
    "ci_predictions_fig.line(yts_test[:, n],\n",
    "                        actual_ci, line_color='red',\n",
    "                        line_width=1, alpha=0.7, legend='Actual')\n",
    "\n",
    "ci_predictions_fig.line(yts_test[:, n],\n",
    "                        pred_ci, line_color='blue',\n",
    "                        line_width=1, alpha=0.7, legend='Predicted')\n",
    "\n",
    "ci_predictions_fig.legend.location = \"top_right\"\n",
    "ci_predictions_fig.legend.background_fill_color = \"darkgrey\"\n",
    "\n",
    "ci_predictions_fig.xaxis.axis_label = 'Timestamp'\n",
    "ci_predictions_fig.yaxis.axis_label = 'Current Imbalance [%]'\n",
    "\n",
    "# output_file('{0}/plots/'.format(_ROOT_DIR) + '{:03d}'.format(n) + '.html', title=_EQUIPMENT)\n",
    "output_file('{0}/plots/'.format(_ROOT_DIR) + '{}'.format(parameters['model_dir']) + '.html', title=_EQUIPMENT)\n",
    "save(ci_predictions_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
