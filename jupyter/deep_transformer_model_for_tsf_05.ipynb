{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer implementation in Keras and TensorFlow 1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT!\n",
    "# code must be used from Python source\n",
    "# then, complete the Transformer model using Keras MHA layer, on TF 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fourth experiment:\n",
    "# TensorFlow 1.15\n",
    "# (there is no support for Keras MultiHeadAttention or TensorFlow addons on TF 1.15!)\n",
    "\n",
    "# MultiHeadAttention from TensorFlow AddOns source\n",
    "# Transformer-encoder only (autoencoder option)\n",
    "# value embedding with Conv1D\n",
    "# basic positional encoding with Keras embedding\n",
    "# encoder output to multi-step target with TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required for TFA MultiHeadAttention\n",
    "import typing\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    r\"\"\"MultiHead Attention layer.\n",
    "    Defines the MultiHead Attention operation as described in\n",
    "    [Attention Is All You Need](https://arxiv.org/abs/1706.03762) which takes\n",
    "    in the tensors `query`, `key`, and `value`, and returns the dot-product attention\n",
    "    between them:\n",
    "    >>> mha = MultiHeadAttention(head_size=128, num_heads=12)\n",
    "    >>> query = np.random.rand(3, 5, 4) # (batch_size, query_elements, query_depth)\n",
    "    >>> key = np.random.rand(3, 6, 5) # (batch_size, key_elements, key_depth)\n",
    "    >>> value = np.random.rand(3, 6, 6) # (batch_size, key_elements, value_depth)\n",
    "    >>> attention = mha([query, key, value]) # (batch_size, query_elements, value_depth)\n",
    "    >>> attention.shape\n",
    "    TensorShape([3, 5, 6])\n",
    "    If `value` is not given then internally `value = key` will be used:\n",
    "    >>> mha = MultiHeadAttention(head_size=128, num_heads=12)\n",
    "    >>> query = np.random.rand(3, 5, 5) # (batch_size, query_elements, query_depth)\n",
    "    >>> key = np.random.rand(3, 6, 10) # (batch_size, key_elements, key_depth)\n",
    "    >>> attention = mha([query, key]) # (batch_size, query_elements, key_depth)\n",
    "    >>> attention.shape\n",
    "    TensorShape([3, 5, 10])\n",
    "    Args:\n",
    "        head_size: int, dimensionality of the `query`, `key` and `value` tensors\n",
    "            after the linear transformation.\n",
    "        num_heads: int, number of attention heads.\n",
    "        output_size: int, dimensionality of the output space, if `None` then the\n",
    "            input dimension of `value` or `key` will be used,\n",
    "            default `None`.\n",
    "        dropout: float, `rate` parameter for the dropout layer that is\n",
    "            applied to attention after softmax,\n",
    "        default `0`.\n",
    "        use_projection_bias: bool, whether to use a bias term after the linear\n",
    "            output projection.\n",
    "        return_attn_coef: bool, if `True`, return the attention coefficients as\n",
    "            an additional output argument.\n",
    "        kernel_initializer: initializer, initializer for the kernel weights.\n",
    "        kernel_regularizer: regularizer, regularizer for the kernel weights.\n",
    "        kernel_constraint: constraint, constraint for the kernel weights.\n",
    "        bias_initializer: initializer, initializer for the bias weights.\n",
    "        bias_regularizer: regularizer, regularizer for the bias weights.\n",
    "        bias_constraint: constraint, constraint for the bias weights.\n",
    "    Call Args:\n",
    "        inputs:  List of `[query, key, value]` where\n",
    "            * `query`: Tensor of shape `(..., query_elements, query_depth)`\n",
    "            * `key`: `Tensor of shape '(..., key_elements, key_depth)`\n",
    "            * `value`: Tensor of shape `(..., key_elements, value_depth)`, optional, if not given `key` will be used.\n",
    "        mask: a binary Tensor of shape `[batch_size?, num_heads?, query_elements, key_elements]`\n",
    "        which specifies which query elements can attendo to which key elements,\n",
    "        `1` indicates attention and `0` indicates no attention.\n",
    "    Output shape:\n",
    "        * `(..., query_elements, output_size)` if `output_size` is given, else\n",
    "        * `(..., query_elements, value_depth)` if `value` is given, else\n",
    "        * `(..., query_elements, key_depth)`\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        head_size: int,\n",
    "        num_heads: int,\n",
    "        output_size: int = None,\n",
    "        dropout: float = 0.0,\n",
    "        use_projection_bias: bool = True,\n",
    "        return_attn_coef: bool = False,\n",
    "        kernel_initializer: typing.Union[str, typing.Callable] = \"glorot_uniform\",\n",
    "        kernel_regularizer: typing.Union[str, typing.Callable] = None,\n",
    "        kernel_constraint: typing.Union[str, typing.Callable] = None,\n",
    "        bias_initializer: typing.Union[str, typing.Callable] = \"zeros\",\n",
    "        bias_regularizer: typing.Union[str, typing.Callable] = None,\n",
    "        bias_constraint: typing.Union[str, typing.Callable] = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        warnings.warn(\n",
    "            \"`MultiHeadAttention` will be deprecated in Addons 0.13. \"\n",
    "            \"Please use `tf.keras.layers.MultiHeadAttention` instead.\",\n",
    "            DeprecationWarning,\n",
    "        )\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        if output_size is not None and output_size < 1:\n",
    "            raise ValueError(\"output_size must be a positive number\")\n",
    "\n",
    "        self.head_size = head_size\n",
    "        self.num_heads = num_heads\n",
    "        self.output_size = output_size\n",
    "        self.use_projection_bias = use_projection_bias\n",
    "        self.return_attn_coef = return_attn_coef\n",
    "\n",
    "        self.kernel_initializer = tf.keras.initializers.get(kernel_initializer)\n",
    "        self.kernel_regularizer = tf.keras.regularizers.get(kernel_regularizer)\n",
    "        self.kernel_constraint = tf.keras.constraints.get(kernel_constraint)\n",
    "        self.bias_initializer = tf.keras.initializers.get(bias_initializer)\n",
    "        self.bias_regularizer = tf.keras.regularizers.get(bias_regularizer)\n",
    "        self.bias_constraint = tf.keras.constraints.get(bias_constraint)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "        self._dropout_rate = dropout\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        num_query_features = input_shape[0][-1]\n",
    "        num_key_features = input_shape[1][-1]\n",
    "        num_value_features = (\n",
    "            input_shape[2][-1] if len(input_shape) > 2 else num_key_features\n",
    "        )\n",
    "        output_size = (\n",
    "            self.output_size if self.output_size is not None else num_value_features\n",
    "        )\n",
    "\n",
    "        self.query_kernel = self.add_weight(\n",
    "            name=\"query_kernel\",\n",
    "            shape=[self.num_heads, num_query_features, self.head_size],\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            constraint=self.kernel_constraint,\n",
    "        )\n",
    "        self.key_kernel = self.add_weight(\n",
    "            name=\"key_kernel\",\n",
    "            shape=[self.num_heads, num_key_features, self.head_size],\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            constraint=self.kernel_constraint,\n",
    "        )\n",
    "        self.value_kernel = self.add_weight(\n",
    "            name=\"value_kernel\",\n",
    "            shape=[self.num_heads, num_value_features, self.head_size],\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            constraint=self.kernel_constraint,\n",
    "        )\n",
    "        self.projection_kernel = self.add_weight(\n",
    "            name=\"projection_kernel\",\n",
    "            shape=[self.num_heads, self.head_size, output_size],\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            constraint=self.kernel_constraint,\n",
    "        )\n",
    "\n",
    "        if self.use_projection_bias:\n",
    "            self.projection_bias = self.add_weight(\n",
    "                name=\"projection_bias\",\n",
    "                shape=[output_size],\n",
    "                initializer=self.bias_initializer,\n",
    "                regularizer=self.bias_regularizer,\n",
    "                constraint=self.bias_constraint,\n",
    "            )\n",
    "        else:\n",
    "            self.projection_bias = None\n",
    "\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "\n",
    "        # einsum nomenclature\n",
    "        # ------------------------\n",
    "        # N = query elements\n",
    "        # M = key/value elements\n",
    "        # H = heads\n",
    "        # I = input features\n",
    "        # O = output features\n",
    "\n",
    "        query = inputs[0]\n",
    "        key = inputs[1]\n",
    "        value = inputs[2] if len(inputs) > 2 else key\n",
    "\n",
    "        # verify shapes\n",
    "        if key.shape[-2] != value.shape[-2]:\n",
    "            raise ValueError(\n",
    "                \"the number of elements in 'key' must be equal to the same as the number of elements in 'value'\"\n",
    "            )\n",
    "\n",
    "        if mask is not None:\n",
    "            if len(mask.shape) < 2:\n",
    "                raise ValueError(\"'mask' must have atleast 2 dimensions\")\n",
    "            if query.shape[-2] != mask.shape[-2]:\n",
    "                raise ValueError(\n",
    "                    \"mask's second to last dimension must be equal to the number of elements in 'query'\"\n",
    "                )\n",
    "            if key.shape[-2] != mask.shape[-1]:\n",
    "                raise ValueError(\n",
    "                    \"mask's last dimension must be equal to the number of elements in 'key'\"\n",
    "                )\n",
    "\n",
    "        # Linear transformations\n",
    "        query = tf.einsum(\"...NI , HIO -> ...NHO\", query, self.query_kernel)\n",
    "        key = tf.einsum(\"...MI , HIO -> ...MHO\", key, self.key_kernel)\n",
    "        value = tf.einsum(\"...MI , HIO -> ...MHO\", value, self.value_kernel)\n",
    "\n",
    "        # Scale dot-product, doing the division to either query or key\n",
    "        # instead of their product saves some computation\n",
    "        depth = tf.constant(self.head_size, dtype=query.dtype)\n",
    "        query /= tf.sqrt(depth)\n",
    "\n",
    "        # Calculate dot product attention\n",
    "        logits = tf.einsum(\"...NHO,...MHO->...HNM\", query, key)\n",
    "\n",
    "        # apply mask\n",
    "        if mask is not None:\n",
    "            mask = tf.cast(mask, tf.float32)\n",
    "\n",
    "            # possibly expand on the head dimension so broadcasting works\n",
    "            if len(mask.shape) != len(logits.shape):\n",
    "                mask = tf.expand_dims(mask, -3)\n",
    "\n",
    "            logits += -10e9 * (1.0 - mask)\n",
    "\n",
    "        attn_coef = tf.nn.softmax(logits)\n",
    "\n",
    "        # attention dropout\n",
    "        attn_coef_dropout = self.dropout(attn_coef, training=training)\n",
    "\n",
    "        # attention * value\n",
    "        multihead_output = tf.einsum(\"...HNM,...MHI->...NHI\", attn_coef_dropout, value)\n",
    "\n",
    "        # Run the outputs through another linear projection layer. Recombining heads\n",
    "        # is automatically done.\n",
    "        output = tf.einsum(\n",
    "            \"...NHI,HIO->...NO\", multihead_output, self.projection_kernel\n",
    "        )\n",
    "\n",
    "        if self.projection_bias is not None:\n",
    "            output += self.projection_bias\n",
    "\n",
    "        if self.return_attn_coef:\n",
    "            return output, attn_coef\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        num_value_features = (\n",
    "            input_shape[2][-1] if len(input_shape) > 2 else input_shape[1][-1]\n",
    "        )\n",
    "        output_size = (\n",
    "            self.output_size if self.output_size is not None else num_value_features\n",
    "        )\n",
    "\n",
    "        output_shape = input_shape[0][:-1] + (output_size,)\n",
    "\n",
    "        if self.return_attn_coef:\n",
    "            num_query_elements = input_shape[0][-2]\n",
    "            num_key_elements = input_shape[1][-2]\n",
    "            attn_coef_shape = input_shape[0][:-2] + (\n",
    "                self.num_heads,\n",
    "                num_query_elements,\n",
    "                num_key_elements,\n",
    "            )\n",
    "\n",
    "            return output_shape, attn_coef_shape\n",
    "        else:\n",
    "            return output_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "\n",
    "        config.update(\n",
    "            head_size=self.head_size,\n",
    "            num_heads=self.num_heads,\n",
    "            output_size=self.output_size,\n",
    "            dropout=self._dropout_rate,\n",
    "            use_projection_bias=self.use_projection_bias,\n",
    "            return_attn_coef=self.return_attn_coef,\n",
    "            kernel_initializer=tf.keras.initializers.serialize(self.kernel_initializer),\n",
    "            kernel_regularizer=tf.keras.regularizers.serialize(self.kernel_regularizer),\n",
    "            kernel_constraint=tf.keras.constraints.serialize(self.kernel_constraint),\n",
    "            bias_initializer=tf.keras.initializers.serialize(self.bias_initializer),\n",
    "            bias_regularizer=tf.keras.regularizers.serialize(self.bias_regularizer),\n",
    "            bias_constraint=tf.keras.constraints.serialize(self.bias_constraint),\n",
    "        )\n",
    "\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.attention_layer = MultiHeadAttention(head_size=embed_dim, num_heads=num_heads)\n",
    "        self.ff_layer = tf.keras.Sequential(\n",
    "            [tf.keras.layers.Dense(ff_dim, activation=\"relu\"),\n",
    "             tf.keras.layers.Dense(embed_dim)]\n",
    "        )\n",
    "        self.add_norm_layer_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.add_norm_layer_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout_1 = tf.keras.layers.Dropout(dropout)\n",
    "        self.dropout_2 = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attention_output = self.attention_layer([inputs, inputs])\n",
    "        attention_output = self.dropout_1(attention_output, training=training)\n",
    "        input_to_ffn = self.add_norm_layer_1(inputs + attention_output)\n",
    "        ffn_output = self.ff_layer(input_to_ffn)\n",
    "        ffn_output = self.dropout_2(ffn_output, training=training)\n",
    "        return self.add_norm_layer_2(input_to_ffn + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get datasets for selected substation, load them as NumPy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('data/256_to_24_train_hourly.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.load('data/256_to_24_train_targets.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17824, 256), (17824, 24))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_eval = np.load('data/256_to_24_eval_hourly.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_eval = np.load('data/256_to_24_eval_targets.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1984, 256), (1984, 24))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_eval.shape, y_eval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use number of timesteps in the input sequence as the limit for positional encoding\n",
    "num_timesteps = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'input_1')>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input layer for Keras functional\n",
    "# use embedding dimension from SLDB as the input dimensionality\n",
    "input_layer = tf.keras.layers.Input(shape=(num_timesteps,))\n",
    "input_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 256, 1) dtype=float32 (created by layer 'tf.expand_dims')>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a layer to expand dimensions of input tensor,\n",
    "# required to project to a d_model space with a convolutional layer\n",
    "expanded_input_layer = tf.expand_dims(input_layer, axis=2)\n",
    "expanded_input_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensionality of Q, K, V\n",
    "embed_dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 256, 64) dtype=float32 (created by layer 'conv1d')>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a simple Conv1D layer to project time series data (scalar) to d_model\n",
    "value_embedding_layer = tf.keras.layers.Conv1D(filters=embed_dim,\n",
    "                                               kernel_size=3,\n",
    "                                               activation=\"relu\",\n",
    "                                               padding=\"same\")(expanded_input_layer)\n",
    "value_embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with a simple position encoding\n",
    "# for instance, the one in Keras Transformer-encoder block for text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a43d8d09a519>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpositions_to_encode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_timesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "positions_to_encode = tf.range(start=0, limit=num_timesteps, delta=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 64), dtype=float32, numpy=\n",
       "array([[ 0.02658891, -0.03204795, -0.03786908, ..., -0.02055534,\n",
       "        -0.02937177, -0.04134696],\n",
       "       [ 0.04068748, -0.00821483,  0.03064803, ...,  0.03557043,\n",
       "        -0.04187651,  0.00584674],\n",
       "       [ 0.03897362,  0.03680462, -0.04512105, ...,  0.00641111,\n",
       "        -0.04568533, -0.02206776],\n",
       "       ...,\n",
       "       [ 0.02469539, -0.00703088, -0.01136528, ...,  0.00360604,\n",
       "         0.01088633,  0.02674219],\n",
       "       [-0.01031395,  0.00929768, -0.00996647, ..., -0.00400395,\n",
       "         0.00120878, -0.00935572],\n",
       "       [ 0.02701252,  0.02953235,  0.00127114, ...,  0.02082128,\n",
       "        -0.04961213,  0.005363  ]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_embedding_layer = tf.keras.layers.Embedding(input_dim=num_timesteps,\n",
    "                                                     output_dim=embed_dim) (positions_to_encode)\n",
    "position_embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 256, 64) dtype=float32 (created by layer 'tf.__operators__.add')>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_to_transformer_block = value_embedding_layer + position_embedding_layer\n",
    "input_to_transformer_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 4\n",
    "ff_dim = 64\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/developer/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:74: DeprecationWarning: `MultiHeadAttention` will be deprecated in Addons 0.13. Please use `tf.keras.layers.MultiHeadAttention` instead.\n"
     ]
    }
   ],
   "source": [
    "encoder_layer_1 = EncoderLayer(embed_dim=embed_dim, num_heads=num_heads, ff_dim=ff_dim, dropout=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/developer/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:74: DeprecationWarning: `MultiHeadAttention` will be deprecated in Addons 0.13. Please use `tf.keras.layers.MultiHeadAttention` instead.\n"
     ]
    }
   ],
   "source": [
    "encoder_layer_2 = EncoderLayer(embed_dim=embed_dim, num_heads=num_heads, ff_dim=ff_dim, dropout=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/developer/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:74: DeprecationWarning: `MultiHeadAttention` will be deprecated in Addons 0.13. Please use `tf.keras.layers.MultiHeadAttention` instead.\n"
     ]
    }
   ],
   "source": [
    "encoder_layer_3 = EncoderLayer(embed_dim=embed_dim, num_heads=num_heads, ff_dim=ff_dim, dropout=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/developer/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:74: DeprecationWarning: `MultiHeadAttention` will be deprecated in Addons 0.13. Please use `tf.keras.layers.MultiHeadAttention` instead.\n"
     ]
    }
   ],
   "source": [
    "encoder_layer_4 = EncoderLayer(embed_dim=embed_dim, num_heads=num_heads, ff_dim=ff_dim, dropout=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 256, 64) dtype=float32 (created by layer 'encoder_layer_3')>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_from_encoder_1 = encoder_layer_1(input_to_transformer_block)\n",
    "output_from_encoder_2 = encoder_layer_2(output_from_encoder_1)\n",
    "output_from_encoder_3 = encoder_layer_3(output_from_encoder_2)\n",
    "output_from_encoder_4 = encoder_layer_4(output_from_encoder_3)\n",
    "\n",
    "output_from_encoder_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing the output from transformer block towards the target\n",
    "# case 1: based on TransformerBlock example at\n",
    "# https://keras.io/examples/nlp/text_classification_with_transformer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 64) dtype=float32 (created by layer 'global_average_pooling1d_1')>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_from_pooling = tf.keras.layers.GlobalAveragePooling1D()(output_from_encoder_4)\n",
    "output_from_pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_targets = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 24, 64) dtype=float32 (created by layer 'repeat_vector_1')>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeated = tf.keras.layers.RepeatVector(num_targets)(output_from_pooling)\n",
    "repeated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_dropout = tf.keras.layers.Dropout(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 24, 64) dtype=float32 (created by layer 'time_distributed_4')>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distributed_first_dropout = tf.keras.layers.TimeDistributed(first_dropout)(repeated)\n",
    "distributed_first_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "units_in_first_dense = 32\n",
    "first_dense = tf.keras.layers.Dense(units_in_first_dense, activation=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 24, 32) dtype=float32 (created by layer 'time_distributed_5')>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distributed_first_dense = tf.keras.layers.TimeDistributed(first_dense)(distributed_first_dropout)\n",
    "distributed_first_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_dropout = tf.keras.layers.Dropout(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 24, 32) dtype=float32 (created by layer 'time_distributed_6')>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distributed_second_dropout = tf.keras.layers.TimeDistributed(second_dropout)(distributed_first_dense)\n",
    "distributed_second_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "units_in_second_dense = 1\n",
    "second_dense = tf.keras.layers.Dense(units_in_second_dense, activation=\"sigmoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 24, 1) dtype=float32 (created by layer 'time_distributed_7')>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distributed_second_dense = tf.keras.layers.TimeDistributed(second_dense)(distributed_second_dropout)\n",
    "distributed_second_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 24) dtype=float32 (created by layer 'tf.compat.v1.squeeze_1')>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squeezed_output = tf.keras.backend.squeeze(distributed_second_dense, axis=-1)\n",
    "squeezed_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=input_layer, outputs=squeezed_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\"adam\", \"mse\", metrics=[tf.keras.metrics.RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "557/557 [==============================] - 1035s 2s/step - loss: 0.0442 - root_mean_squared_error: 0.2095 - val_loss: 0.0431 - val_root_mean_squared_error: 0.2075\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train, batch_size=32, epochs=1, validation_data=(x_eval, y_eval)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
