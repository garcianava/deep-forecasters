{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer-decoder with no Seq2Seq component (autoregressive)\n",
    "\n",
    "# no value embedding\n",
    "# sine-cosine positional encoding on the hour, day, and month of timestamp\n",
    "# modified transformer-encoder layer for masked self-attention\n",
    "\n",
    "# conduct an architecture test similar to the one on the transformer-encoder in\n",
    "# deep_transformer_model_for_tsf_XX.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required for TFA MultiHeadAttention\n",
    "import typing\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MHA class from TensorFlow AddOns source\n",
    "# it is compatible with TF 1.15 for CloudTPU usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    r\"\"\"MultiHead Attention layer.\n",
    "    Defines the MultiHead Attention operation as described in\n",
    "    [Attention Is All You Need](https://arxiv.org/abs/1706.03762) which takes\n",
    "    in the tensors `query`, `key`, and `value`, and returns the dot-product attention\n",
    "    between them:\n",
    "    >>> mha = MultiHeadAttention(head_size=128, num_heads=12)\n",
    "    >>> query = np.random.rand(3, 5, 4) # (batch_size, query_elements, query_depth)\n",
    "    >>> key = np.random.rand(3, 6, 5) # (batch_size, key_elements, key_depth)\n",
    "    >>> value = np.random.rand(3, 6, 6) # (batch_size, key_elements, value_depth)\n",
    "    >>> attention = mha([query, key, value]) # (batch_size, query_elements, value_depth)\n",
    "    >>> attention.shape\n",
    "    TensorShape([3, 5, 6])\n",
    "    If `value` is not given then internally `value = key` will be used:\n",
    "    >>> mha = MultiHeadAttention(head_size=128, num_heads=12)\n",
    "    >>> query = np.random.rand(3, 5, 5) # (batch_size, query_elements, query_depth)\n",
    "    >>> key = np.random.rand(3, 6, 10) # (batch_size, key_elements, key_depth)\n",
    "    >>> attention = mha([query, key]) # (batch_size, query_elements, key_depth)\n",
    "    >>> attention.shape\n",
    "    TensorShape([3, 5, 10])\n",
    "    Args:\n",
    "        head_size: int, dimensionality of the `query`, `key` and `value` tensors\n",
    "            after the linear transformation.\n",
    "        num_heads: int, number of attention heads.\n",
    "        output_size: int, dimensionality of the output space, if `None` then the\n",
    "            input dimension of `value` or `key` will be used,\n",
    "            default `None`.\n",
    "        dropout: float, `rate` parameter for the dropout layer that is\n",
    "            applied to attention after softmax,\n",
    "        default `0`.\n",
    "        use_projection_bias: bool, whether to use a bias term after the linear\n",
    "            output projection.\n",
    "        return_attn_coef: bool, if `True`, return the attention coefficients as\n",
    "            an additional output argument.\n",
    "        kernel_initializer: initializer, initializer for the kernel weights.\n",
    "        kernel_regularizer: regularizer, regularizer for the kernel weights.\n",
    "        kernel_constraint: constraint, constraint for the kernel weights.\n",
    "        bias_initializer: initializer, initializer for the bias weights.\n",
    "        bias_regularizer: regularizer, regularizer for the bias weights.\n",
    "        bias_constraint: constraint, constraint for the bias weights.\n",
    "    Call Args:\n",
    "        inputs:  List of `[query, key, value]` where\n",
    "            * `query`: Tensor of shape `(..., query_elements, query_depth)`\n",
    "            * `key`: `Tensor of shape '(..., key_elements, key_depth)`\n",
    "            * `value`: Tensor of shape `(..., key_elements, value_depth)`, optional, if not given `key` will be used.\n",
    "        mask: a binary Tensor of shape `[batch_size?, num_heads?, query_elements, key_elements]`\n",
    "        which specifies which query elements can attend to which key elements,\n",
    "        `1` indicates attention and `0` indicates no attention.\n",
    "    Output shape:\n",
    "        * `(..., query_elements, output_size)` if `output_size` is given, else\n",
    "        * `(..., query_elements, value_depth)` if `value` is given, else\n",
    "        * `(..., query_elements, key_depth)`\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        head_size: int,\n",
    "        num_heads: int,\n",
    "        output_size: int = None,\n",
    "        dropout: float = 0.0,\n",
    "        use_projection_bias: bool = True,\n",
    "        return_attn_coef: bool = False,\n",
    "        kernel_initializer: typing.Union[str, typing.Callable] = \"glorot_uniform\",\n",
    "        kernel_regularizer: typing.Union[str, typing.Callable] = None,\n",
    "        kernel_constraint: typing.Union[str, typing.Callable] = None,\n",
    "        bias_initializer: typing.Union[str, typing.Callable] = \"zeros\",\n",
    "        bias_regularizer: typing.Union[str, typing.Callable] = None,\n",
    "        bias_constraint: typing.Union[str, typing.Callable] = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        warnings.warn(\n",
    "            \"`MultiHeadAttention` will be deprecated in Addons 0.13. \"\n",
    "            \"Please use `tf.keras.layers.MultiHeadAttention` instead.\",\n",
    "            DeprecationWarning,\n",
    "        )\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        if output_size is not None and output_size < 1:\n",
    "            raise ValueError(\"output_size must be a positive number\")\n",
    "\n",
    "        self.head_size = head_size\n",
    "        self.num_heads = num_heads\n",
    "        self.output_size = output_size\n",
    "        self.use_projection_bias = use_projection_bias\n",
    "        self.return_attn_coef = return_attn_coef\n",
    "\n",
    "        self.kernel_initializer = tf.keras.initializers.get(kernel_initializer)\n",
    "        self.kernel_regularizer = tf.keras.regularizers.get(kernel_regularizer)\n",
    "        self.kernel_constraint = tf.keras.constraints.get(kernel_constraint)\n",
    "        self.bias_initializer = tf.keras.initializers.get(bias_initializer)\n",
    "        self.bias_regularizer = tf.keras.regularizers.get(bias_regularizer)\n",
    "        self.bias_constraint = tf.keras.constraints.get(bias_constraint)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "        self._dropout_rate = dropout\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        num_query_features = input_shape[0][-1]\n",
    "        num_key_features = input_shape[1][-1]\n",
    "        num_value_features = (\n",
    "            input_shape[2][-1] if len(input_shape) > 2 else num_key_features\n",
    "        )\n",
    "        output_size = (\n",
    "            self.output_size if self.output_size is not None else num_value_features\n",
    "        )\n",
    "\n",
    "        self.query_kernel = self.add_weight(\n",
    "            name=\"query_kernel\",\n",
    "            shape=[self.num_heads, num_query_features, self.head_size],\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            constraint=self.kernel_constraint,\n",
    "        )\n",
    "        self.key_kernel = self.add_weight(\n",
    "            name=\"key_kernel\",\n",
    "            shape=[self.num_heads, num_key_features, self.head_size],\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            constraint=self.kernel_constraint,\n",
    "        )\n",
    "        self.value_kernel = self.add_weight(\n",
    "            name=\"value_kernel\",\n",
    "            shape=[self.num_heads, num_value_features, self.head_size],\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            constraint=self.kernel_constraint,\n",
    "        )\n",
    "        self.projection_kernel = self.add_weight(\n",
    "            name=\"projection_kernel\",\n",
    "            shape=[self.num_heads, self.head_size, output_size],\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            constraint=self.kernel_constraint,\n",
    "        )\n",
    "\n",
    "        if self.use_projection_bias:\n",
    "            self.projection_bias = self.add_weight(\n",
    "                name=\"projection_bias\",\n",
    "                shape=[output_size],\n",
    "                initializer=self.bias_initializer,\n",
    "                regularizer=self.bias_regularizer,\n",
    "                constraint=self.bias_constraint,\n",
    "            )\n",
    "        else:\n",
    "            self.projection_bias = None\n",
    "\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "\n",
    "        # einsum nomenclature\n",
    "        # ------------------------\n",
    "        # N = query elements\n",
    "        # M = key/value elements\n",
    "        # H = heads\n",
    "        # I = input features\n",
    "        # O = output features\n",
    "\n",
    "        query = inputs[0]\n",
    "        key = inputs[1]\n",
    "        value = inputs[2] if len(inputs) > 2 else key\n",
    "\n",
    "        # verify shapes\n",
    "        if key.shape[-2] != value.shape[-2]:\n",
    "            raise ValueError(\n",
    "                \"the number of elements in 'key' must be equal to the same as the number of elements in 'value'\"\n",
    "            )\n",
    "\n",
    "        if mask is not None:\n",
    "            if len(mask.shape) < 2:\n",
    "                raise ValueError(\"'mask' must have atleast 2 dimensions\")\n",
    "            if query.shape[-2] != mask.shape[-2]:\n",
    "                raise ValueError(\n",
    "                    \"mask's second to last dimension must be equal to the number of elements in 'query'\"\n",
    "                )\n",
    "            if key.shape[-2] != mask.shape[-1]:\n",
    "                raise ValueError(\n",
    "                    \"mask's last dimension must be equal to the number of elements in 'key'\"\n",
    "                )\n",
    "\n",
    "        # Linear transformations\n",
    "        query = tf.einsum(\"...NI , HIO -> ...NHO\", query, self.query_kernel)\n",
    "        key = tf.einsum(\"...MI , HIO -> ...MHO\", key, self.key_kernel)\n",
    "        value = tf.einsum(\"...MI , HIO -> ...MHO\", value, self.value_kernel)\n",
    "\n",
    "        # Scale dot-product, doing the division to either query or key\n",
    "        # instead of their product saves some computation\n",
    "        depth = tf.constant(self.head_size, dtype=query.dtype)\n",
    "        query /= tf.sqrt(depth)\n",
    "\n",
    "        # Calculate dot product attention\n",
    "        logits = tf.einsum(\"...NHO,...MHO->...HNM\", query, key)\n",
    "\n",
    "        # apply mask\n",
    "        if mask is not None:\n",
    "            mask = tf.cast(mask, tf.float32)\n",
    "\n",
    "            # possibly expand on the head dimension so broadcasting works\n",
    "            if len(mask.shape) != len(logits.shape):\n",
    "                mask = tf.expand_dims(mask, -3)\n",
    "\n",
    "            logits += -10e9 * (1.0 - mask)\n",
    "\n",
    "        attn_coef = tf.nn.softmax(logits)\n",
    "\n",
    "        # attention dropout\n",
    "        attn_coef_dropout = self.dropout(attn_coef, training=training)\n",
    "\n",
    "        # attention * value\n",
    "        multihead_output = tf.einsum(\"...HNM,...MHI->...NHI\", attn_coef_dropout, value)\n",
    "\n",
    "        # Run the outputs through another linear projection layer. Recombining heads\n",
    "        # is automatically done.\n",
    "        output = tf.einsum(\n",
    "            \"...NHI,HIO->...NO\", multihead_output, self.projection_kernel\n",
    "        )\n",
    "\n",
    "        if self.projection_bias is not None:\n",
    "            output += self.projection_bias\n",
    "\n",
    "        if self.return_attn_coef:\n",
    "            return output, attn_coef\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        num_value_features = (\n",
    "            input_shape[2][-1] if len(input_shape) > 2 else input_shape[1][-1]\n",
    "        )\n",
    "        output_size = (\n",
    "            self.output_size if self.output_size is not None else num_value_features\n",
    "        )\n",
    "\n",
    "        output_shape = input_shape[0][:-1] + (output_size,)\n",
    "\n",
    "        if self.return_attn_coef:\n",
    "            num_query_elements = input_shape[0][-2]\n",
    "            num_key_elements = input_shape[1][-2]\n",
    "            attn_coef_shape = input_shape[0][:-2] + (\n",
    "                self.num_heads,\n",
    "                num_query_elements,\n",
    "                num_key_elements,\n",
    "            )\n",
    "\n",
    "            return output_shape, attn_coef_shape\n",
    "        else:\n",
    "            return output_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "\n",
    "        config.update(\n",
    "            head_size=self.head_size,\n",
    "            num_heads=self.num_heads,\n",
    "            output_size=self.output_size,\n",
    "            dropout=self._dropout_rate,\n",
    "            use_projection_bias=self.use_projection_bias,\n",
    "            return_attn_coef=self.return_attn_coef,\n",
    "            kernel_initializer=tf.keras.initializers.serialize(self.kernel_initializer),\n",
    "            kernel_regularizer=tf.keras.regularizers.serialize(self.kernel_regularizer),\n",
    "            kernel_constraint=tf.keras.constraints.serialize(self.kernel_constraint),\n",
    "            bias_initializer=tf.keras.initializers.serialize(self.bias_initializer),\n",
    "            bias_regularizer=tf.keras.regularizers.serialize(self.bias_regularizer),\n",
    "            bias_constraint=tf.keras.constraints.serialize(self.bias_constraint),\n",
    "        )\n",
    "\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[1., 0., 0.],\n",
       "       [1., 1., 0.],\n",
       "       [1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate triangular mask for self-attention\n",
    "# as a TensorFlow tensor\n",
    "d = 3\n",
    "tf.convert_to_tensor(np.tril(np.ones([d, d]), 0), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the autoregressive version of the transformer-decoder does not use the Seq2Seq intermediate layer\n",
    "# as there is no transformer-encoder component that sends encoding hidden states, therefore\n",
    "# having only a self-attention layer and position-wise feed-forward layer,\n",
    "# the autoregressive transformer-decoder is, in fact, a transformer-encoder\n",
    "\n",
    "# the only important modification is the masked self-attention layer\n",
    "\n",
    "# masked self-attention layer seems to be already implemented in\n",
    "# MHA module from TensorFlow AddOns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base transformer encoder layer from # https://keras.io/examples/nlp/text_classification_with_transformer/\n",
    "# modified to include masked self attention\n",
    "\n",
    "# pass number of timesteps as an argument for the encoder layer\n",
    "# ToDo: get the number of timesteps from the input shape\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, n_timesteps, embed_dim, num_heads, ff_dim, dropout=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        # multi-head attention initialization\n",
    "        self.attention_layer = MultiHeadAttention(head_size=embed_dim, num_heads=num_heads)\n",
    "        self.ff_layer = tf.keras.Sequential(\n",
    "            [tf.keras.layers.Dense(ff_dim, activation=\"relu\"),\n",
    "             tf.keras.layers.Dense(embed_dim)]\n",
    "        )\n",
    "        self.add_norm_layer_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.add_norm_layer_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout_1 = tf.keras.layers.Dropout(dropout)\n",
    "        self.dropout_2 = tf.keras.layers.Dropout(dropout)\n",
    "        # mask for self-attention\n",
    "        self.mask = tf.convert_to_tensor(np.tril(np.ones([n_timesteps, n_timesteps]), 0), dtype=tf.float32)\n",
    "\n",
    "        \n",
    "    def call(self, inputs, training):\n",
    "        # mask for self-attention is passed to MHA on call\n",
    "        attention_output = self.attention_layer([inputs, inputs], mask=self.mask)\n",
    "        attention_output = self.dropout_1(attention_output, training=training)\n",
    "        input_to_ffn = self.add_norm_layer_1(inputs + attention_output)\n",
    "        ffn_output = self.ff_layer(input_to_ffn)\n",
    "        ffn_output = self.dropout_2(ffn_output, training=training)\n",
    "        return self.add_norm_layer_2(input_to_ffn + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8\r\n",
      "drwxrwxr-x 2 developer developer 4096 feb 11 13:08 CPE04115_H_kw_20201021084001\r\n",
      "drwxrwxr-x 2 developer developer 4096 feb 16 13:17 CPE04115_H_kw_20201021084001_csv\r\n"
     ]
    }
   ],
   "source": [
    "# get the active power time series as main data source\n",
    "! ls -l /home/developer/gcp/cbidmltsf/timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 364\r\n",
      "-rw-rw-r-- 1 developer developer    621 oct 21  2020 scaler.save\r\n",
      "-rw-rw-r-- 1 developer developer    218 oct 21  2020 ts.json\r\n",
      "-rw-rw-r-- 1 developer developer 362977 oct 21  2020 ts.pkl\r\n"
     ]
    }
   ],
   "source": [
    "! ls -l /home/developer/gcp/cbidmltsf/timeseries/CPE04115_H_kw_20201021084001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.read_pickle(\"/home/developer/gcp/cbidmltsf/timeseries/CPE04115_H_kw_20201021084001/ts.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kw_scaled</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01 00:00:00</th>\n",
       "      <td>0.274317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 01:00:00</th>\n",
       "      <td>0.217363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 02:00:00</th>\n",
       "      <td>0.168545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 03:00:00</th>\n",
       "      <td>0.122996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 04:00:00</th>\n",
       "      <td>0.080440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     kw_scaled\n",
       "timestamp                     \n",
       "2016-01-01 00:00:00   0.274317\n",
       "2016-01-01 01:00:00   0.217363\n",
       "2016-01-01 02:00:00   0.168545\n",
       "2016-01-01 03:00:00   0.122996\n",
       "2016-01-01 04:00:00   0.080440"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a training dataset\n",
    "# features: m consecutive lectures with their timestamps\n",
    "# target: m consecutive lectures (lectures in features, shifted by 1 to the future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22629"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# length of time series\n",
    "ts['kw_scaled'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of input sequence\n",
    "m = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare sine-cosine positional encoding for the input sequence\n",
    "hours_in_day = 24\n",
    "days_in_month = 30\n",
    "months_in_year = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a collection of examples for training\n",
    "# use a range on the time series index\n",
    "train_range = np.arange(0, 1000)\n",
    "\n",
    "features_list = list()\n",
    "targets_list = list()\n",
    "\n",
    "for start in train_range:\n",
    "    end = start + m\n",
    "    values = np.expand_dims(ts[start:end]['kw_scaled'].values, axis=1)\n",
    "    target_values = np.expand_dims(ts[1+start:1+end]['kw_scaled'].values, axis=1)\n",
    "    \n",
    "    timestamps_hour = ts[start:end].index.hour\n",
    "    timestamps_day = ts[start:end].index.day\n",
    "    timestamps_month = ts[start:end].index.month\n",
    "    \n",
    "    sin_hour = np.expand_dims(np.sin(2*np.pi*timestamps_hour/hours_in_day), axis=1)\n",
    "    cos_hour = np.expand_dims(np.sin(2*np.pi*timestamps_hour/hours_in_day), axis=1)\n",
    "    sin_day = np.expand_dims(np.sin(2*np.pi*timestamps_day/days_in_month), axis=1)\n",
    "    cos_day = np.expand_dims(np.cos(2*np.pi*timestamps_day/days_in_month), axis=1)\n",
    "    sin_month = np.expand_dims(np.sin(2*np.pi*timestamps_month/months_in_year), axis=1)\n",
    "    cos_month = np.expand_dims(np.cos(2*np.pi*timestamps_month/months_in_year), axis=1)\n",
    "    \n",
    "    feature_row = np.concatenate((values, sin_hour, cos_hour, sin_day, cos_day, sin_month, cos_month), axis=1)    \n",
    "\n",
    "    features_list.append(feature_row)\n",
    "    targets_list.append(target_values)\n",
    "\n",
    "x_train = np.array(features_list)\n",
    "y_train = np.array(targets_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 48, 7), (1000, 48, 1))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.27431688, 0.21736328, 0.16854513, 0.12299635, 0.08044036,\n",
       "       0.04925277, 0.06771694, 0.04966028, 0.02315827, 0.0611418 ,\n",
       "       0.16809889, 0.23126119, 0.28965889, 0.31682717, 0.34027286,\n",
       "       0.37148524, 0.3697847 , 0.38247015, 0.44962929, 0.56348924,\n",
       "       0.53345987, 0.51550237, 0.43560898, 0.32928794, 0.23602656,\n",
       "       0.14696731, 0.09737444, 0.04251571, 0.04444092, 0.06843589,\n",
       "       0.12769277, 0.15101761, 0.1872332 , 0.24428829, 0.30788212,\n",
       "       0.37800538, 0.41353456, 0.43940206, 0.43413931, 0.40126436,\n",
       "       0.37682159, 0.41638402, 0.47179745, 0.59373552, 0.59430882,\n",
       "       0.59690262, 0.53751327, 0.3898944 ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.21736328, 0.16854513, 0.12299635, 0.08044036, 0.04925277,\n",
       "       0.06771694, 0.04966028, 0.02315827, 0.0611418 , 0.16809889,\n",
       "       0.23126119, 0.28965889, 0.31682717, 0.34027286, 0.37148524,\n",
       "       0.3697847 , 0.38247015, 0.44962929, 0.56348924, 0.53345987,\n",
       "       0.51550237, 0.43560898, 0.32928794, 0.23602656, 0.14696731,\n",
       "       0.09737444, 0.04251571, 0.04444092, 0.06843589, 0.12769277,\n",
       "       0.15101761, 0.1872332 , 0.24428829, 0.30788212, 0.37800538,\n",
       "       0.41353456, 0.43940206, 0.43413931, 0.40126436, 0.37682159,\n",
       "       0.41638402, 0.47179745, 0.59373552, 0.59430882, 0.59690262,\n",
       "       0.53751327, 0.3898944 , 0.27423011])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training with teacher forcing\n",
    "# pass only true values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a collection of examples for evaluation\n",
    "# use a range on the time series index\n",
    "eval_range = np.arange(1100, 1300)\n",
    "\n",
    "features_list = list()\n",
    "targets_list = list()\n",
    "\n",
    "for start in eval_range:\n",
    "    end = start + m\n",
    "    values = np.expand_dims(ts[start:end]['kw_scaled'].values, axis=1)\n",
    "    target_values = np.expand_dims(ts[1+start:1+end]['kw_scaled'].values, axis=1)\n",
    "    \n",
    "    timestamps_hour = ts[start:end].index.hour\n",
    "    timestamps_day = ts[start:end].index.day\n",
    "    timestamps_month = ts[start:end].index.month\n",
    "    \n",
    "    sin_hour = np.expand_dims(np.sin(2*np.pi*timestamps_hour/hours_in_day), axis=1)\n",
    "    cos_hour = np.expand_dims(np.sin(2*np.pi*timestamps_hour/hours_in_day), axis=1)\n",
    "    sin_day = np.expand_dims(np.sin(2*np.pi*timestamps_day/days_in_month), axis=1)\n",
    "    cos_day = np.expand_dims(np.cos(2*np.pi*timestamps_day/days_in_month), axis=1)\n",
    "    sin_month = np.expand_dims(np.sin(2*np.pi*timestamps_month/months_in_year), axis=1)\n",
    "    cos_month = np.expand_dims(np.cos(2*np.pi*timestamps_month/months_in_year), axis=1)\n",
    "    \n",
    "    feature_row = np.concatenate((values, sin_hour, cos_hour, sin_day, cos_day, sin_month, cos_month), axis=1)    \n",
    "\n",
    "    features_list.append(feature_row)\n",
    "    targets_list.append(target_values)\n",
    "\n",
    "x_eval = np.array(features_list)\n",
    "y_eval = np.array(targets_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 48, 7), (200, 48, 1))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_eval.shape, y_eval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.61518706, 0.57427117, 0.4674117 , 0.34486934, 0.2245218 ,\n",
       "       0.15264377, 0.10878081, 0.07731354, 0.05909031, 0.05338674,\n",
       "       0.14980825, 0.19518737, 0.20623891, 0.21277067, 0.29595125,\n",
       "       0.31055726, 0.33621482, 0.36981647, 0.37839197, 0.38991145,\n",
       "       0.39248666, 0.40448492, 0.42273217, 0.55039318, 0.61994778,\n",
       "       0.56638596, 0.45977285, 0.31207109, 0.19304601, 0.11578748,\n",
       "       0.08181241, 0.07105061, 0.05574425, 0.07363279, 0.17405657,\n",
       "       0.23519682, 0.27807665, 0.33219551, 0.399436  , 0.41929778,\n",
       "       0.47372576, 0.51229809, 0.51688914, 0.5222681 , 0.51115691,\n",
       "       0.52278717, 0.55290486, 0.69725978])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_eval[0, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.57427117, 0.4674117 , 0.34486934, 0.2245218 , 0.15264377,\n",
       "       0.10878081, 0.07731354, 0.05909031, 0.05338674, 0.14980825,\n",
       "       0.19518737, 0.20623891, 0.21277067, 0.29595125, 0.31055726,\n",
       "       0.33621482, 0.36981647, 0.37839197, 0.38991145, 0.39248666,\n",
       "       0.40448492, 0.42273217, 0.55039318, 0.61994778, 0.56638596,\n",
       "       0.45977285, 0.31207109, 0.19304601, 0.11578748, 0.08181241,\n",
       "       0.07105061, 0.05574425, 0.07363279, 0.17405657, 0.23519682,\n",
       "       0.27807665, 0.33219551, 0.399436  , 0.41929778, 0.47372576,\n",
       "       0.51229809, 0.51688914, 0.5222681 , 0.51115691, 0.52278717,\n",
       "       0.55290486, 0.69725978, 0.68099739])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_eval[0, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# architecture details according to the Klingenbrunn experiment\n",
    "# (including notes to further modifications on the basic autoregressive model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of timesteps is the length of the input sequence,\n",
    "# is the embedding dimension from SLDB\n",
    "num_timesteps = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of features is the active load value (main feature)\n",
    "# plus the six components of the sine-cosine positional encoding on hour, day, month\n",
    "\n",
    "# important: there is no value embedding, therefore d_model is very low\n",
    "d_model = 7\n",
    "\n",
    "# ToDo: use value embedding to a high-dimensional space and compare results\n",
    "# ToDo: use a different positional encoding system and compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as long as there is no value embedding, neither convolutional nor dense layers are required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 48, 7) dtype=float32 (created by layer 'input_1')>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input layer for Keras functional\n",
    "input_layer = tf.keras.layers.Input(shape=(num_timesteps, d_model))\n",
    "input_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 48, 7) dtype=float32 (created by layer 'input_1')>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_to_transformer_block = input_layer\n",
    "input_to_transformer_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 4\n",
    "ff_dim = 256\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/developer/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:74: DeprecationWarning: `MultiHeadAttention` will be deprecated in Addons 0.13. Please use `tf.keras.layers.MultiHeadAttention` instead.\n"
     ]
    }
   ],
   "source": [
    "encoder_layer_1 = EncoderLayer(n_timesteps=num_timesteps,\n",
    "                               embed_dim=d_model,\n",
    "                               num_heads=num_heads,\n",
    "                               ff_dim=ff_dim,\n",
    "                               dropout=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/developer/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:74: DeprecationWarning: `MultiHeadAttention` will be deprecated in Addons 0.13. Please use `tf.keras.layers.MultiHeadAttention` instead.\n"
     ]
    }
   ],
   "source": [
    "encoder_layer_2 = EncoderLayer(n_timesteps=num_timesteps,\n",
    "                               embed_dim=d_model,\n",
    "                               num_heads=num_heads,\n",
    "                               ff_dim=ff_dim,\n",
    "                               dropout=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 48, 7) dtype=float32 (created by layer 'encoder_layer_2')>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_from_encoder_1 = encoder_layer_1(input_to_transformer_block)\n",
    "output_from_encoder_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 48, 7) dtype=float32 (created by layer 'encoder_layer_3')>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_from_encoder_2 = encoder_layer_2(output_from_encoder_1)\n",
    "output_from_encoder_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klingenbrunn uses a linear layer to decode the output_from_encoder\n",
    "# from (?, num_timesteps, num_features) to (?, num_timesteps, 1)\n",
    "\n",
    "# the equivalent operation in TensorFlow is a TimeDistributed Dense layer to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "units_in_first_dense = 1\n",
    "first_dense = tf.keras.layers.Dense(units_in_first_dense, activation=\"sigmoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 48, 1) dtype=float32 (created by layer 'time_distributed_3')>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distributed_first_dense = tf.keras.layers.TimeDistributed(first_dense)(output_from_encoder_2)\n",
    "distributed_first_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=input_layer, outputs=distributed_first_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\"adam\", \"mse\", metrics=[tf.keras.metrics.RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "32/32 [==============================] - 3s 34ms/step - loss: 0.0026 - root_mean_squared_error: 0.0506 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0596\n",
      "Epoch 2/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0014 - root_mean_squared_error: 0.0369 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0620\n",
      "Epoch 3/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0013 - root_mean_squared_error: 0.0360 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0624\n",
      "Epoch 4/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0013 - root_mean_squared_error: 0.0356 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0636\n",
      "Epoch 5/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0013 - root_mean_squared_error: 0.0360 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0618\n",
      "Epoch 6/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0013 - root_mean_squared_error: 0.0362 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0610\n",
      "Epoch 7/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0013 - root_mean_squared_error: 0.0363 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0626\n",
      "Epoch 8/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0012 - root_mean_squared_error: 0.0351 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0637\n",
      "Epoch 9/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0013 - root_mean_squared_error: 0.0355 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0629\n",
      "Epoch 10/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0012 - root_mean_squared_error: 0.0351 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0636\n",
      "Epoch 11/500\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.0013 - root_mean_squared_error: 0.0354 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0629\n",
      "Epoch 12/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0013 - root_mean_squared_error: 0.0356 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0651\n",
      "Epoch 13/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0013 - root_mean_squared_error: 0.0357 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0660\n",
      "Epoch 14/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0013 - root_mean_squared_error: 0.0358 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0664\n",
      "Epoch 15/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0013 - root_mean_squared_error: 0.0359 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0653\n",
      "Epoch 16/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0012 - root_mean_squared_error: 0.0351 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0656\n",
      "Epoch 17/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0013 - root_mean_squared_error: 0.0355 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0628\n",
      "Epoch 18/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0012 - root_mean_squared_error: 0.0353 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0655\n",
      "Epoch 19/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0013 - root_mean_squared_error: 0.0355 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0667\n",
      "Epoch 20/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0013 - root_mean_squared_error: 0.0354 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0660\n",
      "Epoch 21/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0013 - root_mean_squared_error: 0.0357 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0652\n",
      "Epoch 22/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0012 - root_mean_squared_error: 0.0348 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0630\n",
      "Epoch 23/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0013 - root_mean_squared_error: 0.0358 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0652\n",
      "Epoch 24/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0012 - root_mean_squared_error: 0.0352 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0628\n",
      "Epoch 25/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0012 - root_mean_squared_error: 0.0345 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0640\n",
      "Epoch 26/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0012 - root_mean_squared_error: 0.0352 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0673\n",
      "Epoch 27/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0012 - root_mean_squared_error: 0.0347 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0623\n",
      "Epoch 28/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0012 - root_mean_squared_error: 0.0348 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0630\n",
      "Epoch 29/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0012 - root_mean_squared_error: 0.0344 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0664\n",
      "Epoch 30/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0012 - root_mean_squared_error: 0.0350 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0632\n",
      "Epoch 31/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0012 - root_mean_squared_error: 0.0349 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0628\n",
      "Epoch 32/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0012 - root_mean_squared_error: 0.0346 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0637\n",
      "Epoch 33/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0012 - root_mean_squared_error: 0.0349 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0647\n",
      "Epoch 34/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0012 - root_mean_squared_error: 0.0347 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0666\n",
      "Epoch 35/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0012 - root_mean_squared_error: 0.0348 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0616\n",
      "Epoch 36/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0012 - root_mean_squared_error: 0.0345 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0633\n",
      "Epoch 37/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0012 - root_mean_squared_error: 0.0347 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0617\n",
      "Epoch 38/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0012 - root_mean_squared_error: 0.0349 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0649\n",
      "Epoch 39/500\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.0012 - root_mean_squared_error: 0.0342 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0641\n",
      "Epoch 40/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0012 - root_mean_squared_error: 0.0349 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0617\n",
      "Epoch 41/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0012 - root_mean_squared_error: 0.0347 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0681\n",
      "Epoch 42/500\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.0012 - root_mean_squared_error: 0.0347 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0639\n",
      "Epoch 43/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0012 - root_mean_squared_error: 0.0344 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0657\n",
      "Epoch 44/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0012 - root_mean_squared_error: 0.0346 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0626\n",
      "Epoch 45/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0012 - root_mean_squared_error: 0.0340 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0622\n",
      "Epoch 46/500\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 0.0012 - root_mean_squared_error: 0.0341 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0633\n",
      "Epoch 47/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0012 - root_mean_squared_error: 0.0339 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0640\n",
      "Epoch 48/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0012 - root_mean_squared_error: 0.0342 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0627\n",
      "Epoch 49/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0011 - root_mean_squared_error: 0.0330 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0633\n",
      "Epoch 50/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0011 - root_mean_squared_error: 0.0332 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0612\n",
      "Epoch 51/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0013 - root_mean_squared_error: 0.0360 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0625\n",
      "Epoch 52/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0011 - root_mean_squared_error: 0.0336 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0653\n",
      "Epoch 53/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0011 - root_mean_squared_error: 0.0338 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0636\n",
      "Epoch 54/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0012 - root_mean_squared_error: 0.0340 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0634\n",
      "Epoch 55/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0012 - root_mean_squared_error: 0.0340 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0604\n",
      "Epoch 56/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0011 - root_mean_squared_error: 0.0334 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0636\n",
      "Epoch 57/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0011 - root_mean_squared_error: 0.0339 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0591\n",
      "Epoch 58/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0011 - root_mean_squared_error: 0.0338 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0663\n",
      "Epoch 59/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0611\n",
      "Epoch 60/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0012 - root_mean_squared_error: 0.0349 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0622\n",
      "Epoch 61/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0011 - root_mean_squared_error: 0.0329 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0638\n",
      "Epoch 62/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0010 - root_mean_squared_error: 0.0324 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0626\n",
      "Epoch 63/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0011 - root_mean_squared_error: 0.0336 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0616\n",
      "Epoch 64/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0011 - root_mean_squared_error: 0.0335 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0623\n",
      "Epoch 65/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0659\n",
      "Epoch 66/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0631\n",
      "Epoch 67/500\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - root_mean_squared_error: 0.0334 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0637\n",
      "Epoch 68/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0011 - root_mean_squared_error: 0.0325 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0602\n",
      "Epoch 69/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0011 - root_mean_squared_error: 0.0333 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0630\n",
      "Epoch 70/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0011 - root_mean_squared_error: 0.0326 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0598\n",
      "Epoch 71/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0010 - root_mean_squared_error: 0.0322 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0635\n",
      "Epoch 72/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0646\n",
      "Epoch 73/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0634\n",
      "Epoch 74/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0010 - root_mean_squared_error: 0.0323 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0613\n",
      "Epoch 75/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0011 - root_mean_squared_error: 0.0327 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0630\n",
      "Epoch 76/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0010 - root_mean_squared_error: 0.0318 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0649\n",
      "Epoch 77/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0010 - root_mean_squared_error: 0.0323 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0655\n",
      "Epoch 78/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0618\n",
      "Epoch 79/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0011 - root_mean_squared_error: 0.0325 - val_loss: 0.0034 - val_root_mean_squared_error: 0.0587\n",
      "Epoch 80/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0011 - root_mean_squared_error: 0.0324 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0630\n",
      "Epoch 81/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0010 - root_mean_squared_error: 0.0321 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0635\n",
      "Epoch 82/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0010 - root_mean_squared_error: 0.0324 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0613\n",
      "Epoch 83/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0616\n",
      "Epoch 84/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0011 - root_mean_squared_error: 0.0324 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0613\n",
      "Epoch 85/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0010 - root_mean_squared_error: 0.0323 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0594\n",
      "Epoch 86/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0011 - root_mean_squared_error: 0.0334 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0650\n",
      "Epoch 87/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0012 - root_mean_squared_error: 0.0341 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0607\n",
      "Epoch 88/500\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 0.0011 - root_mean_squared_error: 0.0330 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0621\n",
      "Epoch 89/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0011 - root_mean_squared_error: 0.0335 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0633\n",
      "Epoch 90/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0011 - root_mean_squared_error: 0.0338 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0638\n",
      "Epoch 91/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0011 - root_mean_squared_error: 0.0330 - val_loss: 0.0033 - val_root_mean_squared_error: 0.0577\n",
      "Epoch 92/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0010 - root_mean_squared_error: 0.0323 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0607\n",
      "Epoch 93/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0010 - root_mean_squared_error: 0.0318 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0588\n",
      "Epoch 94/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0010 - root_mean_squared_error: 0.0322 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0655\n",
      "Epoch 95/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0010 - root_mean_squared_error: 0.0322 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0629\n",
      "Epoch 96/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0010 - root_mean_squared_error: 0.0319 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0624\n",
      "Epoch 97/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.9777e-04 - root_mean_squared_error: 0.0316 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0601\n",
      "Epoch 98/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0010 - root_mean_squared_error: 0.0319 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0593\n",
      "Epoch 99/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0010 - root_mean_squared_error: 0.0320 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0614\n",
      "Epoch 100/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0010 - root_mean_squared_error: 0.0321 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0643\n",
      "Epoch 101/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0010 - root_mean_squared_error: 0.0316 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0657\n",
      "Epoch 102/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0010 - root_mean_squared_error: 0.0322 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0642\n",
      "Epoch 103/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0010 - root_mean_squared_error: 0.0316 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0646\n",
      "Epoch 104/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0010 - root_mean_squared_error: 0.0320 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0613\n",
      "Epoch 105/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0010 - root_mean_squared_error: 0.0322 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0645\n",
      "Epoch 106/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.8902e-04 - root_mean_squared_error: 0.0314 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0635\n",
      "Epoch 107/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.9664e-04 - root_mean_squared_error: 0.0316 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0611\n",
      "Epoch 108/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0011 - root_mean_squared_error: 0.0325 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0618\n",
      "Epoch 109/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0010 - root_mean_squared_error: 0.0320 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0607\n",
      "Epoch 110/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0010 - root_mean_squared_error: 0.0318 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0643\n",
      "Epoch 111/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0011 - root_mean_squared_error: 0.0327 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0650\n",
      "Epoch 112/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0010 - root_mean_squared_error: 0.0317 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0633\n",
      "Epoch 113/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0010 - root_mean_squared_error: 0.0322 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0651\n",
      "Epoch 114/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0010 - root_mean_squared_error: 0.0319 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0658\n",
      "Epoch 115/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.7026e-04 - root_mean_squared_error: 0.0311 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0612\n",
      "Epoch 116/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0011 - root_mean_squared_error: 0.0333 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0588\n",
      "Epoch 117/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0011 - root_mean_squared_error: 0.0335 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0605\n",
      "Epoch 118/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0010 - root_mean_squared_error: 0.0323 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0597\n",
      "Epoch 119/500\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 9.9516e-04 - root_mean_squared_error: 0.0315 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0614\n",
      "Epoch 120/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0010 - root_mean_squared_error: 0.0317 - val_loss: 0.0034 - val_root_mean_squared_error: 0.0583\n",
      "Epoch 121/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.7780e-04 - root_mean_squared_error: 0.0313 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0645\n",
      "Epoch 122/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0010 - root_mean_squared_error: 0.0318 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0605\n",
      "Epoch 123/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.9535e-04 - root_mean_squared_error: 0.0315 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0594\n",
      "Epoch 124/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 9.8374e-04 - root_mean_squared_error: 0.0314 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0617\n",
      "Epoch 125/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 0.0010 - root_mean_squared_error: 0.0323 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0589\n",
      "Epoch 126/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0010 - root_mean_squared_error: 0.0321 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0637\n",
      "Epoch 127/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.6367e-04 - root_mean_squared_error: 0.0310 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0667\n",
      "Epoch 128/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.7179e-04 - root_mean_squared_error: 0.0312 - val_loss: 0.0034 - val_root_mean_squared_error: 0.0582\n",
      "Epoch 129/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.8660e-04 - root_mean_squared_error: 0.0314 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0650\n",
      "Epoch 130/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.6326e-04 - root_mean_squared_error: 0.0310 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0684\n",
      "Epoch 131/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 9.8967e-04 - root_mean_squared_error: 0.0315 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0635\n",
      "Epoch 132/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0010 - root_mean_squared_error: 0.0319 - val_loss: 0.0032 - val_root_mean_squared_error: 0.0570\n",
      "Epoch 133/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 9.3880e-04 - root_mean_squared_error: 0.0306 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0629\n",
      "Epoch 134/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 9.6791e-04 - root_mean_squared_error: 0.0311 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0607\n",
      "Epoch 135/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.3550e-04 - root_mean_squared_error: 0.0306 - val_loss: 0.0034 - val_root_mean_squared_error: 0.0586\n",
      "Epoch 136/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 9.4081e-04 - root_mean_squared_error: 0.0307 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0638\n",
      "Epoch 137/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.4982e-04 - root_mean_squared_error: 0.0308 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0606\n",
      "Epoch 138/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.7344e-04 - root_mean_squared_error: 0.0312 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0619\n",
      "Epoch 139/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.2857e-04 - root_mean_squared_error: 0.0305 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0592\n",
      "Epoch 140/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.5740e-04 - root_mean_squared_error: 0.0309 - val_loss: 0.0034 - val_root_mean_squared_error: 0.0587\n",
      "Epoch 141/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0010 - root_mean_squared_error: 0.0317 - val_loss: 0.0029 - val_root_mean_squared_error: 0.0539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.5954e-04 - root_mean_squared_error: 0.0310 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0604\n",
      "Epoch 143/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 9.3915e-04 - root_mean_squared_error: 0.0306 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0664\n",
      "Epoch 144/500\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 9.7035e-04 - root_mean_squared_error: 0.0311 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0610\n",
      "Epoch 145/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.7539e-04 - root_mean_squared_error: 0.0312 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0600\n",
      "Epoch 146/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.3141e-04 - root_mean_squared_error: 0.0305 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0607\n",
      "Epoch 147/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.3414e-04 - root_mean_squared_error: 0.0306 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0626\n",
      "Epoch 148/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.3999e-04 - root_mean_squared_error: 0.0307 - val_loss: 0.0032 - val_root_mean_squared_error: 0.0569\n",
      "Epoch 149/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.5651e-04 - root_mean_squared_error: 0.0309 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0642\n",
      "Epoch 150/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.9298e-04 - root_mean_squared_error: 0.0315 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0668\n",
      "Epoch 151/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.6873e-04 - root_mean_squared_error: 0.0311 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0661\n",
      "Epoch 152/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.7782e-04 - root_mean_squared_error: 0.0313 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0675\n",
      "Epoch 153/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.3832e-04 - root_mean_squared_error: 0.0306 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0599\n",
      "Epoch 154/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 9.2132e-04 - root_mean_squared_error: 0.0304 - val_loss: 0.0032 - val_root_mean_squared_error: 0.0562\n",
      "Epoch 155/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 9.9847e-04 - root_mean_squared_error: 0.0316 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0624\n",
      "Epoch 156/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 9.6682e-04 - root_mean_squared_error: 0.0311 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0633\n",
      "Epoch 157/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.7255e-04 - root_mean_squared_error: 0.0312 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0666\n",
      "Epoch 158/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0011 - root_mean_squared_error: 0.0328 - val_loss: 0.0033 - val_root_mean_squared_error: 0.0572\n",
      "Epoch 159/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.1625e-04 - root_mean_squared_error: 0.0303 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0616\n",
      "Epoch 160/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.9568e-04 - root_mean_squared_error: 0.0299 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0698\n",
      "Epoch 161/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 9.6693e-04 - root_mean_squared_error: 0.0311 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0648\n",
      "Epoch 162/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0010 - root_mean_squared_error: 0.0319 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0588\n",
      "Epoch 163/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.0738e-04 - root_mean_squared_error: 0.0301 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0610\n",
      "Epoch 164/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.4427e-04 - root_mean_squared_error: 0.0307 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0647\n",
      "Epoch 165/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 9.7429e-04 - root_mean_squared_error: 0.0312 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0645\n",
      "Epoch 166/500\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 9.0451e-04 - root_mean_squared_error: 0.0301 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0643\n",
      "Epoch 167/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 9.7482e-04 - root_mean_squared_error: 0.0312 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0607\n",
      "Epoch 168/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.8671e-04 - root_mean_squared_error: 0.0314 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0683\n",
      "Epoch 169/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.2397e-04 - root_mean_squared_error: 0.0304 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0601\n",
      "Epoch 170/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.2017e-04 - root_mean_squared_error: 0.0303 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0640\n",
      "Epoch 171/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.1425e-04 - root_mean_squared_error: 0.0302 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0615\n",
      "Epoch 172/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.1685e-04 - root_mean_squared_error: 0.0303 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0645\n",
      "Epoch 173/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 9.8590e-04 - root_mean_squared_error: 0.0314 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0637\n",
      "Epoch 174/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.5878e-04 - root_mean_squared_error: 0.0293 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0695\n",
      "Epoch 175/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.2215e-04 - root_mean_squared_error: 0.0304 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0609\n",
      "Epoch 176/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.2633e-04 - root_mean_squared_error: 0.0304 - val_loss: 0.0033 - val_root_mean_squared_error: 0.0577\n",
      "Epoch 177/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 9.1589e-04 - root_mean_squared_error: 0.0303 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0644\n",
      "Epoch 178/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.8050e-04 - root_mean_squared_error: 0.0297 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0591\n",
      "Epoch 179/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.9006e-04 - root_mean_squared_error: 0.0298 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0601\n",
      "Epoch 180/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.9307e-04 - root_mean_squared_error: 0.0299 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0594\n",
      "Epoch 181/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.9577e-04 - root_mean_squared_error: 0.0299 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0699\n",
      "Epoch 182/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.9128e-04 - root_mean_squared_error: 0.0315 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0706\n",
      "Epoch 183/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 9.3008e-04 - root_mean_squared_error: 0.0305 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0640\n",
      "Epoch 184/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.4351e-04 - root_mean_squared_error: 0.0307 - val_loss: 0.0034 - val_root_mean_squared_error: 0.0587\n",
      "Epoch 185/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.8884e-04 - root_mean_squared_error: 0.0314 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0632\n",
      "Epoch 186/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.9462e-04 - root_mean_squared_error: 0.0315 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0635\n",
      "Epoch 187/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0010 - root_mean_squared_error: 0.0323 - val_loss: 0.0030 - val_root_mean_squared_error: 0.0549\n",
      "Epoch 188/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 22ms/step - loss: 8.9477e-04 - root_mean_squared_error: 0.0299 - val_loss: 0.0032 - val_root_mean_squared_error: 0.0569\n",
      "Epoch 189/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 9.1321e-04 - root_mean_squared_error: 0.0302 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0595\n",
      "Epoch 190/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.8652e-04 - root_mean_squared_error: 0.0298 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0603\n",
      "Epoch 191/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.6467e-04 - root_mean_squared_error: 0.0294 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0590\n",
      "Epoch 192/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.9297e-04 - root_mean_squared_error: 0.0299 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0656\n",
      "Epoch 193/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 9.6476e-04 - root_mean_squared_error: 0.0311 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0609\n",
      "Epoch 194/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 9.9863e-04 - root_mean_squared_error: 0.0316 - val_loss: 0.0028 - val_root_mean_squared_error: 0.0526\n",
      "Epoch 195/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0011 - root_mean_squared_error: 0.0326 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0596\n",
      "Epoch 196/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.1600e-04 - root_mean_squared_error: 0.0303 - val_loss: 0.0029 - val_root_mean_squared_error: 0.0541\n",
      "Epoch 197/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 9.0308e-04 - root_mean_squared_error: 0.0300 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0593\n",
      "Epoch 198/500\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 9.1450e-04 - root_mean_squared_error: 0.0302 - val_loss: 0.0034 - val_root_mean_squared_error: 0.0583\n",
      "Epoch 199/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.9276e-04 - root_mean_squared_error: 0.0299 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0622\n",
      "Epoch 200/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.0569e-04 - root_mean_squared_error: 0.0301 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0596\n",
      "Epoch 201/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 9.6248e-04 - root_mean_squared_error: 0.0310 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0621\n",
      "Epoch 202/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.2668e-04 - root_mean_squared_error: 0.0304 - val_loss: 0.0032 - val_root_mean_squared_error: 0.0570\n",
      "Epoch 203/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 9.3223e-04 - root_mean_squared_error: 0.0305 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0616\n",
      "Epoch 204/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.9991e-04 - root_mean_squared_error: 0.0300 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0589\n",
      "Epoch 205/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.7498e-04 - root_mean_squared_error: 0.0296 - val_loss: 0.0031 - val_root_mean_squared_error: 0.0559\n",
      "Epoch 206/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 9.2643e-04 - root_mean_squared_error: 0.0304 - val_loss: 0.0033 - val_root_mean_squared_error: 0.0573\n",
      "Epoch 207/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.9946e-04 - root_mean_squared_error: 0.0300 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0613\n",
      "Epoch 208/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 9.0542e-04 - root_mean_squared_error: 0.0301 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0643\n",
      "Epoch 209/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.9350e-04 - root_mean_squared_error: 0.0299 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0623\n",
      "Epoch 210/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.7216e-04 - root_mean_squared_error: 0.0295 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0589\n",
      "Epoch 211/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 9.3454e-04 - root_mean_squared_error: 0.0306 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0616\n",
      "Epoch 212/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.9601e-04 - root_mean_squared_error: 0.0299 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0615\n",
      "Epoch 213/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.6928e-04 - root_mean_squared_error: 0.0295 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0590\n",
      "Epoch 214/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.0065e-04 - root_mean_squared_error: 0.0300 - val_loss: 0.0030 - val_root_mean_squared_error: 0.0550\n",
      "Epoch 215/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0010 - root_mean_squared_error: 0.0319 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0623\n",
      "Epoch 216/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 9.2683e-04 - root_mean_squared_error: 0.0304 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0675\n",
      "Epoch 217/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 9.0607e-04 - root_mean_squared_error: 0.0301 - val_loss: 0.0030 - val_root_mean_squared_error: 0.0551\n",
      "Epoch 218/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.6580e-04 - root_mean_squared_error: 0.0294 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0608\n",
      "Epoch 219/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.9006e-04 - root_mean_squared_error: 0.0298 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0610\n",
      "Epoch 220/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.8056e-04 - root_mean_squared_error: 0.0297 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0629\n",
      "Epoch 221/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 9.9908e-04 - root_mean_squared_error: 0.0316 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0610\n",
      "Epoch 222/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.6825e-04 - root_mean_squared_error: 0.0311 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0613\n",
      "Epoch 223/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.5402e-04 - root_mean_squared_error: 0.0292 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0634\n",
      "Epoch 224/500\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 8.8640e-04 - root_mean_squared_error: 0.0298 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0619\n",
      "Epoch 225/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.0730e-04 - root_mean_squared_error: 0.0301 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0608\n",
      "Epoch 226/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.5411e-04 - root_mean_squared_error: 0.0292 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0594\n",
      "Epoch 227/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.7856e-04 - root_mean_squared_error: 0.0296 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0588\n",
      "Epoch 228/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.2967e-04 - root_mean_squared_error: 0.0288 - val_loss: 0.0033 - val_root_mean_squared_error: 0.0576\n",
      "Epoch 229/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.3546e-04 - root_mean_squared_error: 0.0289 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0615\n",
      "Epoch 230/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.7855e-04 - root_mean_squared_error: 0.0296 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0614\n",
      "Epoch 231/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.1248e-04 - root_mean_squared_error: 0.0302 - val_loss: 0.0033 - val_root_mean_squared_error: 0.0577\n",
      "Epoch 232/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.4534e-04 - root_mean_squared_error: 0.0291 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0601\n",
      "Epoch 233/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.6852e-04 - root_mean_squared_error: 0.0295 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0595\n",
      "Epoch 234/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 23ms/step - loss: 8.6838e-04 - root_mean_squared_error: 0.0295 - val_loss: 0.0030 - val_root_mean_squared_error: 0.0548\n",
      "Epoch 235/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.4282e-04 - root_mean_squared_error: 0.0307 - val_loss: 0.0033 - val_root_mean_squared_error: 0.0570\n",
      "Epoch 236/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 9.0307e-04 - root_mean_squared_error: 0.0300 - val_loss: 0.0034 - val_root_mean_squared_error: 0.0587\n",
      "Epoch 237/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.9441e-04 - root_mean_squared_error: 0.0299 - val_loss: 0.0033 - val_root_mean_squared_error: 0.0575\n",
      "Epoch 238/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.9343e-04 - root_mean_squared_error: 0.0299 - val_loss: 0.0028 - val_root_mean_squared_error: 0.0532\n",
      "Epoch 239/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.6108e-04 - root_mean_squared_error: 0.0293 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0606\n",
      "Epoch 240/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.6622e-04 - root_mean_squared_error: 0.0294 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0678\n",
      "Epoch 241/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.7267e-04 - root_mean_squared_error: 0.0295 - val_loss: 0.0032 - val_root_mean_squared_error: 0.0561\n",
      "Epoch 242/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.3514e-04 - root_mean_squared_error: 0.0289 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0664\n",
      "Epoch 243/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.0972e-04 - root_mean_squared_error: 0.0302 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0608\n",
      "Epoch 244/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.6292e-04 - root_mean_squared_error: 0.0294 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0599\n",
      "Epoch 245/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.8661e-04 - root_mean_squared_error: 0.0298 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0616\n",
      "Epoch 246/500\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 8.0185e-04 - root_mean_squared_error: 0.0283 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0641\n",
      "Epoch 247/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.3784e-04 - root_mean_squared_error: 0.0289 - val_loss: 0.0033 - val_root_mean_squared_error: 0.0573\n",
      "Epoch 248/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 9.0833e-04 - root_mean_squared_error: 0.0301 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0599\n",
      "Epoch 249/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.2994e-04 - root_mean_squared_error: 0.0305 - val_loss: 0.0033 - val_root_mean_squared_error: 0.0573\n",
      "Epoch 250/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.4974e-04 - root_mean_squared_error: 0.0291 - val_loss: 0.0033 - val_root_mean_squared_error: 0.0571\n",
      "Epoch 251/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.4467e-04 - root_mean_squared_error: 0.0291 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0631\n",
      "Epoch 252/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.7662e-04 - root_mean_squared_error: 0.0296 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0633\n",
      "Epoch 253/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.5422e-04 - root_mean_squared_error: 0.0292 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0601\n",
      "Epoch 254/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.4992e-04 - root_mean_squared_error: 0.0292 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0679\n",
      "Epoch 255/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.0010 - root_mean_squared_error: 0.0320 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0666\n",
      "Epoch 256/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.3851e-04 - root_mean_squared_error: 0.0290 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0590\n",
      "Epoch 257/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.2204e-04 - root_mean_squared_error: 0.0304 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0628\n",
      "Epoch 258/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.8673e-04 - root_mean_squared_error: 0.0298 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0592\n",
      "Epoch 259/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.4490e-04 - root_mean_squared_error: 0.0291 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0647\n",
      "Epoch 260/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.3118e-04 - root_mean_squared_error: 0.0288 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0619\n",
      "Epoch 261/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.5016e-04 - root_mean_squared_error: 0.0292 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0601\n",
      "Epoch 262/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.6034e-04 - root_mean_squared_error: 0.0293 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0626\n",
      "Epoch 263/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.3828e-04 - root_mean_squared_error: 0.0290 - val_loss: 0.0028 - val_root_mean_squared_error: 0.0529\n",
      "Epoch 264/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.5684e-04 - root_mean_squared_error: 0.0293 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0649\n",
      "Epoch 265/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.4768e-04 - root_mean_squared_error: 0.0291 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0588\n",
      "Epoch 266/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.5957e-04 - root_mean_squared_error: 0.0293 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0649\n",
      "Epoch 267/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.8580e-04 - root_mean_squared_error: 0.0298 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0623\n",
      "Epoch 268/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.5472e-04 - root_mean_squared_error: 0.0292 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0634\n",
      "Epoch 269/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.5506e-04 - root_mean_squared_error: 0.0292 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0659\n",
      "Epoch 270/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.8944e-04 - root_mean_squared_error: 0.0298 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0625\n",
      "Epoch 271/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.4752e-04 - root_mean_squared_error: 0.0291 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0593\n",
      "Epoch 272/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.8078e-04 - root_mean_squared_error: 0.0297 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0621\n",
      "Epoch 273/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.1433e-04 - root_mean_squared_error: 0.0285 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0636\n",
      "Epoch 274/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.5405e-04 - root_mean_squared_error: 0.0292 - val_loss: 0.0030 - val_root_mean_squared_error: 0.0547\n",
      "Epoch 275/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.4471e-04 - root_mean_squared_error: 0.0291 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0608\n",
      "Epoch 276/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.1954e-04 - root_mean_squared_error: 0.0286 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0647\n",
      "Epoch 277/500\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 8.3373e-04 - root_mean_squared_error: 0.0289 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0619\n",
      "Epoch 278/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.0433e-04 - root_mean_squared_error: 0.0284 - val_loss: 0.0034 - val_root_mean_squared_error: 0.0580\n",
      "Epoch 279/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.7983e-04 - root_mean_squared_error: 0.0297 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0652\n",
      "Epoch 280/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 22ms/step - loss: 8.3622e-04 - root_mean_squared_error: 0.0289 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0619\n",
      "Epoch 281/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.3325e-04 - root_mean_squared_error: 0.0289 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0599\n",
      "Epoch 282/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.4290e-04 - root_mean_squared_error: 0.0290 - val_loss: 0.0032 - val_root_mean_squared_error: 0.0569\n",
      "Epoch 283/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.1519e-04 - root_mean_squared_error: 0.0285 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0689\n",
      "Epoch 284/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.4472e-04 - root_mean_squared_error: 0.0291 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0621\n",
      "Epoch 285/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.4610e-04 - root_mean_squared_error: 0.0291 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0609\n",
      "Epoch 286/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.5203e-04 - root_mean_squared_error: 0.0292 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0708\n",
      "Epoch 287/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.3296e-04 - root_mean_squared_error: 0.0289 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0609\n",
      "Epoch 288/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.8094e-04 - root_mean_squared_error: 0.0297 - val_loss: 0.0032 - val_root_mean_squared_error: 0.0565\n",
      "Epoch 289/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.8332e-04 - root_mean_squared_error: 0.0297 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0702\n",
      "Epoch 290/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.7435e-04 - root_mean_squared_error: 0.0296 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0619\n",
      "Epoch 291/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.9649e-04 - root_mean_squared_error: 0.0282 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0645\n",
      "Epoch 292/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.1769e-04 - root_mean_squared_error: 0.0286 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0672\n",
      "Epoch 293/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.7768e-04 - root_mean_squared_error: 0.0313 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0597\n",
      "Epoch 294/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.3499e-04 - root_mean_squared_error: 0.0289 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0658\n",
      "Epoch 295/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.0314e-04 - root_mean_squared_error: 0.0283 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0590\n",
      "Epoch 296/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.2745e-04 - root_mean_squared_error: 0.0288 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0679\n",
      "Epoch 297/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.1926e-04 - root_mean_squared_error: 0.0286 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0648\n",
      "Epoch 298/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.1078e-04 - root_mean_squared_error: 0.0285 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0626\n",
      "Epoch 299/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.5820e-04 - root_mean_squared_error: 0.0293 - val_loss: 0.0032 - val_root_mean_squared_error: 0.0562\n",
      "Epoch 300/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.4611e-04 - root_mean_squared_error: 0.0308 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0614\n",
      "Epoch 301/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.6730e-04 - root_mean_squared_error: 0.0294 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0708\n",
      "Epoch 302/500\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 8.1330e-04 - root_mean_squared_error: 0.0285 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0672\n",
      "Epoch 303/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.3660e-04 - root_mean_squared_error: 0.0289 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0662\n",
      "Epoch 304/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.3271e-04 - root_mean_squared_error: 0.0289 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0605\n",
      "Epoch 305/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.0707e-04 - root_mean_squared_error: 0.0284 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0617\n",
      "Epoch 306/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.2081e-04 - root_mean_squared_error: 0.0286 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0628\n",
      "Epoch 307/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.3402e-04 - root_mean_squared_error: 0.0289 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0716\n",
      "Epoch 308/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.1677e-04 - root_mean_squared_error: 0.0286 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0707\n",
      "Epoch 309/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.2400e-04 - root_mean_squared_error: 0.0287 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0666\n",
      "Epoch 310/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.0811e-04 - root_mean_squared_error: 0.0284 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0637\n",
      "Epoch 311/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.1315e-04 - root_mean_squared_error: 0.0285 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0742\n",
      "Epoch 312/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.4758e-04 - root_mean_squared_error: 0.0291 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0746\n",
      "Epoch 313/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.2712e-04 - root_mean_squared_error: 0.0288 - val_loss: 0.0032 - val_root_mean_squared_error: 0.0569\n",
      "Epoch 314/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 9.5777e-04 - root_mean_squared_error: 0.0309 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0681\n",
      "Epoch 315/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.6061e-04 - root_mean_squared_error: 0.0293 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0615\n",
      "Epoch 316/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.4267e-04 - root_mean_squared_error: 0.0290 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0687\n",
      "Epoch 317/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.2386e-04 - root_mean_squared_error: 0.0287 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0596\n",
      "Epoch 318/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.1030e-04 - root_mean_squared_error: 0.0285 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0643\n",
      "Epoch 319/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.9868e-04 - root_mean_squared_error: 0.0282 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0626\n",
      "Epoch 320/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.1065e-04 - root_mean_squared_error: 0.0285 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0638\n",
      "Epoch 321/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.0534e-04 - root_mean_squared_error: 0.0284 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0633\n",
      "Epoch 322/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.0478e-04 - root_mean_squared_error: 0.0284 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0614\n",
      "Epoch 323/500\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 8.0905e-04 - root_mean_squared_error: 0.0284 - val_loss: 0.0032 - val_root_mean_squared_error: 0.0568\n",
      "Epoch 324/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.0600e-04 - root_mean_squared_error: 0.0284 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0615\n",
      "Epoch 325/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.9911e-04 - root_mean_squared_error: 0.0283 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0677\n",
      "Epoch 326/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 23ms/step - loss: 8.0523e-04 - root_mean_squared_error: 0.0284 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0643\n",
      "Epoch 327/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.4372e-04 - root_mean_squared_error: 0.0290 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0652\n",
      "Epoch 328/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.7396e-04 - root_mean_squared_error: 0.0278 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0603\n",
      "Epoch 329/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.1155e-04 - root_mean_squared_error: 0.0285 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0659\n",
      "Epoch 330/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.0373e-04 - root_mean_squared_error: 0.0283 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0655\n",
      "Epoch 331/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.1588e-04 - root_mean_squared_error: 0.0286 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0622\n",
      "Epoch 332/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.0995e-04 - root_mean_squared_error: 0.0285 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0636\n",
      "Epoch 333/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 7.9452e-04 - root_mean_squared_error: 0.0282 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0632\n",
      "Epoch 334/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.1091e-04 - root_mean_squared_error: 0.0285 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0588\n",
      "Epoch 335/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.3036e-04 - root_mean_squared_error: 0.0288 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0705\n",
      "Epoch 336/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.1664e-04 - root_mean_squared_error: 0.0286 - val_loss: 0.0031 - val_root_mean_squared_error: 0.0557\n",
      "Epoch 337/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.9342e-04 - root_mean_squared_error: 0.0315 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0676\n",
      "Epoch 338/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.3214e-04 - root_mean_squared_error: 0.0288 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0684\n",
      "Epoch 339/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 7.9632e-04 - root_mean_squared_error: 0.0282 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0688\n",
      "Epoch 340/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.2726e-04 - root_mean_squared_error: 0.0288 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0641\n",
      "Epoch 341/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.8592e-04 - root_mean_squared_error: 0.0280 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0616\n",
      "Epoch 342/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.9941e-04 - root_mean_squared_error: 0.0283 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0625\n",
      "Epoch 343/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.9915e-04 - root_mean_squared_error: 0.0283 - val_loss: 0.0034 - val_root_mean_squared_error: 0.0585\n",
      "Epoch 344/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.0626e-04 - root_mean_squared_error: 0.0284 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0655\n",
      "Epoch 345/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 9.5158e-04 - root_mean_squared_error: 0.0308 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0633\n",
      "Epoch 346/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.5031e-04 - root_mean_squared_error: 0.0292 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0685\n",
      "Epoch 347/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 7.9230e-04 - root_mean_squared_error: 0.0281 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0663\n",
      "Epoch 348/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.2556e-04 - root_mean_squared_error: 0.0287 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0636\n",
      "Epoch 349/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.8574e-04 - root_mean_squared_error: 0.0280 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0690\n",
      "Epoch 350/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.9090e-04 - root_mean_squared_error: 0.0281 - val_loss: 0.0034 - val_root_mean_squared_error: 0.0586\n",
      "Epoch 351/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.2165e-04 - root_mean_squared_error: 0.0287 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0653\n",
      "Epoch 352/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.3000e-04 - root_mean_squared_error: 0.0288 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0646\n",
      "Epoch 353/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 7.9484e-04 - root_mean_squared_error: 0.0282 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0637\n",
      "Epoch 354/500\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 7.9928e-04 - root_mean_squared_error: 0.0283 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0690\n",
      "Epoch 355/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.5017e-04 - root_mean_squared_error: 0.0292 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0645\n",
      "Epoch 356/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.7043e-04 - root_mean_squared_error: 0.0278 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0637\n",
      "Epoch 357/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 7.8474e-04 - root_mean_squared_error: 0.0280 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0631\n",
      "Epoch 358/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.1012e-04 - root_mean_squared_error: 0.0285 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0667\n",
      "Epoch 359/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.6262e-04 - root_mean_squared_error: 0.0276 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0673\n",
      "Epoch 360/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.7282e-04 - root_mean_squared_error: 0.0278 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0693\n",
      "Epoch 361/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.1239e-04 - root_mean_squared_error: 0.0285 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0613\n",
      "Epoch 362/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.5274e-04 - root_mean_squared_error: 0.0292 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0722\n",
      "Epoch 363/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.9601e-04 - root_mean_squared_error: 0.0282 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0663\n",
      "Epoch 364/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.9551e-04 - root_mean_squared_error: 0.0282 - val_loss: 0.0033 - val_root_mean_squared_error: 0.0577\n",
      "Epoch 365/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.3089e-04 - root_mean_squared_error: 0.0288 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0689\n",
      "Epoch 366/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 7.9128e-04 - root_mean_squared_error: 0.0281 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0609\n",
      "Epoch 367/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 7.9997e-04 - root_mean_squared_error: 0.0283 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0640\n",
      "Epoch 368/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 7.7423e-04 - root_mean_squared_error: 0.0278 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0701\n",
      "Epoch 369/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.7624e-04 - root_mean_squared_error: 0.0279 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0668\n",
      "Epoch 370/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 7.8942e-04 - root_mean_squared_error: 0.0281 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0693\n",
      "Epoch 371/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.9670e-04 - root_mean_squared_error: 0.0282 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0678\n",
      "Epoch 372/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 23ms/step - loss: 7.6077e-04 - root_mean_squared_error: 0.0276 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0603\n",
      "Epoch 373/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.8064e-04 - root_mean_squared_error: 0.0279 - val_loss: 0.0034 - val_root_mean_squared_error: 0.0582\n",
      "Epoch 374/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.0039e-04 - root_mean_squared_error: 0.0300 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0666\n",
      "Epoch 375/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.6076e-04 - root_mean_squared_error: 0.0276 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0608\n",
      "Epoch 376/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 7.7348e-04 - root_mean_squared_error: 0.0278 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0731\n",
      "Epoch 377/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 7.6748e-04 - root_mean_squared_error: 0.0277 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0706\n",
      "Epoch 378/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.0693e-04 - root_mean_squared_error: 0.0284 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0625\n",
      "Epoch 379/500\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 7.7586e-04 - root_mean_squared_error: 0.0279 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0637\n",
      "Epoch 380/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.8994e-04 - root_mean_squared_error: 0.0281 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0645\n",
      "Epoch 381/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.3990e-04 - root_mean_squared_error: 0.0290 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0617\n",
      "Epoch 382/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 9.1816e-04 - root_mean_squared_error: 0.0303 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0597\n",
      "Epoch 383/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.3198e-04 - root_mean_squared_error: 0.0288 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0676\n",
      "Epoch 384/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.0817e-04 - root_mean_squared_error: 0.0284 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0688\n",
      "Epoch 385/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.0206e-04 - root_mean_squared_error: 0.0283 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0683\n",
      "Epoch 386/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.0551e-04 - root_mean_squared_error: 0.0284 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0740\n",
      "Epoch 387/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.9927e-04 - root_mean_squared_error: 0.0283 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0703\n",
      "Epoch 388/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.5495e-04 - root_mean_squared_error: 0.0292 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0644\n",
      "Epoch 389/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.5740e-04 - root_mean_squared_error: 0.0275 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0615\n",
      "Epoch 390/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.0964e-04 - root_mean_squared_error: 0.0285 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0703\n",
      "Epoch 391/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.3468e-04 - root_mean_squared_error: 0.0289 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0665\n",
      "Epoch 392/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.6629e-04 - root_mean_squared_error: 0.0277 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0674\n",
      "Epoch 393/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.4508e-04 - root_mean_squared_error: 0.0273 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0615\n",
      "Epoch 394/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.4119e-04 - root_mean_squared_error: 0.0272 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0599\n",
      "Epoch 395/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.2602e-04 - root_mean_squared_error: 0.0287 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0680\n",
      "Epoch 396/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.9144e-04 - root_mean_squared_error: 0.0281 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0682\n",
      "Epoch 397/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.7555e-04 - root_mean_squared_error: 0.0278 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0621\n",
      "Epoch 398/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 8.0640e-04 - root_mean_squared_error: 0.0284 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0638\n",
      "Epoch 399/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.8517e-04 - root_mean_squared_error: 0.0280 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0711\n",
      "Epoch 400/500\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 7.6672e-04 - root_mean_squared_error: 0.0277 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0668\n",
      "Epoch 401/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.7811e-04 - root_mean_squared_error: 0.0279 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0637\n",
      "Epoch 402/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 7.8548e-04 - root_mean_squared_error: 0.0280 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0617\n",
      "Epoch 403/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.6704e-04 - root_mean_squared_error: 0.0277 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0680\n",
      "Epoch 404/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.3893e-04 - root_mean_squared_error: 0.0272 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0648\n",
      "Epoch 405/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 7.7484e-04 - root_mean_squared_error: 0.0278 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0604\n",
      "Epoch 406/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.6533e-04 - root_mean_squared_error: 0.0277 - val_loss: 0.0033 - val_root_mean_squared_error: 0.0575\n",
      "Epoch 407/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.3716e-04 - root_mean_squared_error: 0.0289 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0692\n",
      "Epoch 408/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 7.4073e-04 - root_mean_squared_error: 0.0272 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0705\n",
      "Epoch 409/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.8489e-04 - root_mean_squared_error: 0.0280 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0677\n",
      "Epoch 410/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.6837e-04 - root_mean_squared_error: 0.0277 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0595\n",
      "Epoch 411/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 7.6992e-04 - root_mean_squared_error: 0.0277 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0643\n",
      "Epoch 412/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.6374e-04 - root_mean_squared_error: 0.0276 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0588\n",
      "Epoch 413/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.6110e-04 - root_mean_squared_error: 0.0276 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0635\n",
      "Epoch 414/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.7984e-04 - root_mean_squared_error: 0.0279 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0632\n",
      "Epoch 415/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.7877e-04 - root_mean_squared_error: 0.0279 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0694\n",
      "Epoch 416/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.4316e-04 - root_mean_squared_error: 0.0273 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0707\n",
      "Epoch 417/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.8203e-04 - root_mean_squared_error: 0.0280 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0632\n",
      "Epoch 418/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 23ms/step - loss: 8.2526e-04 - root_mean_squared_error: 0.0287 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0629\n",
      "Epoch 419/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 7.8118e-04 - root_mean_squared_error: 0.0279 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0606\n",
      "Epoch 420/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.6898e-04 - root_mean_squared_error: 0.0277 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0652\n",
      "Epoch 421/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.7902e-04 - root_mean_squared_error: 0.0279 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0616\n",
      "Epoch 422/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.8238e-04 - root_mean_squared_error: 0.0280 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0706\n",
      "Epoch 423/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.4147e-04 - root_mean_squared_error: 0.0272 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0655\n",
      "Epoch 424/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.7674e-04 - root_mean_squared_error: 0.0279 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0747\n",
      "Epoch 425/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.6441e-04 - root_mean_squared_error: 0.0276 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0692\n",
      "Epoch 426/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.7758e-04 - root_mean_squared_error: 0.0279 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0632\n",
      "Epoch 427/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 7.7365e-04 - root_mean_squared_error: 0.0278 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0699\n",
      "Epoch 428/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.2000e-04 - root_mean_squared_error: 0.0286 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0618\n",
      "Epoch 429/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.6031e-04 - root_mean_squared_error: 0.0276 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0646\n",
      "Epoch 430/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 7.6411e-04 - root_mean_squared_error: 0.0276 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0693\n",
      "Epoch 431/500\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 7.5620e-04 - root_mean_squared_error: 0.0275 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0701\n",
      "Epoch 432/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.9544e-04 - root_mean_squared_error: 0.0282 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0624\n",
      "Epoch 433/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.1529e-04 - root_mean_squared_error: 0.0267 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0639\n",
      "Epoch 434/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.5365e-04 - root_mean_squared_error: 0.0274 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0701\n",
      "Epoch 435/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.2988e-04 - root_mean_squared_error: 0.0288 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0647\n",
      "Epoch 436/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.6315e-04 - root_mean_squared_error: 0.0276 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0686\n",
      "Epoch 437/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.7737e-04 - root_mean_squared_error: 0.0279 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0637\n",
      "Epoch 438/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 7.7693e-04 - root_mean_squared_error: 0.0279 - val_loss: 0.0034 - val_root_mean_squared_error: 0.0582\n",
      "Epoch 439/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.4560e-04 - root_mean_squared_error: 0.0273 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0717\n",
      "Epoch 440/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.9384e-04 - root_mean_squared_error: 0.0282 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0727\n",
      "Epoch 441/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.5193e-04 - root_mean_squared_error: 0.0274 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0639\n",
      "Epoch 442/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.3566e-04 - root_mean_squared_error: 0.0271 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0701\n",
      "Epoch 443/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.3219e-04 - root_mean_squared_error: 0.0288 - val_loss: 0.0029 - val_root_mean_squared_error: 0.0535\n",
      "Epoch 444/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.8519e-04 - root_mean_squared_error: 0.0297 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0710\n",
      "Epoch 445/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.9712e-04 - root_mean_squared_error: 0.0282 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0594\n",
      "Epoch 446/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.2555e-04 - root_mean_squared_error: 0.0269 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0619\n",
      "Epoch 447/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.4553e-04 - root_mean_squared_error: 0.0273 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0745\n",
      "Epoch 448/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 7.7523e-04 - root_mean_squared_error: 0.0278 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0712\n",
      "Epoch 449/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 7.5858e-04 - root_mean_squared_error: 0.0275 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0702\n",
      "Epoch 450/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.6776e-04 - root_mean_squared_error: 0.0277 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0667\n",
      "Epoch 451/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 7.2135e-04 - root_mean_squared_error: 0.0269 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0698\n",
      "Epoch 452/500\n",
      "32/32 [==============================] - 1s 22ms/step - loss: 7.6589e-04 - root_mean_squared_error: 0.0277 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0642\n",
      "Epoch 453/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.5208e-04 - root_mean_squared_error: 0.0274 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0617\n",
      "Epoch 454/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.4538e-04 - root_mean_squared_error: 0.0273 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0678\n",
      "Epoch 455/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.7360e-04 - root_mean_squared_error: 0.0278 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0672\n",
      "Epoch 456/500\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 7.6782e-04 - root_mean_squared_error: 0.0277 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0734\n",
      "Epoch 457/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.2749e-04 - root_mean_squared_error: 0.0270 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0725\n",
      "Epoch 458/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 9.1116e-04 - root_mean_squared_error: 0.0302 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0667\n",
      "Epoch 459/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.5477e-04 - root_mean_squared_error: 0.0292 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0670\n",
      "Epoch 460/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.6091e-04 - root_mean_squared_error: 0.0276 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0613\n",
      "Epoch 461/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.6398e-04 - root_mean_squared_error: 0.0276 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0637\n",
      "Epoch 462/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.1949e-04 - root_mean_squared_error: 0.0286 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0695\n",
      "Epoch 463/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.2001e-04 - root_mean_squared_error: 0.0268 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0635\n",
      "Epoch 464/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 23ms/step - loss: 7.1280e-04 - root_mean_squared_error: 0.0267 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0722\n",
      "Epoch 465/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.0129e-04 - root_mean_squared_error: 0.0283 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0632\n",
      "Epoch 466/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.7265e-04 - root_mean_squared_error: 0.0278 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0666\n",
      "Epoch 467/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.7133e-04 - root_mean_squared_error: 0.0278 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0646\n",
      "Epoch 468/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.8111e-04 - root_mean_squared_error: 0.0279 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0675\n",
      "Epoch 469/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.7020e-04 - root_mean_squared_error: 0.0278 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0697\n",
      "Epoch 470/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.5793e-04 - root_mean_squared_error: 0.0275 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0598\n",
      "Epoch 471/500\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 8.4514e-04 - root_mean_squared_error: 0.0291 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0630\n",
      "Epoch 472/500\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 7.5898e-04 - root_mean_squared_error: 0.0275 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0646\n",
      "Epoch 473/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.4448e-04 - root_mean_squared_error: 0.0273 - val_loss: 0.0034 - val_root_mean_squared_error: 0.0582\n",
      "Epoch 474/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.4962e-04 - root_mean_squared_error: 0.0274 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0726\n",
      "Epoch 475/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.7530e-04 - root_mean_squared_error: 0.0296 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0684\n",
      "Epoch 476/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.5848e-04 - root_mean_squared_error: 0.0275 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0635\n",
      "Epoch 477/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.6522e-04 - root_mean_squared_error: 0.0277 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0668\n",
      "Epoch 478/500\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 7.5303e-04 - root_mean_squared_error: 0.0274 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0673\n",
      "Epoch 479/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.7976e-04 - root_mean_squared_error: 0.0279 - val_loss: 0.0034 - val_root_mean_squared_error: 0.0583\n",
      "Epoch 480/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.6240e-04 - root_mean_squared_error: 0.0276 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0707\n",
      "Epoch 481/500\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 7.1555e-04 - root_mean_squared_error: 0.0267 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0611\n",
      "Epoch 482/500\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 7.3865e-04 - root_mean_squared_error: 0.0272 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0732\n",
      "Epoch 483/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.6566e-04 - root_mean_squared_error: 0.0277 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0703\n",
      "Epoch 484/500\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 7.6204e-04 - root_mean_squared_error: 0.0276 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0657\n",
      "Epoch 485/500\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 7.8213e-04 - root_mean_squared_error: 0.0280 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0679\n",
      "Epoch 486/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 8.0037e-04 - root_mean_squared_error: 0.0283 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0654\n",
      "Epoch 487/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.4383e-04 - root_mean_squared_error: 0.0273 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0676\n",
      "Epoch 488/500\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 7.7821e-04 - root_mean_squared_error: 0.0279 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0643\n",
      "Epoch 489/500\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 7.3676e-04 - root_mean_squared_error: 0.0271 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0625\n",
      "Epoch 490/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.8737e-04 - root_mean_squared_error: 0.0281 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0613\n",
      "Epoch 491/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.3511e-04 - root_mean_squared_error: 0.0271 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0700\n",
      "Epoch 492/500\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 7.6581e-04 - root_mean_squared_error: 0.0277 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0735\n",
      "Epoch 493/500\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 7.5539e-04 - root_mean_squared_error: 0.0275 - val_loss: 0.0060 - val_root_mean_squared_error: 0.0775\n",
      "Epoch 494/500\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 7.7424e-04 - root_mean_squared_error: 0.0278 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0621\n",
      "Epoch 495/500\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 7.4235e-04 - root_mean_squared_error: 0.0272 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0663\n",
      "Epoch 496/500\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 7.3381e-04 - root_mean_squared_error: 0.0271 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0679\n",
      "Epoch 497/500\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 7.2862e-04 - root_mean_squared_error: 0.0270 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0642\n",
      "Epoch 498/500\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 7.3898e-04 - root_mean_squared_error: 0.0272 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0726\n",
      "Epoch 499/500\n",
      "32/32 [==============================] - 1s 24ms/step - loss: 7.6982e-04 - root_mean_squared_error: 0.0277 - val_loss: 0.0027 - val_root_mean_squared_error: 0.0523\n",
      "Epoch 500/500\n",
      "32/32 [==============================] - 1s 26ms/step - loss: 9.0481e-04 - root_mean_squared_error: 0.0301 - val_loss: 0.0033 - val_root_mean_squared_error: 0.0573\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train, batch_size=32, epochs=100, validation_data=(x_eval, y_eval)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempt a Keras model prediction based on history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 48, 7])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the row from evaluation dataset as feature\n",
    "x = tf.expand_dims(x_eval[-1], axis=0)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(\n",
    "    x, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10,\n",
    "    workers=1, use_multiprocessing=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 48, 1)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(48,), dtype=float32, numpy=\n",
       "array([0.05151626, 0.0556708 , 0.08318445, 0.21065259, 0.26449195,\n",
       "       0.29920423, 0.35440305, 0.4246517 , 0.4375494 , 0.47477224,\n",
       "       0.47573763, 0.5083699 , 0.547621  , 0.5605179 , 0.5864214 ,\n",
       "       0.5884714 , 0.6397058 , 0.62527925, 0.57474184, 0.38857785,\n",
       "       0.20128909, 0.13423377, 0.06665537, 0.05359823, 0.04958963,\n",
       "       0.05151397, 0.07779732, 0.16744536, 0.27258268, 0.26778847,\n",
       "       0.29126436, 0.39697954, 0.415762  , 0.45612934, 0.42826465,\n",
       "       0.5056358 , 0.5836543 , 0.5700174 , 0.5550365 , 0.5969828 ,\n",
       "       0.65022904, 0.6379078 , 0.5966716 , 0.41843218, 0.2176767 ,\n",
       "       0.14470291, 0.07474747, 0.05372745], dtype=float32)>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.squeeze(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05694353, 0.08109268, 0.1868071 , 0.2268336 , 0.27008607,\n",
       "       0.34029998, 0.41255685, 0.46587463, 0.52656089, 0.53039813,\n",
       "       0.542525  , 0.55296916, 0.55264532, 0.56996134, 0.56719632,\n",
       "       0.70061591, 0.69560572, 0.62580088, 0.5194047 , 0.3447051 ,\n",
       "       0.22073026, 0.1225563 , 0.09421663, 0.07533178, 0.03961047,\n",
       "       0.05124383, 0.16601331, 0.24328269, 0.27739954, 0.32324039,\n",
       "       0.39474112, 0.44984002, 0.49953826, 0.50764815, 0.5444812 ,\n",
       "       0.5982034 , 0.55595497, 0.51901191, 0.5598511 , 0.69131216,\n",
       "       0.69535239, 0.64015355, 0.533456  , 0.38168535, 0.25074026,\n",
       "       0.15781743, 0.10555095, 0.09946311])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_eval[-1][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
