{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1001\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.plotting import figure, show, output_file, save\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.layouts import row, gridplot, layout\n",
    "from bokeh.palettes import d3\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to encode float values for serialized examples\n",
    "def _float_feature_from_list_of_values(list_of_values):\n",
    "    \"\"\"Returns a float_list from a list of floats / doubles.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=list_of_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the main source is the electricity dataset LD2011-2014 from UCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it resides in\n",
    "dataset_path = '/home/developer/gcp/cbidmltsf/datasets/electricity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LD2011_2014.txt',\n",
       " 'separated_preprocessed',\n",
       " 'separated_raw',\n",
       " 'hourly_electricity_complete.pkl',\n",
       " 'hourly_electricity.csv',\n",
       " 'LD2011_2014.txt.zip',\n",
       " 'hourly_electricity_filtered_academic_papers.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'LD2011_2014.txt'                                          source from UCI\n",
    "# 'LD2011_2014.txt.zip'                                      source from UCI, compressed\n",
    "# 'hourly_electricity.csv'                                   complete dataset in CSV\n",
    "# 'hourly_electricity_complete.pkl'                          complete dataset in Pandas\n",
    "# 'hourly_electricity_filtered_academic_papers.pkl'          filtered dataset for benchmarking\n",
    "# 'separated_raw/'                                           pickles per customer, raw data\n",
    "# 'separated_preprocessed/'                                  pickles per customer, outliers removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a SLDB is produced from separated time series (raw or preprocessed)\n",
    "\n",
    "# SLDB contents are:\n",
    "# TFRecord files for training\n",
    "# TFRecord files for evaluation (if eval required)\n",
    "# time series pickles for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constant values for positional encodings\n",
    "hours_in_day = 24\n",
    "days_in_week = 7\n",
    "days_in_month = 30\n",
    "days_in_year = 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a constant to make sin/cos functions from hours_from_start (the 'age' covariate)\n",
    "total_hours = 32303"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the time series in seen (train, eval) and unseen (test) data\n",
    "# according to academic papers:\n",
    "\n",
    "# 243 days on seen data, 7 days on unseen data \n",
    "\n",
    "# seen data:      '2014-01-01 00:00:00' to '2014-08-31 23:00:00', 243*24 = 5832 lectures\n",
    "\n",
    "# train/eval split is 0.9/0.1, then\n",
    "\n",
    "# train data:     '2014-01-01 00:00:00' to '2014-08-07 15:00:00', 5248 lectures\n",
    "# eval data:      '2014-08-07 16:00:00' to '2014-08-31 23:00:00', 584 lectures\n",
    "\n",
    "# unseen data:    '2014-09-01 00:00:00' to '2014-09-07 23:00:00', 7*24 = 168 lectures\n",
    "\n",
    "# 243 weeks for seen data, 1 week for unseen data\n",
    "no_lectures_seen_data = 243*24 # 5832\n",
    "\n",
    "# seen data is divided as 90% for training and 10% for evaluation\n",
    "train_eval_limit = 0.9\n",
    "\n",
    "train_interval_end = int(no_lectures_seen_data*train_eval_limit) # 5248"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build sub-series to be persisted as serialized training examples\n",
    "\n",
    "# dimensionality of the encoder input\n",
    "m = 168\n",
    "\n",
    "# dimensionality of the decoder output \n",
    "t = 168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to be included in the SLDB\n",
    "\n",
    "# use 7D encoder (age, hour-day, day-week)\n",
    "\n",
    "sldb_columns = [\n",
    "    'date',\n",
    "    'token_id',\n",
    "    'kw_scaled',\n",
    "    'sin_hours_from_start',\n",
    "    'cos_hours_from_start',\n",
    "    'sin_hour_day',\n",
    "    'cos_hour_day',\n",
    "    'sin_day_week',\n",
    "    'cos_day_week',\n",
    "    # 'sin_day_month',\n",
    "    # 'cos_day_month',\n",
    "    # 'sin_day_year',\n",
    "    # 'cos_day_year'    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sldb = {\n",
    "    'ts': 'LD2011-2014_SEPARATED_FULL',\n",
    "    'embedding': {\n",
    "        'hourly': 168\n",
    "    },\n",
    "    'tau': {\n",
    "        'hourly': 1\n",
    "    },\n",
    "    'no_targets': 168,\n",
    "    'BSCTRFM': 1,\n",
    "    'preprocessed': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ts': 'LD2011-2014_SEPARATED_FULL',\n",
       " 'embedding': {'hourly': 168},\n",
       " 'tau': {'hourly': 1},\n",
       " 'no_targets': 168,\n",
       " 'BSCTRFM': 1,\n",
       " 'preprocessed': 0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sldb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BSCTRFM_168_168_07DB_MMX'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a string with the basic specifications of the SLDB, as part of the SLDB identifier\n",
    "\n",
    "# add the suffix '11D' to differentiate this SLDB from the original one, which is 9D\n",
    "\n",
    "# add the suffix MMX to indicate the scaler used was MinMax\n",
    "# add the suffix STD to indicate the scaler used was Standard\n",
    "\n",
    "sldb_specs = 'BSCTRFM_{:03d}_{:03d}_07DB_MMX'.format(sldb['embedding']['hourly'], sldb['no_targets'])\n",
    "sldb_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LD2011-2014_SEPARATED_FULL_BSCTRFM_168_168_07DB_MMX'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the time-based identifier for the SLDB\n",
    "sldb_identifier = '{}_{}'.format(sldb['ts'], sldb_specs)\n",
    "sldb_identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/developer/gcp/cbidmltsf/sldbs/LD2011-2014_SEPARATED_FULL_BSCTRFM_168_168_07DB_MMX'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sldb_dir = '/home/developer/gcp/cbidmltsf/sldbs/{}'.format(sldb_identifier)\n",
    "sldb_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /home/developer/gcp/cbidmltsf/sldbs/LD2011-2014_SEPARATED_FULL_BSCTRFM_168_168_07DB_MMX was created.\n"
     ]
    }
   ],
   "source": [
    "# make a directory for the complete SLDB\n",
    "try:\n",
    "    os.mkdir(sldb_dir)\n",
    "    print('Directory {} was created.'.format(sldb_dir))\n",
    "except FileExistsError:\n",
    "    print('Error: directory {} already exists.'.format(sldb_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /home/developer/gcp/cbidmltsf/sldbs/LD2011-2014_SEPARATED_FULL_BSCTRFM_168_168_07DB_MMX/train was created.\n"
     ]
    }
   ],
   "source": [
    "# make a sub-directory for the training TFRecord files\n",
    "try:\n",
    "    os.mkdir('{}/train'.format(sldb_dir))\n",
    "    print('Directory {}/train was created.'.format(sldb_dir))\n",
    "except FileExistsError:\n",
    "    print('Error: directory {}/train already exists.'.format(sldb_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /home/developer/gcp/cbidmltsf/sldbs/LD2011-2014_SEPARATED_FULL_BSCTRFM_168_168_07DB_MMX/eval was created.\n"
     ]
    }
   ],
   "source": [
    "# make a sub-directory for the evaluation TFRecord files\n",
    "try:\n",
    "    os.mkdir('{}/eval'.format(sldb_dir))\n",
    "    print('Directory {}/eval was created.'.format(sldb_dir))\n",
    "except FileExistsError:\n",
    "    print('Error: directory {}/eval already exists.'.format(sldb_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /home/developer/gcp/cbidmltsf/sldbs/LD2011-2014_SEPARATED_FULL_BSCTRFM_168_168_07DB_MMX/test was created.\n"
     ]
    }
   ],
   "source": [
    "# make a sub-directory to persist time series pickles used for inference\n",
    "try:\n",
    "    os.mkdir('{}/test'.format(sldb_dir))\n",
    "    print('Directory {}/test was created.'.format(sldb_dir))\n",
    "except FileExistsError:\n",
    "    print('Error: directory {}/test already exists.'.format(sldb_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/developer/gcp/cbidmltsf/sldbs/LD2011-2014_SEPARATED_FULL_BSCTRFM_168_168_07DB_MMX/scalers'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a path to the scalers sub-directory\n",
    "scalers_dir = '{}/scalers'.format(sldb_dir)\n",
    "scalers_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /home/developer/gcp/cbidmltsf/sldbs/LD2011-2014_SEPARATED_FULL_BSCTRFM_168_168_07DB_MMX/scalers was created.\n"
     ]
    }
   ],
   "source": [
    "# make a sub-directory for the scalers\n",
    "try:\n",
    "    os.mkdir(scalers_dir)\n",
    "    print('Directory {} was created.'.format(scalers_dir))\n",
    "except FileExistsError:\n",
    "    print('Error: directory {} already exists.'.format(scalers_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_columns = [\n",
    "    'kw_scaled',\n",
    "    'sin_hours_from_start',\n",
    "    'cos_hours_from_start',\n",
    "    'sin_hour_day',\n",
    "    'cos_hour_day',\n",
    "    'sin_day_week',\n",
    "    'cos_day_week',\n",
    "    # 'sin_day_month',\n",
    "    # 'cos_day_month',\n",
    "    # 'sin_day_year',\n",
    "    # 'cos_day_year'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# both the encoder input and the decoder input use the same columns from the source sub_series dataframe\n",
    "decoder_input_columns = encoder_input_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_columns = ['kw_scaled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_columns = ['token_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dictionary to manage data per individual customer_id\n",
    "data = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of cores available for training in Cloud TPU\n",
    "num_cores = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "start, end = 1, 370"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = [token_id for token_id in np.arange(start, end + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_ids = ['MT_{:03d}'.format(token_id) for token_id in token_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# are we training over raw data or preprocessed data?\n",
    "state = 'raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for customer_id in customer_ids:\n",
    "    customer_data_path = '{}/separated_{}/{}.pkl'.format(dataset_path, state, customer_id)\n",
    "    data[customer_id] = pd.read_pickle(customer_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "370"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude token ids from SLDB here\n",
    "\n",
    "# 223 has no data!\n",
    "excluded_token_ids = [223]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are 20 time series with a total number of lectures under the expected 6000\n",
    "incomplete_time_series = [\n",
    "    'MT_106', 'MT_107', 'MT_108', 'MT_109', 'MT_110', 'MT_111', 'MT_112',\n",
    "    'MT_113', 'MT_115', 'MT_116', 'MT_117', 'MT_120', 'MT_121', 'MT_122',\n",
    "    'MT_133', 'MT_160', 'MT_178', 'MT_181', 'MT_223', 'MT_337']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>power_usage</th>\n",
       "      <th>token_id</th>\n",
       "      <th>date</th>\n",
       "      <th>hours_from_start</th>\n",
       "      <th>days_from_start</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>week_of_year</th>\n",
       "      <th>month_of_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2668763</th>\n",
       "      <td>27.302944</td>\n",
       "      <td>106</td>\n",
       "      <td>2014-01-14 00:00:00</td>\n",
       "      <td>26616.0</td>\n",
       "      <td>1109</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2668764</th>\n",
       "      <td>36.324786</td>\n",
       "      <td>106</td>\n",
       "      <td>2014-01-14 01:00:00</td>\n",
       "      <td>26617.0</td>\n",
       "      <td>1109</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2668765</th>\n",
       "      <td>37.037037</td>\n",
       "      <td>106</td>\n",
       "      <td>2014-01-14 02:00:00</td>\n",
       "      <td>26618.0</td>\n",
       "      <td>1109</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2668766</th>\n",
       "      <td>37.037037</td>\n",
       "      <td>106</td>\n",
       "      <td>2014-01-14 03:00:00</td>\n",
       "      <td>26619.0</td>\n",
       "      <td>1109</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2668767</th>\n",
       "      <td>35.612536</td>\n",
       "      <td>106</td>\n",
       "      <td>2014-01-14 04:00:00</td>\n",
       "      <td>26620.0</td>\n",
       "      <td>1109</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674446</th>\n",
       "      <td>32.288699</td>\n",
       "      <td>106</td>\n",
       "      <td>2014-09-07 19:00:00</td>\n",
       "      <td>32299.0</td>\n",
       "      <td>1345</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>250</td>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674447</th>\n",
       "      <td>31.339031</td>\n",
       "      <td>106</td>\n",
       "      <td>2014-09-07 20:00:00</td>\n",
       "      <td>32300.0</td>\n",
       "      <td>1345</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>250</td>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674448</th>\n",
       "      <td>32.051282</td>\n",
       "      <td>106</td>\n",
       "      <td>2014-09-07 21:00:00</td>\n",
       "      <td>32301.0</td>\n",
       "      <td>1345</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>250</td>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674449</th>\n",
       "      <td>33.000950</td>\n",
       "      <td>106</td>\n",
       "      <td>2014-09-07 22:00:00</td>\n",
       "      <td>32302.0</td>\n",
       "      <td>1345</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>250</td>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674450</th>\n",
       "      <td>31.576448</td>\n",
       "      <td>106</td>\n",
       "      <td>2014-09-07 23:00:00</td>\n",
       "      <td>32303.0</td>\n",
       "      <td>1345</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>250</td>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5688 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         power_usage  token_id                date  hours_from_start  \\\n",
       "2668763    27.302944       106 2014-01-14 00:00:00           26616.0   \n",
       "2668764    36.324786       106 2014-01-14 01:00:00           26617.0   \n",
       "2668765    37.037037       106 2014-01-14 02:00:00           26618.0   \n",
       "2668766    37.037037       106 2014-01-14 03:00:00           26619.0   \n",
       "2668767    35.612536       106 2014-01-14 04:00:00           26620.0   \n",
       "...              ...       ...                 ...               ...   \n",
       "2674446    32.288699       106 2014-09-07 19:00:00           32299.0   \n",
       "2674447    31.339031       106 2014-09-07 20:00:00           32300.0   \n",
       "2674448    32.051282       106 2014-09-07 21:00:00           32301.0   \n",
       "2674449    33.000950       106 2014-09-07 22:00:00           32302.0   \n",
       "2674450    31.576448       106 2014-09-07 23:00:00           32303.0   \n",
       "\n",
       "         days_from_start  hour_of_day  day_of_week  day_of_month  day_of_year  \\\n",
       "2668763             1109            0            1            14           14   \n",
       "2668764             1109            1            1            14           14   \n",
       "2668765             1109            2            1            14           14   \n",
       "2668766             1109            3            1            14           14   \n",
       "2668767             1109            4            1            14           14   \n",
       "...                  ...          ...          ...           ...          ...   \n",
       "2674446             1345           19            6             7          250   \n",
       "2674447             1345           20            6             7          250   \n",
       "2674448             1345           21            6             7          250   \n",
       "2674449             1345           22            6             7          250   \n",
       "2674450             1345           23            6             7          250   \n",
       "\n",
       "         week_of_year  month_of_year  \n",
       "2668763             3              1  \n",
       "2668764             3              1  \n",
       "2668765             3              1  \n",
       "2668766             3              1  \n",
       "2668767             3              1  \n",
       "...               ...            ...  \n",
       "2674446            36              9  \n",
       "2674447            36              9  \n",
       "2674448            36              9  \n",
       "2674449            36              9  \n",
       "2674450            36              9  \n",
       "\n",
       "[5688 rows x 11 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for instance\n",
    "customer_id = incomplete_time_series[0]\n",
    "data[customer_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locate the missing values by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, the expected 6000 dates in a list\n",
    "start_timestamp = pd.to_datetime('2014-01-01 00:00:00')\n",
    "end_timestamp = pd.to_datetime('2014-09-07 23:00:00')\n",
    "\n",
    "required_interval = pd.date_range(start=start_timestamp, end=end_timestamp, freq='H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(required_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_timestamps = list(set(required_interval) - set(data[customer_id]['date']))\n",
    "missing_timestamps.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(missing_timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for SLDB generation, run this unified code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started processing for MT_001\n",
      "Scaler min_max generated on training data for MT_001\n",
      "Scaler min_max persisted for MT_001\n",
      "Test dataset persisted as a time series pickle for MT_001\n",
      "MT_001 processed. The number of examples in train dataset is 4913\n",
      "MT_001 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_001 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_001 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_001\n",
      "Persisted eval TFRecord file for MT_001\n",
      "Started processing for MT_002\n",
      "Scaler min_max generated on training data for MT_002\n",
      "Scaler min_max persisted for MT_002\n",
      "Test dataset persisted as a time series pickle for MT_002\n",
      "MT_002 processed. The number of examples in train dataset is 4913\n",
      "MT_002 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_002 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_002 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_002\n",
      "Persisted eval TFRecord file for MT_002\n",
      "Started processing for MT_003\n",
      "Scaler min_max generated on training data for MT_003\n",
      "Scaler min_max persisted for MT_003\n",
      "Test dataset persisted as a time series pickle for MT_003\n",
      "MT_003 processed. The number of examples in train dataset is 4913\n",
      "MT_003 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_003 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_003 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_003\n",
      "Persisted eval TFRecord file for MT_003\n",
      "Started processing for MT_004\n",
      "Scaler min_max generated on training data for MT_004\n",
      "Scaler min_max persisted for MT_004\n",
      "Test dataset persisted as a time series pickle for MT_004\n",
      "MT_004 processed. The number of examples in train dataset is 4913\n",
      "MT_004 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_004 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_004 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_004\n",
      "Persisted eval TFRecord file for MT_004\n",
      "Started processing for MT_005\n",
      "Scaler min_max generated on training data for MT_005\n",
      "Scaler min_max persisted for MT_005\n",
      "Test dataset persisted as a time series pickle for MT_005\n",
      "MT_005 processed. The number of examples in train dataset is 4913\n",
      "MT_005 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_005 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_005 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_005\n",
      "Persisted eval TFRecord file for MT_005\n",
      "Started processing for MT_006\n",
      "Scaler min_max generated on training data for MT_006\n",
      "Scaler min_max persisted for MT_006\n",
      "Test dataset persisted as a time series pickle for MT_006\n",
      "MT_006 processed. The number of examples in train dataset is 4913\n",
      "MT_006 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_006 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_006 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_006\n",
      "Persisted eval TFRecord file for MT_006\n",
      "Started processing for MT_007\n",
      "Scaler min_max generated on training data for MT_007\n",
      "Scaler min_max persisted for MT_007\n",
      "Test dataset persisted as a time series pickle for MT_007\n",
      "MT_007 processed. The number of examples in train dataset is 4913\n",
      "MT_007 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_007 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_007 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_007\n",
      "Persisted eval TFRecord file for MT_007\n",
      "Started processing for MT_008\n",
      "Scaler min_max generated on training data for MT_008\n",
      "Scaler min_max persisted for MT_008\n",
      "Test dataset persisted as a time series pickle for MT_008\n",
      "MT_008 processed. The number of examples in train dataset is 4913\n",
      "MT_008 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_008 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_008 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_008\n",
      "Persisted eval TFRecord file for MT_008\n",
      "Started processing for MT_009\n",
      "Scaler min_max generated on training data for MT_009\n",
      "Scaler min_max persisted for MT_009\n",
      "Test dataset persisted as a time series pickle for MT_009\n",
      "MT_009 processed. The number of examples in train dataset is 4913\n",
      "MT_009 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_009 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_009 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_009\n",
      "Persisted eval TFRecord file for MT_009\n",
      "Started processing for MT_010\n",
      "Scaler min_max generated on training data for MT_010\n",
      "Scaler min_max persisted for MT_010\n",
      "Test dataset persisted as a time series pickle for MT_010\n",
      "MT_010 processed. The number of examples in train dataset is 4913\n",
      "MT_010 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_010 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_010 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_010\n",
      "Persisted eval TFRecord file for MT_010\n",
      "Started processing for MT_011\n",
      "Scaler min_max generated on training data for MT_011\n",
      "Scaler min_max persisted for MT_011\n",
      "Test dataset persisted as a time series pickle for MT_011\n",
      "MT_011 processed. The number of examples in train dataset is 4913\n",
      "MT_011 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_011 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_011 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_011\n",
      "Persisted eval TFRecord file for MT_011\n",
      "Started processing for MT_012\n",
      "Scaler min_max generated on training data for MT_012\n",
      "Scaler min_max persisted for MT_012\n",
      "Test dataset persisted as a time series pickle for MT_012\n",
      "MT_012 processed. The number of examples in train dataset is 4913\n",
      "MT_012 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_012 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_012 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_012\n",
      "Persisted eval TFRecord file for MT_012\n",
      "Started processing for MT_013\n",
      "Scaler min_max generated on training data for MT_013\n",
      "Scaler min_max persisted for MT_013\n",
      "Test dataset persisted as a time series pickle for MT_013\n",
      "MT_013 processed. The number of examples in train dataset is 4913\n",
      "MT_013 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_013 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_013 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_013\n",
      "Persisted eval TFRecord file for MT_013\n",
      "Started processing for MT_014\n",
      "Scaler min_max generated on training data for MT_014\n",
      "Scaler min_max persisted for MT_014\n",
      "Test dataset persisted as a time series pickle for MT_014\n",
      "MT_014 processed. The number of examples in train dataset is 4913\n",
      "MT_014 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_014 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_014 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_014\n",
      "Persisted eval TFRecord file for MT_014\n",
      "Started processing for MT_015\n",
      "Scaler min_max generated on training data for MT_015\n",
      "Scaler min_max persisted for MT_015\n",
      "Test dataset persisted as a time series pickle for MT_015\n",
      "MT_015 processed. The number of examples in train dataset is 4913\n",
      "MT_015 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_015 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_015 was adjusted to 248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persisted train TFRecord file for MT_015\n",
      "Persisted eval TFRecord file for MT_015\n",
      "Started processing for MT_016\n",
      "Scaler min_max generated on training data for MT_016\n",
      "Scaler min_max persisted for MT_016\n",
      "Test dataset persisted as a time series pickle for MT_016\n",
      "MT_016 processed. The number of examples in train dataset is 4913\n",
      "MT_016 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_016 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_016 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_016\n",
      "Persisted eval TFRecord file for MT_016\n",
      "Started processing for MT_017\n",
      "Scaler min_max generated on training data for MT_017\n",
      "Scaler min_max persisted for MT_017\n",
      "Test dataset persisted as a time series pickle for MT_017\n",
      "MT_017 processed. The number of examples in train dataset is 4913\n",
      "MT_017 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_017 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_017 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_017\n",
      "Persisted eval TFRecord file for MT_017\n",
      "Started processing for MT_018\n",
      "Scaler min_max generated on training data for MT_018\n",
      "Scaler min_max persisted for MT_018\n",
      "Test dataset persisted as a time series pickle for MT_018\n",
      "MT_018 processed. The number of examples in train dataset is 4913\n",
      "MT_018 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_018 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_018 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_018\n",
      "Persisted eval TFRecord file for MT_018\n",
      "Started processing for MT_019\n",
      "Scaler min_max generated on training data for MT_019\n",
      "Scaler min_max persisted for MT_019\n",
      "Test dataset persisted as a time series pickle for MT_019\n",
      "MT_019 processed. The number of examples in train dataset is 4913\n",
      "MT_019 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_019 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_019 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_019\n",
      "Persisted eval TFRecord file for MT_019\n",
      "Started processing for MT_020\n",
      "Scaler min_max generated on training data for MT_020\n",
      "Scaler min_max persisted for MT_020\n",
      "Test dataset persisted as a time series pickle for MT_020\n",
      "MT_020 processed. The number of examples in train dataset is 4913\n",
      "MT_020 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_020 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_020 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_020\n",
      "Persisted eval TFRecord file for MT_020\n",
      "Started processing for MT_021\n",
      "Scaler min_max generated on training data for MT_021\n",
      "Scaler min_max persisted for MT_021\n",
      "Test dataset persisted as a time series pickle for MT_021\n",
      "MT_021 processed. The number of examples in train dataset is 4913\n",
      "MT_021 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_021 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_021 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_021\n",
      "Persisted eval TFRecord file for MT_021\n",
      "Started processing for MT_022\n",
      "Scaler min_max generated on training data for MT_022\n",
      "Scaler min_max persisted for MT_022\n",
      "Test dataset persisted as a time series pickle for MT_022\n",
      "MT_022 processed. The number of examples in train dataset is 4913\n",
      "MT_022 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_022 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_022 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_022\n",
      "Persisted eval TFRecord file for MT_022\n",
      "Started processing for MT_023\n",
      "Scaler min_max generated on training data for MT_023\n",
      "Scaler min_max persisted for MT_023\n",
      "Test dataset persisted as a time series pickle for MT_023\n",
      "MT_023 processed. The number of examples in train dataset is 4913\n",
      "MT_023 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_023 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_023 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_023\n",
      "Persisted eval TFRecord file for MT_023\n",
      "Started processing for MT_024\n",
      "Scaler min_max generated on training data for MT_024\n",
      "Scaler min_max persisted for MT_024\n",
      "Test dataset persisted as a time series pickle for MT_024\n",
      "MT_024 processed. The number of examples in train dataset is 4913\n",
      "MT_024 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_024 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_024 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_024\n",
      "Persisted eval TFRecord file for MT_024\n",
      "Started processing for MT_025\n",
      "Scaler min_max generated on training data for MT_025\n",
      "Scaler min_max persisted for MT_025\n",
      "Test dataset persisted as a time series pickle for MT_025\n",
      "MT_025 processed. The number of examples in train dataset is 4913\n",
      "MT_025 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_025 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_025 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_025\n",
      "Persisted eval TFRecord file for MT_025\n",
      "Started processing for MT_026\n",
      "Scaler min_max generated on training data for MT_026\n",
      "Scaler min_max persisted for MT_026\n",
      "Test dataset persisted as a time series pickle for MT_026\n",
      "MT_026 processed. The number of examples in train dataset is 4913\n",
      "MT_026 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_026 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_026 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_026\n",
      "Persisted eval TFRecord file for MT_026\n",
      "Started processing for MT_027\n",
      "Scaler min_max generated on training data for MT_027\n",
      "Scaler min_max persisted for MT_027\n",
      "Test dataset persisted as a time series pickle for MT_027\n",
      "MT_027 processed. The number of examples in train dataset is 4913\n",
      "MT_027 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_027 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_027 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_027\n",
      "Persisted eval TFRecord file for MT_027\n",
      "Started processing for MT_028\n",
      "Scaler min_max generated on training data for MT_028\n",
      "Scaler min_max persisted for MT_028\n",
      "Test dataset persisted as a time series pickle for MT_028\n",
      "MT_028 processed. The number of examples in train dataset is 4913\n",
      "MT_028 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_028 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_028 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_028\n",
      "Persisted eval TFRecord file for MT_028\n",
      "Started processing for MT_029\n",
      "Scaler min_max generated on training data for MT_029\n",
      "Scaler min_max persisted for MT_029\n",
      "Test dataset persisted as a time series pickle for MT_029\n",
      "MT_029 processed. The number of examples in train dataset is 4913\n",
      "MT_029 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_029 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_029 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_029\n",
      "Persisted eval TFRecord file for MT_029\n",
      "Started processing for MT_030\n",
      "Scaler min_max generated on training data for MT_030\n",
      "Scaler min_max persisted for MT_030\n",
      "Test dataset persisted as a time series pickle for MT_030\n",
      "MT_030 processed. The number of examples in train dataset is 4913\n",
      "MT_030 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_030 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_030 was adjusted to 248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persisted train TFRecord file for MT_030\n",
      "Persisted eval TFRecord file for MT_030\n",
      "Started processing for MT_031\n",
      "Scaler min_max generated on training data for MT_031\n",
      "Scaler min_max persisted for MT_031\n",
      "Test dataset persisted as a time series pickle for MT_031\n",
      "MT_031 processed. The number of examples in train dataset is 4913\n",
      "MT_031 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_031 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_031 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_031\n",
      "Persisted eval TFRecord file for MT_031\n",
      "Started processing for MT_032\n",
      "Scaler min_max generated on training data for MT_032\n",
      "Scaler min_max persisted for MT_032\n",
      "Test dataset persisted as a time series pickle for MT_032\n",
      "MT_032 processed. The number of examples in train dataset is 4913\n",
      "MT_032 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_032 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_032 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_032\n",
      "Persisted eval TFRecord file for MT_032\n",
      "Started processing for MT_033\n",
      "Scaler min_max generated on training data for MT_033\n",
      "Scaler min_max persisted for MT_033\n",
      "Test dataset persisted as a time series pickle for MT_033\n",
      "MT_033 processed. The number of examples in train dataset is 4913\n",
      "MT_033 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_033 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_033 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_033\n",
      "Persisted eval TFRecord file for MT_033\n",
      "Started processing for MT_034\n",
      "Scaler min_max generated on training data for MT_034\n",
      "Scaler min_max persisted for MT_034\n",
      "Test dataset persisted as a time series pickle for MT_034\n",
      "MT_034 processed. The number of examples in train dataset is 4913\n",
      "MT_034 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_034 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_034 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_034\n",
      "Persisted eval TFRecord file for MT_034\n",
      "Started processing for MT_035\n",
      "Scaler min_max generated on training data for MT_035\n",
      "Scaler min_max persisted for MT_035\n",
      "Test dataset persisted as a time series pickle for MT_035\n",
      "MT_035 processed. The number of examples in train dataset is 4913\n",
      "MT_035 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_035 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_035 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_035\n",
      "Persisted eval TFRecord file for MT_035\n",
      "Started processing for MT_036\n",
      "Scaler min_max generated on training data for MT_036\n",
      "Scaler min_max persisted for MT_036\n",
      "Test dataset persisted as a time series pickle for MT_036\n",
      "MT_036 processed. The number of examples in train dataset is 4913\n",
      "MT_036 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_036 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_036 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_036\n",
      "Persisted eval TFRecord file for MT_036\n",
      "Started processing for MT_037\n",
      "Scaler min_max generated on training data for MT_037\n",
      "Scaler min_max persisted for MT_037\n",
      "Test dataset persisted as a time series pickle for MT_037\n",
      "MT_037 processed. The number of examples in train dataset is 4913\n",
      "MT_037 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_037 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_037 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_037\n",
      "Persisted eval TFRecord file for MT_037\n",
      "Started processing for MT_038\n",
      "Scaler min_max generated on training data for MT_038\n",
      "Scaler min_max persisted for MT_038\n",
      "Test dataset persisted as a time series pickle for MT_038\n",
      "MT_038 processed. The number of examples in train dataset is 4913\n",
      "MT_038 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_038 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_038 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_038\n",
      "Persisted eval TFRecord file for MT_038\n",
      "Started processing for MT_039\n",
      "Scaler min_max generated on training data for MT_039\n",
      "Scaler min_max persisted for MT_039\n",
      "Test dataset persisted as a time series pickle for MT_039\n",
      "MT_039 processed. The number of examples in train dataset is 4913\n",
      "MT_039 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_039 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_039 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_039\n",
      "Persisted eval TFRecord file for MT_039\n",
      "Started processing for MT_040\n",
      "Scaler min_max generated on training data for MT_040\n",
      "Scaler min_max persisted for MT_040\n",
      "Test dataset persisted as a time series pickle for MT_040\n",
      "MT_040 processed. The number of examples in train dataset is 4913\n",
      "MT_040 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_040 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_040 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_040\n",
      "Persisted eval TFRecord file for MT_040\n",
      "Started processing for MT_041\n",
      "Scaler min_max generated on training data for MT_041\n",
      "Scaler min_max persisted for MT_041\n",
      "Test dataset persisted as a time series pickle for MT_041\n",
      "MT_041 processed. The number of examples in train dataset is 4913\n",
      "MT_041 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_041 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_041 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_041\n",
      "Persisted eval TFRecord file for MT_041\n",
      "Started processing for MT_042\n",
      "Scaler min_max generated on training data for MT_042\n",
      "Scaler min_max persisted for MT_042\n",
      "Test dataset persisted as a time series pickle for MT_042\n",
      "MT_042 processed. The number of examples in train dataset is 4913\n",
      "MT_042 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_042 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_042 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_042\n",
      "Persisted eval TFRecord file for MT_042\n",
      "Started processing for MT_043\n",
      "Scaler min_max generated on training data for MT_043\n",
      "Scaler min_max persisted for MT_043\n",
      "Test dataset persisted as a time series pickle for MT_043\n",
      "MT_043 processed. The number of examples in train dataset is 4913\n",
      "MT_043 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_043 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_043 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_043\n",
      "Persisted eval TFRecord file for MT_043\n",
      "Started processing for MT_044\n",
      "Scaler min_max generated on training data for MT_044\n",
      "Scaler min_max persisted for MT_044\n",
      "Test dataset persisted as a time series pickle for MT_044\n",
      "MT_044 processed. The number of examples in train dataset is 4913\n",
      "MT_044 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_044 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_044 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_044\n",
      "Persisted eval TFRecord file for MT_044\n",
      "Started processing for MT_045\n",
      "Scaler min_max generated on training data for MT_045\n",
      "Scaler min_max persisted for MT_045\n",
      "Test dataset persisted as a time series pickle for MT_045\n",
      "MT_045 processed. The number of examples in train dataset is 4913\n",
      "MT_045 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_045 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_045 was adjusted to 248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persisted train TFRecord file for MT_045\n",
      "Persisted eval TFRecord file for MT_045\n",
      "Started processing for MT_046\n",
      "Scaler min_max generated on training data for MT_046\n",
      "Scaler min_max persisted for MT_046\n",
      "Test dataset persisted as a time series pickle for MT_046\n",
      "MT_046 processed. The number of examples in train dataset is 4913\n",
      "MT_046 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_046 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_046 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_046\n",
      "Persisted eval TFRecord file for MT_046\n",
      "Started processing for MT_047\n",
      "Scaler min_max generated on training data for MT_047\n",
      "Scaler min_max persisted for MT_047\n",
      "Test dataset persisted as a time series pickle for MT_047\n",
      "MT_047 processed. The number of examples in train dataset is 4913\n",
      "MT_047 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_047 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_047 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_047\n",
      "Persisted eval TFRecord file for MT_047\n",
      "Started processing for MT_048\n",
      "Scaler min_max generated on training data for MT_048\n",
      "Scaler min_max persisted for MT_048\n",
      "Test dataset persisted as a time series pickle for MT_048\n",
      "MT_048 processed. The number of examples in train dataset is 4913\n",
      "MT_048 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_048 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_048 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_048\n",
      "Persisted eval TFRecord file for MT_048\n",
      "Started processing for MT_049\n",
      "Scaler min_max generated on training data for MT_049\n",
      "Scaler min_max persisted for MT_049\n",
      "Test dataset persisted as a time series pickle for MT_049\n",
      "MT_049 processed. The number of examples in train dataset is 4913\n",
      "MT_049 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_049 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_049 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_049\n",
      "Persisted eval TFRecord file for MT_049\n",
      "Started processing for MT_050\n",
      "Scaler min_max generated on training data for MT_050\n",
      "Scaler min_max persisted for MT_050\n",
      "Test dataset persisted as a time series pickle for MT_050\n",
      "MT_050 processed. The number of examples in train dataset is 4913\n",
      "MT_050 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_050 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_050 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_050\n",
      "Persisted eval TFRecord file for MT_050\n",
      "Started processing for MT_051\n",
      "Scaler min_max generated on training data for MT_051\n",
      "Scaler min_max persisted for MT_051\n",
      "Test dataset persisted as a time series pickle for MT_051\n",
      "MT_051 processed. The number of examples in train dataset is 4913\n",
      "MT_051 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_051 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_051 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_051\n",
      "Persisted eval TFRecord file for MT_051\n",
      "Started processing for MT_052\n",
      "Scaler min_max generated on training data for MT_052\n",
      "Scaler min_max persisted for MT_052\n",
      "Test dataset persisted as a time series pickle for MT_052\n",
      "MT_052 processed. The number of examples in train dataset is 4913\n",
      "MT_052 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_052 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_052 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_052\n",
      "Persisted eval TFRecord file for MT_052\n",
      "Started processing for MT_053\n",
      "Scaler min_max generated on training data for MT_053\n",
      "Scaler min_max persisted for MT_053\n",
      "Test dataset persisted as a time series pickle for MT_053\n",
      "MT_053 processed. The number of examples in train dataset is 4913\n",
      "MT_053 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_053 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_053 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_053\n",
      "Persisted eval TFRecord file for MT_053\n",
      "Started processing for MT_054\n",
      "Scaler min_max generated on training data for MT_054\n",
      "Scaler min_max persisted for MT_054\n",
      "Test dataset persisted as a time series pickle for MT_054\n",
      "MT_054 processed. The number of examples in train dataset is 4913\n",
      "MT_054 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_054 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_054 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_054\n",
      "Persisted eval TFRecord file for MT_054\n",
      "Started processing for MT_055\n",
      "Scaler min_max generated on training data for MT_055\n",
      "Scaler min_max persisted for MT_055\n",
      "Test dataset persisted as a time series pickle for MT_055\n",
      "MT_055 processed. The number of examples in train dataset is 4913\n",
      "MT_055 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_055 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_055 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_055\n",
      "Persisted eval TFRecord file for MT_055\n",
      "Started processing for MT_056\n",
      "Scaler min_max generated on training data for MT_056\n",
      "Scaler min_max persisted for MT_056\n",
      "Test dataset persisted as a time series pickle for MT_056\n",
      "MT_056 processed. The number of examples in train dataset is 4913\n",
      "MT_056 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_056 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_056 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_056\n",
      "Persisted eval TFRecord file for MT_056\n",
      "Started processing for MT_057\n",
      "Scaler min_max generated on training data for MT_057\n",
      "Scaler min_max persisted for MT_057\n",
      "Test dataset persisted as a time series pickle for MT_057\n",
      "MT_057 processed. The number of examples in train dataset is 4913\n",
      "MT_057 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_057 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_057 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_057\n",
      "Persisted eval TFRecord file for MT_057\n",
      "Started processing for MT_058\n",
      "Scaler min_max generated on training data for MT_058\n",
      "Scaler min_max persisted for MT_058\n",
      "Test dataset persisted as a time series pickle for MT_058\n",
      "MT_058 processed. The number of examples in train dataset is 4913\n",
      "MT_058 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_058 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_058 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_058\n",
      "Persisted eval TFRecord file for MT_058\n",
      "Started processing for MT_059\n",
      "Scaler min_max generated on training data for MT_059\n",
      "Scaler min_max persisted for MT_059\n",
      "Test dataset persisted as a time series pickle for MT_059\n",
      "MT_059 processed. The number of examples in train dataset is 4913\n",
      "MT_059 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_059 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_059 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_059\n",
      "Persisted eval TFRecord file for MT_059\n",
      "Started processing for MT_060\n",
      "Scaler min_max generated on training data for MT_060\n",
      "Scaler min_max persisted for MT_060\n",
      "Test dataset persisted as a time series pickle for MT_060\n",
      "MT_060 processed. The number of examples in train dataset is 4913\n",
      "MT_060 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_060 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_060 was adjusted to 248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persisted train TFRecord file for MT_060\n",
      "Persisted eval TFRecord file for MT_060\n",
      "Started processing for MT_061\n",
      "Scaler min_max generated on training data for MT_061\n",
      "Scaler min_max persisted for MT_061\n",
      "Test dataset persisted as a time series pickle for MT_061\n",
      "MT_061 processed. The number of examples in train dataset is 4913\n",
      "MT_061 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_061 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_061 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_061\n",
      "Persisted eval TFRecord file for MT_061\n",
      "Started processing for MT_062\n",
      "Scaler min_max generated on training data for MT_062\n",
      "Scaler min_max persisted for MT_062\n",
      "Test dataset persisted as a time series pickle for MT_062\n",
      "MT_062 processed. The number of examples in train dataset is 4913\n",
      "MT_062 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_062 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_062 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_062\n",
      "Persisted eval TFRecord file for MT_062\n",
      "Started processing for MT_063\n",
      "Scaler min_max generated on training data for MT_063\n",
      "Scaler min_max persisted for MT_063\n",
      "Test dataset persisted as a time series pickle for MT_063\n",
      "MT_063 processed. The number of examples in train dataset is 4913\n",
      "MT_063 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_063 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_063 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_063\n",
      "Persisted eval TFRecord file for MT_063\n",
      "Started processing for MT_064\n",
      "Scaler min_max generated on training data for MT_064\n",
      "Scaler min_max persisted for MT_064\n",
      "Test dataset persisted as a time series pickle for MT_064\n",
      "MT_064 processed. The number of examples in train dataset is 4913\n",
      "MT_064 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_064 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_064 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_064\n",
      "Persisted eval TFRecord file for MT_064\n",
      "Started processing for MT_065\n",
      "Scaler min_max generated on training data for MT_065\n",
      "Scaler min_max persisted for MT_065\n",
      "Test dataset persisted as a time series pickle for MT_065\n",
      "MT_065 processed. The number of examples in train dataset is 4913\n",
      "MT_065 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_065 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_065 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_065\n",
      "Persisted eval TFRecord file for MT_065\n",
      "Started processing for MT_066\n",
      "Scaler min_max generated on training data for MT_066\n",
      "Scaler min_max persisted for MT_066\n",
      "Test dataset persisted as a time series pickle for MT_066\n",
      "MT_066 processed. The number of examples in train dataset is 4913\n",
      "MT_066 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_066 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_066 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_066\n",
      "Persisted eval TFRecord file for MT_066\n",
      "Started processing for MT_067\n",
      "Scaler min_max generated on training data for MT_067\n",
      "Scaler min_max persisted for MT_067\n",
      "Test dataset persisted as a time series pickle for MT_067\n",
      "MT_067 processed. The number of examples in train dataset is 4913\n",
      "MT_067 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_067 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_067 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_067\n",
      "Persisted eval TFRecord file for MT_067\n",
      "Started processing for MT_068\n",
      "Scaler min_max generated on training data for MT_068\n",
      "Scaler min_max persisted for MT_068\n",
      "Test dataset persisted as a time series pickle for MT_068\n",
      "MT_068 processed. The number of examples in train dataset is 4913\n",
      "MT_068 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_068 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_068 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_068\n",
      "Persisted eval TFRecord file for MT_068\n",
      "Started processing for MT_069\n",
      "Scaler min_max generated on training data for MT_069\n",
      "Scaler min_max persisted for MT_069\n",
      "Test dataset persisted as a time series pickle for MT_069\n",
      "MT_069 processed. The number of examples in train dataset is 4913\n",
      "MT_069 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_069 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_069 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_069\n",
      "Persisted eval TFRecord file for MT_069\n",
      "Started processing for MT_070\n",
      "Scaler min_max generated on training data for MT_070\n",
      "Scaler min_max persisted for MT_070\n",
      "Test dataset persisted as a time series pickle for MT_070\n",
      "MT_070 processed. The number of examples in train dataset is 4913\n",
      "MT_070 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_070 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_070 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_070\n",
      "Persisted eval TFRecord file for MT_070\n",
      "Started processing for MT_071\n",
      "Scaler min_max generated on training data for MT_071\n",
      "Scaler min_max persisted for MT_071\n",
      "Test dataset persisted as a time series pickle for MT_071\n",
      "MT_071 processed. The number of examples in train dataset is 4913\n",
      "MT_071 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_071 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_071 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_071\n",
      "Persisted eval TFRecord file for MT_071\n",
      "Started processing for MT_072\n",
      "Scaler min_max generated on training data for MT_072\n",
      "Scaler min_max persisted for MT_072\n",
      "Test dataset persisted as a time series pickle for MT_072\n",
      "MT_072 processed. The number of examples in train dataset is 4913\n",
      "MT_072 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_072 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_072 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_072\n",
      "Persisted eval TFRecord file for MT_072\n",
      "Started processing for MT_073\n",
      "Scaler min_max generated on training data for MT_073\n",
      "Scaler min_max persisted for MT_073\n",
      "Test dataset persisted as a time series pickle for MT_073\n",
      "MT_073 processed. The number of examples in train dataset is 4913\n",
      "MT_073 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_073 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_073 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_073\n",
      "Persisted eval TFRecord file for MT_073\n",
      "Started processing for MT_074\n",
      "Scaler min_max generated on training data for MT_074\n",
      "Scaler min_max persisted for MT_074\n",
      "Test dataset persisted as a time series pickle for MT_074\n",
      "MT_074 processed. The number of examples in train dataset is 4913\n",
      "MT_074 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_074 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_074 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_074\n",
      "Persisted eval TFRecord file for MT_074\n",
      "Started processing for MT_075\n",
      "Scaler min_max generated on training data for MT_075\n",
      "Scaler min_max persisted for MT_075\n",
      "Test dataset persisted as a time series pickle for MT_075\n",
      "MT_075 processed. The number of examples in train dataset is 4913\n",
      "MT_075 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_075 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_075 was adjusted to 248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persisted train TFRecord file for MT_075\n",
      "Persisted eval TFRecord file for MT_075\n",
      "Started processing for MT_076\n",
      "Scaler min_max generated on training data for MT_076\n",
      "Scaler min_max persisted for MT_076\n",
      "Test dataset persisted as a time series pickle for MT_076\n",
      "MT_076 processed. The number of examples in train dataset is 4913\n",
      "MT_076 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_076 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_076 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_076\n",
      "Persisted eval TFRecord file for MT_076\n",
      "Started processing for MT_077\n",
      "Scaler min_max generated on training data for MT_077\n",
      "Scaler min_max persisted for MT_077\n",
      "Test dataset persisted as a time series pickle for MT_077\n",
      "MT_077 processed. The number of examples in train dataset is 4913\n",
      "MT_077 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_077 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_077 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_077\n",
      "Persisted eval TFRecord file for MT_077\n",
      "Started processing for MT_078\n",
      "Scaler min_max generated on training data for MT_078\n",
      "Scaler min_max persisted for MT_078\n",
      "Test dataset persisted as a time series pickle for MT_078\n",
      "MT_078 processed. The number of examples in train dataset is 4913\n",
      "MT_078 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_078 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_078 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_078\n",
      "Persisted eval TFRecord file for MT_078\n",
      "Started processing for MT_079\n",
      "Scaler min_max generated on training data for MT_079\n",
      "Scaler min_max persisted for MT_079\n",
      "Test dataset persisted as a time series pickle for MT_079\n",
      "MT_079 processed. The number of examples in train dataset is 4913\n",
      "MT_079 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_079 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_079 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_079\n",
      "Persisted eval TFRecord file for MT_079\n",
      "Started processing for MT_080\n",
      "Scaler min_max generated on training data for MT_080\n",
      "Scaler min_max persisted for MT_080\n",
      "Test dataset persisted as a time series pickle for MT_080\n",
      "MT_080 processed. The number of examples in train dataset is 4913\n",
      "MT_080 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_080 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_080 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_080\n",
      "Persisted eval TFRecord file for MT_080\n",
      "Started processing for MT_081\n",
      "Scaler min_max generated on training data for MT_081\n",
      "Scaler min_max persisted for MT_081\n",
      "Test dataset persisted as a time series pickle for MT_081\n",
      "MT_081 processed. The number of examples in train dataset is 4913\n",
      "MT_081 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_081 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_081 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_081\n",
      "Persisted eval TFRecord file for MT_081\n",
      "Started processing for MT_082\n",
      "Scaler min_max generated on training data for MT_082\n",
      "Scaler min_max persisted for MT_082\n",
      "Test dataset persisted as a time series pickle for MT_082\n",
      "MT_082 processed. The number of examples in train dataset is 4913\n",
      "MT_082 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_082 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_082 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_082\n",
      "Persisted eval TFRecord file for MT_082\n",
      "Started processing for MT_083\n",
      "Scaler min_max generated on training data for MT_083\n",
      "Scaler min_max persisted for MT_083\n",
      "Test dataset persisted as a time series pickle for MT_083\n",
      "MT_083 processed. The number of examples in train dataset is 4913\n",
      "MT_083 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_083 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_083 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_083\n",
      "Persisted eval TFRecord file for MT_083\n",
      "Started processing for MT_084\n",
      "Scaler min_max generated on training data for MT_084\n",
      "Scaler min_max persisted for MT_084\n",
      "Test dataset persisted as a time series pickle for MT_084\n",
      "MT_084 processed. The number of examples in train dataset is 4913\n",
      "MT_084 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_084 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_084 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_084\n",
      "Persisted eval TFRecord file for MT_084\n",
      "Started processing for MT_085\n",
      "Scaler min_max generated on training data for MT_085\n",
      "Scaler min_max persisted for MT_085\n",
      "Test dataset persisted as a time series pickle for MT_085\n",
      "MT_085 processed. The number of examples in train dataset is 4913\n",
      "MT_085 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_085 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_085 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_085\n",
      "Persisted eval TFRecord file for MT_085\n",
      "Started processing for MT_086\n",
      "Scaler min_max generated on training data for MT_086\n",
      "Scaler min_max persisted for MT_086\n",
      "Test dataset persisted as a time series pickle for MT_086\n",
      "MT_086 processed. The number of examples in train dataset is 4913\n",
      "MT_086 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_086 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_086 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_086\n",
      "Persisted eval TFRecord file for MT_086\n",
      "Started processing for MT_087\n",
      "Scaler min_max generated on training data for MT_087\n",
      "Scaler min_max persisted for MT_087\n",
      "Test dataset persisted as a time series pickle for MT_087\n",
      "MT_087 processed. The number of examples in train dataset is 4913\n",
      "MT_087 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_087 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_087 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_087\n",
      "Persisted eval TFRecord file for MT_087\n",
      "Started processing for MT_088\n",
      "Scaler min_max generated on training data for MT_088\n",
      "Scaler min_max persisted for MT_088\n",
      "Test dataset persisted as a time series pickle for MT_088\n",
      "MT_088 processed. The number of examples in train dataset is 4913\n",
      "MT_088 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_088 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_088 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_088\n",
      "Persisted eval TFRecord file for MT_088\n",
      "Started processing for MT_089\n",
      "Scaler min_max generated on training data for MT_089\n",
      "Scaler min_max persisted for MT_089\n",
      "Test dataset persisted as a time series pickle for MT_089\n",
      "MT_089 processed. The number of examples in train dataset is 4913\n",
      "MT_089 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_089 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_089 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_089\n",
      "Persisted eval TFRecord file for MT_089\n",
      "Started processing for MT_090\n",
      "Scaler min_max generated on training data for MT_090\n",
      "Scaler min_max persisted for MT_090\n",
      "Test dataset persisted as a time series pickle for MT_090\n",
      "MT_090 processed. The number of examples in train dataset is 4913\n",
      "MT_090 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_090 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_090 was adjusted to 248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persisted train TFRecord file for MT_090\n",
      "Persisted eval TFRecord file for MT_090\n",
      "Started processing for MT_091\n",
      "Scaler min_max generated on training data for MT_091\n",
      "Scaler min_max persisted for MT_091\n",
      "Test dataset persisted as a time series pickle for MT_091\n",
      "MT_091 processed. The number of examples in train dataset is 4913\n",
      "MT_091 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_091 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_091 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_091\n",
      "Persisted eval TFRecord file for MT_091\n",
      "Started processing for MT_092\n",
      "Scaler min_max generated on training data for MT_092\n",
      "Scaler min_max persisted for MT_092\n",
      "Test dataset persisted as a time series pickle for MT_092\n",
      "MT_092 processed. The number of examples in train dataset is 4913\n",
      "MT_092 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_092 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_092 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_092\n",
      "Persisted eval TFRecord file for MT_092\n",
      "Started processing for MT_093\n",
      "Scaler min_max generated on training data for MT_093\n",
      "Scaler min_max persisted for MT_093\n",
      "Test dataset persisted as a time series pickle for MT_093\n",
      "MT_093 processed. The number of examples in train dataset is 4913\n",
      "MT_093 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_093 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_093 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_093\n",
      "Persisted eval TFRecord file for MT_093\n",
      "Started processing for MT_094\n",
      "Scaler min_max generated on training data for MT_094\n",
      "Scaler min_max persisted for MT_094\n",
      "Test dataset persisted as a time series pickle for MT_094\n",
      "MT_094 processed. The number of examples in train dataset is 4913\n",
      "MT_094 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_094 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_094 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_094\n",
      "Persisted eval TFRecord file for MT_094\n",
      "Started processing for MT_095\n",
      "Scaler min_max generated on training data for MT_095\n",
      "Scaler min_max persisted for MT_095\n",
      "Test dataset persisted as a time series pickle for MT_095\n",
      "MT_095 processed. The number of examples in train dataset is 4913\n",
      "MT_095 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_095 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_095 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_095\n",
      "Persisted eval TFRecord file for MT_095\n",
      "Started processing for MT_096\n",
      "Scaler min_max generated on training data for MT_096\n",
      "Scaler min_max persisted for MT_096\n",
      "Test dataset persisted as a time series pickle for MT_096\n",
      "MT_096 processed. The number of examples in train dataset is 4913\n",
      "MT_096 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_096 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_096 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_096\n",
      "Persisted eval TFRecord file for MT_096\n",
      "Started processing for MT_097\n",
      "Scaler min_max generated on training data for MT_097\n",
      "Scaler min_max persisted for MT_097\n",
      "Test dataset persisted as a time series pickle for MT_097\n",
      "MT_097 processed. The number of examples in train dataset is 4913\n",
      "MT_097 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_097 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_097 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_097\n",
      "Persisted eval TFRecord file for MT_097\n",
      "Started processing for MT_098\n",
      "Scaler min_max generated on training data for MT_098\n",
      "Scaler min_max persisted for MT_098\n",
      "Test dataset persisted as a time series pickle for MT_098\n",
      "MT_098 processed. The number of examples in train dataset is 4913\n",
      "MT_098 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_098 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_098 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_098\n",
      "Persisted eval TFRecord file for MT_098\n",
      "Started processing for MT_099\n",
      "Scaler min_max generated on training data for MT_099\n",
      "Scaler min_max persisted for MT_099\n",
      "Test dataset persisted as a time series pickle for MT_099\n",
      "MT_099 processed. The number of examples in train dataset is 4913\n",
      "MT_099 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_099 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_099 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_099\n",
      "Persisted eval TFRecord file for MT_099\n",
      "Started processing for MT_100\n",
      "Scaler min_max generated on training data for MT_100\n",
      "Scaler min_max persisted for MT_100\n",
      "Test dataset persisted as a time series pickle for MT_100\n",
      "MT_100 processed. The number of examples in train dataset is 4913\n",
      "MT_100 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_100 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_100 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_100\n",
      "Persisted eval TFRecord file for MT_100\n",
      "Started processing for MT_101\n",
      "Scaler min_max generated on training data for MT_101\n",
      "Scaler min_max persisted for MT_101\n",
      "Test dataset persisted as a time series pickle for MT_101\n",
      "MT_101 processed. The number of examples in train dataset is 4913\n",
      "MT_101 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_101 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_101 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_101\n",
      "Persisted eval TFRecord file for MT_101\n",
      "Started processing for MT_102\n",
      "Scaler min_max generated on training data for MT_102\n",
      "Scaler min_max persisted for MT_102\n",
      "Test dataset persisted as a time series pickle for MT_102\n",
      "MT_102 processed. The number of examples in train dataset is 4913\n",
      "MT_102 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_102 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_102 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_102\n",
      "Persisted eval TFRecord file for MT_102\n",
      "Started processing for MT_103\n",
      "Scaler min_max generated on training data for MT_103\n",
      "Scaler min_max persisted for MT_103\n",
      "Test dataset persisted as a time series pickle for MT_103\n",
      "MT_103 processed. The number of examples in train dataset is 4913\n",
      "MT_103 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_103 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_103 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_103\n",
      "Persisted eval TFRecord file for MT_103\n",
      "Started processing for MT_104\n",
      "Scaler min_max generated on training data for MT_104\n",
      "Scaler min_max persisted for MT_104\n",
      "Test dataset persisted as a time series pickle for MT_104\n",
      "MT_104 processed. The number of examples in train dataset is 4913\n",
      "MT_104 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_104 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_104 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_104\n",
      "Persisted eval TFRecord file for MT_104\n",
      "Started processing for MT_105\n",
      "Scaler min_max generated on training data for MT_105\n",
      "Scaler min_max persisted for MT_105\n",
      "Test dataset persisted as a time series pickle for MT_105\n",
      "MT_105 processed. The number of examples in train dataset is 4913\n",
      "MT_105 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_105 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_105 was adjusted to 248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persisted train TFRecord file for MT_105\n",
      "Persisted eval TFRecord file for MT_105\n",
      "Started processing for MT_106\n",
      "Scaler min_max generated on training data for MT_106\n",
      "Scaler min_max persisted for MT_106\n",
      "Test dataset persisted as a time series pickle for MT_106\n",
      "MT_106 processed. The number of examples in train dataset is 4913\n",
      "MT_106 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_106 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_106 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_106\n",
      "Persisted eval TFRecord file for MT_106\n",
      "Started processing for MT_107\n",
      "Scaler min_max generated on training data for MT_107\n",
      "Scaler min_max persisted for MT_107\n",
      "Test dataset persisted as a time series pickle for MT_107\n",
      "MT_107 processed. The number of examples in train dataset is 4913\n",
      "MT_107 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_107 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_107 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_107\n",
      "Persisted eval TFRecord file for MT_107\n",
      "Started processing for MT_108\n",
      "Scaler min_max generated on training data for MT_108\n",
      "Scaler min_max persisted for MT_108\n",
      "Test dataset persisted as a time series pickle for MT_108\n",
      "MT_108 processed. The number of examples in train dataset is 4913\n",
      "MT_108 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_108 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_108 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_108\n",
      "Persisted eval TFRecord file for MT_108\n",
      "Started processing for MT_109\n",
      "Scaler min_max generated on training data for MT_109\n",
      "Scaler min_max persisted for MT_109\n",
      "Test dataset persisted as a time series pickle for MT_109\n",
      "MT_109 processed. The number of examples in train dataset is 4913\n",
      "MT_109 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_109 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_109 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_109\n",
      "Persisted eval TFRecord file for MT_109\n",
      "Started processing for MT_110\n",
      "Scaler min_max generated on training data for MT_110\n",
      "Scaler min_max persisted for MT_110\n",
      "Test dataset persisted as a time series pickle for MT_110\n",
      "MT_110 processed. The number of examples in train dataset is 4913\n",
      "MT_110 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_110 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_110 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_110\n",
      "Persisted eval TFRecord file for MT_110\n",
      "Started processing for MT_111\n",
      "Scaler min_max generated on training data for MT_111\n",
      "Scaler min_max persisted for MT_111\n",
      "Test dataset persisted as a time series pickle for MT_111\n",
      "MT_111 processed. The number of examples in train dataset is 4913\n",
      "MT_111 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_111 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_111 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_111\n",
      "Persisted eval TFRecord file for MT_111\n",
      "Started processing for MT_112\n",
      "Scaler min_max generated on training data for MT_112\n",
      "Scaler min_max persisted for MT_112\n",
      "Test dataset persisted as a time series pickle for MT_112\n",
      "MT_112 processed. The number of examples in train dataset is 4913\n",
      "MT_112 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_112 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_112 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_112\n",
      "Persisted eval TFRecord file for MT_112\n",
      "Started processing for MT_113\n",
      "Scaler min_max generated on training data for MT_113\n",
      "Scaler min_max persisted for MT_113\n",
      "Test dataset persisted as a time series pickle for MT_113\n",
      "MT_113 processed. The number of examples in train dataset is 4913\n",
      "MT_113 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_113 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_113 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_113\n",
      "Persisted eval TFRecord file for MT_113\n",
      "Started processing for MT_114\n",
      "Scaler min_max generated on training data for MT_114\n",
      "Scaler min_max persisted for MT_114\n",
      "Test dataset persisted as a time series pickle for MT_114\n",
      "MT_114 processed. The number of examples in train dataset is 4913\n",
      "MT_114 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_114 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_114 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_114\n",
      "Persisted eval TFRecord file for MT_114\n",
      "Started processing for MT_115\n",
      "Scaler min_max generated on training data for MT_115\n",
      "Scaler min_max persisted for MT_115\n",
      "Test dataset persisted as a time series pickle for MT_115\n",
      "MT_115 processed. The number of examples in train dataset is 4913\n",
      "MT_115 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_115 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_115 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_115\n",
      "Persisted eval TFRecord file for MT_115\n",
      "Started processing for MT_116\n",
      "Scaler min_max generated on training data for MT_116\n",
      "Scaler min_max persisted for MT_116\n",
      "Test dataset persisted as a time series pickle for MT_116\n",
      "MT_116 processed. The number of examples in train dataset is 4913\n",
      "MT_116 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_116 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_116 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_116\n",
      "Persisted eval TFRecord file for MT_116\n",
      "Started processing for MT_117\n",
      "Scaler min_max generated on training data for MT_117\n",
      "Scaler min_max persisted for MT_117\n",
      "Test dataset persisted as a time series pickle for MT_117\n",
      "MT_117 processed. The number of examples in train dataset is 4913\n",
      "MT_117 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_117 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_117 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_117\n",
      "Persisted eval TFRecord file for MT_117\n",
      "Started processing for MT_118\n",
      "Scaler min_max generated on training data for MT_118\n",
      "Scaler min_max persisted for MT_118\n",
      "Test dataset persisted as a time series pickle for MT_118\n",
      "MT_118 processed. The number of examples in train dataset is 4913\n",
      "MT_118 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_118 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_118 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_118\n",
      "Persisted eval TFRecord file for MT_118\n",
      "Started processing for MT_119\n",
      "Scaler min_max generated on training data for MT_119\n",
      "Scaler min_max persisted for MT_119\n",
      "Test dataset persisted as a time series pickle for MT_119\n",
      "MT_119 processed. The number of examples in train dataset is 4913\n",
      "MT_119 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_119 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_119 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_119\n",
      "Persisted eval TFRecord file for MT_119\n",
      "Started processing for MT_120\n",
      "Scaler min_max generated on training data for MT_120\n",
      "Scaler min_max persisted for MT_120\n",
      "Test dataset persisted as a time series pickle for MT_120\n",
      "MT_120 processed. The number of examples in train dataset is 4913\n",
      "MT_120 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_120 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_120 was adjusted to 248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persisted train TFRecord file for MT_120\n",
      "Persisted eval TFRecord file for MT_120\n",
      "Started processing for MT_121\n",
      "Scaler min_max generated on training data for MT_121\n",
      "Scaler min_max persisted for MT_121\n",
      "Test dataset persisted as a time series pickle for MT_121\n",
      "MT_121 processed. The number of examples in train dataset is 4913\n",
      "MT_121 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_121 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_121 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_121\n",
      "Persisted eval TFRecord file for MT_121\n",
      "Started processing for MT_122\n",
      "Scaler min_max generated on training data for MT_122\n",
      "Scaler min_max persisted for MT_122\n",
      "Test dataset persisted as a time series pickle for MT_122\n",
      "MT_122 processed. The number of examples in train dataset is 4913\n",
      "MT_122 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_122 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_122 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_122\n",
      "Persisted eval TFRecord file for MT_122\n",
      "Started processing for MT_123\n",
      "Scaler min_max generated on training data for MT_123\n",
      "Scaler min_max persisted for MT_123\n",
      "Test dataset persisted as a time series pickle for MT_123\n",
      "MT_123 processed. The number of examples in train dataset is 4913\n",
      "MT_123 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_123 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_123 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_123\n",
      "Persisted eval TFRecord file for MT_123\n",
      "Started processing for MT_124\n",
      "Scaler min_max generated on training data for MT_124\n",
      "Scaler min_max persisted for MT_124\n",
      "Test dataset persisted as a time series pickle for MT_124\n",
      "MT_124 processed. The number of examples in train dataset is 4913\n",
      "MT_124 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_124 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_124 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_124\n",
      "Persisted eval TFRecord file for MT_124\n",
      "Started processing for MT_125\n",
      "Scaler min_max generated on training data for MT_125\n",
      "Scaler min_max persisted for MT_125\n",
      "Test dataset persisted as a time series pickle for MT_125\n",
      "MT_125 processed. The number of examples in train dataset is 4913\n",
      "MT_125 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_125 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_125 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_125\n",
      "Persisted eval TFRecord file for MT_125\n",
      "Started processing for MT_126\n",
      "Scaler min_max generated on training data for MT_126\n",
      "Scaler min_max persisted for MT_126\n",
      "Test dataset persisted as a time series pickle for MT_126\n",
      "MT_126 processed. The number of examples in train dataset is 4913\n",
      "MT_126 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_126 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_126 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_126\n",
      "Persisted eval TFRecord file for MT_126\n",
      "Started processing for MT_127\n",
      "Scaler min_max generated on training data for MT_127\n",
      "Scaler min_max persisted for MT_127\n",
      "Test dataset persisted as a time series pickle for MT_127\n",
      "MT_127 processed. The number of examples in train dataset is 4913\n",
      "MT_127 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_127 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_127 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_127\n",
      "Persisted eval TFRecord file for MT_127\n",
      "Started processing for MT_128\n",
      "Scaler min_max generated on training data for MT_128\n",
      "Scaler min_max persisted for MT_128\n",
      "Test dataset persisted as a time series pickle for MT_128\n",
      "MT_128 processed. The number of examples in train dataset is 4913\n",
      "MT_128 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_128 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_128 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_128\n",
      "Persisted eval TFRecord file for MT_128\n",
      "Started processing for MT_129\n",
      "Scaler min_max generated on training data for MT_129\n",
      "Scaler min_max persisted for MT_129\n",
      "Test dataset persisted as a time series pickle for MT_129\n",
      "MT_129 processed. The number of examples in train dataset is 4913\n",
      "MT_129 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_129 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_129 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_129\n",
      "Persisted eval TFRecord file for MT_129\n",
      "Started processing for MT_130\n",
      "Scaler min_max generated on training data for MT_130\n",
      "Scaler min_max persisted for MT_130\n",
      "Test dataset persisted as a time series pickle for MT_130\n",
      "MT_130 processed. The number of examples in train dataset is 4913\n",
      "MT_130 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_130 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_130 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_130\n",
      "Persisted eval TFRecord file for MT_130\n",
      "Started processing for MT_131\n",
      "Scaler min_max generated on training data for MT_131\n",
      "Scaler min_max persisted for MT_131\n",
      "Test dataset persisted as a time series pickle for MT_131\n",
      "MT_131 processed. The number of examples in train dataset is 4913\n",
      "MT_131 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_131 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_131 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_131\n",
      "Persisted eval TFRecord file for MT_131\n",
      "Started processing for MT_132\n",
      "Scaler min_max generated on training data for MT_132\n",
      "Scaler min_max persisted for MT_132\n",
      "Test dataset persisted as a time series pickle for MT_132\n",
      "MT_132 processed. The number of examples in train dataset is 4913\n",
      "MT_132 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_132 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_132 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_132\n",
      "Persisted eval TFRecord file for MT_132\n",
      "Started processing for MT_133\n",
      "Scaler min_max generated on training data for MT_133\n",
      "Scaler min_max persisted for MT_133\n",
      "Test dataset persisted as a time series pickle for MT_133\n",
      "MT_133 processed. The number of examples in train dataset is 4913\n",
      "MT_133 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_133 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_133 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_133\n",
      "Persisted eval TFRecord file for MT_133\n",
      "Started processing for MT_134\n",
      "Scaler min_max generated on training data for MT_134\n",
      "Scaler min_max persisted for MT_134\n",
      "Test dataset persisted as a time series pickle for MT_134\n",
      "MT_134 processed. The number of examples in train dataset is 4913\n",
      "MT_134 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_134 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_134 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_134\n",
      "Persisted eval TFRecord file for MT_134\n",
      "Started processing for MT_135\n",
      "Scaler min_max generated on training data for MT_135\n",
      "Scaler min_max persisted for MT_135\n",
      "Test dataset persisted as a time series pickle for MT_135\n",
      "MT_135 processed. The number of examples in train dataset is 4913\n",
      "MT_135 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_135 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_135 was adjusted to 248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persisted train TFRecord file for MT_135\n",
      "Persisted eval TFRecord file for MT_135\n",
      "Started processing for MT_136\n",
      "Scaler min_max generated on training data for MT_136\n",
      "Scaler min_max persisted for MT_136\n",
      "Test dataset persisted as a time series pickle for MT_136\n",
      "MT_136 processed. The number of examples in train dataset is 4913\n",
      "MT_136 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_136 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_136 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_136\n",
      "Persisted eval TFRecord file for MT_136\n",
      "Started processing for MT_137\n",
      "Scaler min_max generated on training data for MT_137\n",
      "Scaler min_max persisted for MT_137\n",
      "Test dataset persisted as a time series pickle for MT_137\n",
      "MT_137 processed. The number of examples in train dataset is 4913\n",
      "MT_137 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_137 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_137 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_137\n",
      "Persisted eval TFRecord file for MT_137\n",
      "Started processing for MT_138\n",
      "Scaler min_max generated on training data for MT_138\n",
      "Scaler min_max persisted for MT_138\n",
      "Test dataset persisted as a time series pickle for MT_138\n",
      "MT_138 processed. The number of examples in train dataset is 4913\n",
      "MT_138 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_138 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_138 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_138\n",
      "Persisted eval TFRecord file for MT_138\n",
      "Started processing for MT_139\n",
      "Scaler min_max generated on training data for MT_139\n",
      "Scaler min_max persisted for MT_139\n",
      "Test dataset persisted as a time series pickle for MT_139\n",
      "MT_139 processed. The number of examples in train dataset is 4913\n",
      "MT_139 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_139 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_139 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_139\n",
      "Persisted eval TFRecord file for MT_139\n",
      "Started processing for MT_140\n",
      "Scaler min_max generated on training data for MT_140\n",
      "Scaler min_max persisted for MT_140\n",
      "Test dataset persisted as a time series pickle for MT_140\n",
      "MT_140 processed. The number of examples in train dataset is 4913\n",
      "MT_140 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_140 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_140 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_140\n",
      "Persisted eval TFRecord file for MT_140\n",
      "Started processing for MT_141\n",
      "Scaler min_max generated on training data for MT_141\n",
      "Scaler min_max persisted for MT_141\n",
      "Test dataset persisted as a time series pickle for MT_141\n",
      "MT_141 processed. The number of examples in train dataset is 4913\n",
      "MT_141 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_141 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_141 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_141\n",
      "Persisted eval TFRecord file for MT_141\n",
      "Started processing for MT_142\n",
      "Scaler min_max generated on training data for MT_142\n",
      "Scaler min_max persisted for MT_142\n",
      "Test dataset persisted as a time series pickle for MT_142\n",
      "MT_142 processed. The number of examples in train dataset is 4913\n",
      "MT_142 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_142 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_142 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_142\n",
      "Persisted eval TFRecord file for MT_142\n",
      "Started processing for MT_143\n",
      "Scaler min_max generated on training data for MT_143\n",
      "Scaler min_max persisted for MT_143\n",
      "Test dataset persisted as a time series pickle for MT_143\n",
      "MT_143 processed. The number of examples in train dataset is 4913\n",
      "MT_143 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_143 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_143 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_143\n",
      "Persisted eval TFRecord file for MT_143\n",
      "Started processing for MT_144\n",
      "Scaler min_max generated on training data for MT_144\n",
      "Scaler min_max persisted for MT_144\n",
      "Test dataset persisted as a time series pickle for MT_144\n",
      "MT_144 processed. The number of examples in train dataset is 4913\n",
      "MT_144 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_144 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_144 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_144\n",
      "Persisted eval TFRecord file for MT_144\n",
      "Started processing for MT_145\n",
      "Scaler min_max generated on training data for MT_145\n",
      "Scaler min_max persisted for MT_145\n",
      "Test dataset persisted as a time series pickle for MT_145\n",
      "MT_145 processed. The number of examples in train dataset is 4913\n",
      "MT_145 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_145 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_145 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_145\n",
      "Persisted eval TFRecord file for MT_145\n",
      "Started processing for MT_146\n",
      "Scaler min_max generated on training data for MT_146\n",
      "Scaler min_max persisted for MT_146\n",
      "Test dataset persisted as a time series pickle for MT_146\n",
      "MT_146 processed. The number of examples in train dataset is 4913\n",
      "MT_146 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_146 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_146 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_146\n",
      "Persisted eval TFRecord file for MT_146\n",
      "Started processing for MT_147\n",
      "Scaler min_max generated on training data for MT_147\n",
      "Scaler min_max persisted for MT_147\n",
      "Test dataset persisted as a time series pickle for MT_147\n",
      "MT_147 processed. The number of examples in train dataset is 4913\n",
      "MT_147 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_147 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_147 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_147\n",
      "Persisted eval TFRecord file for MT_147\n",
      "Started processing for MT_148\n",
      "Scaler min_max generated on training data for MT_148\n",
      "Scaler min_max persisted for MT_148\n",
      "Test dataset persisted as a time series pickle for MT_148\n",
      "MT_148 processed. The number of examples in train dataset is 4913\n",
      "MT_148 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_148 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_148 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_148\n",
      "Persisted eval TFRecord file for MT_148\n",
      "Started processing for MT_149\n",
      "Scaler min_max generated on training data for MT_149\n",
      "Scaler min_max persisted for MT_149\n",
      "Test dataset persisted as a time series pickle for MT_149\n",
      "MT_149 processed. The number of examples in train dataset is 4913\n",
      "MT_149 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_149 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_149 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_149\n",
      "Persisted eval TFRecord file for MT_149\n",
      "Started processing for MT_150\n",
      "Scaler min_max generated on training data for MT_150\n",
      "Scaler min_max persisted for MT_150\n",
      "Test dataset persisted as a time series pickle for MT_150\n",
      "MT_150 processed. The number of examples in train dataset is 4913\n",
      "MT_150 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_150 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_150 was adjusted to 248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persisted train TFRecord file for MT_150\n",
      "Persisted eval TFRecord file for MT_150\n",
      "Started processing for MT_151\n",
      "Scaler min_max generated on training data for MT_151\n",
      "Scaler min_max persisted for MT_151\n",
      "Test dataset persisted as a time series pickle for MT_151\n",
      "MT_151 processed. The number of examples in train dataset is 4913\n",
      "MT_151 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_151 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_151 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_151\n",
      "Persisted eval TFRecord file for MT_151\n",
      "Started processing for MT_152\n",
      "Scaler min_max generated on training data for MT_152\n",
      "Scaler min_max persisted for MT_152\n",
      "Test dataset persisted as a time series pickle for MT_152\n",
      "MT_152 processed. The number of examples in train dataset is 4913\n",
      "MT_152 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_152 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_152 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_152\n",
      "Persisted eval TFRecord file for MT_152\n",
      "Started processing for MT_153\n",
      "Scaler min_max generated on training data for MT_153\n",
      "Scaler min_max persisted for MT_153\n",
      "Test dataset persisted as a time series pickle for MT_153\n",
      "MT_153 processed. The number of examples in train dataset is 4913\n",
      "MT_153 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_153 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_153 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_153\n",
      "Persisted eval TFRecord file for MT_153\n",
      "Started processing for MT_154\n",
      "Scaler min_max generated on training data for MT_154\n",
      "Scaler min_max persisted for MT_154\n",
      "Test dataset persisted as a time series pickle for MT_154\n",
      "MT_154 processed. The number of examples in train dataset is 4913\n",
      "MT_154 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_154 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_154 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_154\n",
      "Persisted eval TFRecord file for MT_154\n",
      "Started processing for MT_155\n",
      "Scaler min_max generated on training data for MT_155\n",
      "Scaler min_max persisted for MT_155\n",
      "Test dataset persisted as a time series pickle for MT_155\n",
      "MT_155 processed. The number of examples in train dataset is 4913\n",
      "MT_155 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_155 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_155 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_155\n",
      "Persisted eval TFRecord file for MT_155\n",
      "Started processing for MT_156\n",
      "Scaler min_max generated on training data for MT_156\n",
      "Scaler min_max persisted for MT_156\n",
      "Test dataset persisted as a time series pickle for MT_156\n",
      "MT_156 processed. The number of examples in train dataset is 4913\n",
      "MT_156 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_156 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_156 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_156\n",
      "Persisted eval TFRecord file for MT_156\n",
      "Started processing for MT_157\n",
      "Scaler min_max generated on training data for MT_157\n",
      "Scaler min_max persisted for MT_157\n",
      "Test dataset persisted as a time series pickle for MT_157\n",
      "MT_157 processed. The number of examples in train dataset is 4913\n",
      "MT_157 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_157 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_157 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_157\n",
      "Persisted eval TFRecord file for MT_157\n",
      "Started processing for MT_158\n",
      "Scaler min_max generated on training data for MT_158\n",
      "Scaler min_max persisted for MT_158\n",
      "Test dataset persisted as a time series pickle for MT_158\n",
      "MT_158 processed. The number of examples in train dataset is 4913\n",
      "MT_158 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_158 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_158 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_158\n",
      "Persisted eval TFRecord file for MT_158\n",
      "Started processing for MT_159\n",
      "Scaler min_max generated on training data for MT_159\n",
      "Scaler min_max persisted for MT_159\n",
      "Test dataset persisted as a time series pickle for MT_159\n",
      "MT_159 processed. The number of examples in train dataset is 4913\n",
      "MT_159 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_159 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_159 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_159\n",
      "Persisted eval TFRecord file for MT_159\n",
      "Started processing for MT_160\n",
      "Scaler min_max generated on training data for MT_160\n",
      "Scaler min_max persisted for MT_160\n",
      "Test dataset persisted as a time series pickle for MT_160\n",
      "MT_160 processed. The number of examples in train dataset is 4913\n",
      "MT_160 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_160 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_160 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_160\n",
      "Persisted eval TFRecord file for MT_160\n",
      "Started processing for MT_161\n",
      "Scaler min_max generated on training data for MT_161\n",
      "Scaler min_max persisted for MT_161\n",
      "Test dataset persisted as a time series pickle for MT_161\n",
      "MT_161 processed. The number of examples in train dataset is 4913\n",
      "MT_161 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_161 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_161 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_161\n",
      "Persisted eval TFRecord file for MT_161\n",
      "Started processing for MT_162\n",
      "Scaler min_max generated on training data for MT_162\n",
      "Scaler min_max persisted for MT_162\n",
      "Test dataset persisted as a time series pickle for MT_162\n",
      "MT_162 processed. The number of examples in train dataset is 4913\n",
      "MT_162 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_162 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_162 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_162\n",
      "Persisted eval TFRecord file for MT_162\n",
      "Started processing for MT_163\n",
      "Scaler min_max generated on training data for MT_163\n",
      "Scaler min_max persisted for MT_163\n",
      "Test dataset persisted as a time series pickle for MT_163\n",
      "MT_163 processed. The number of examples in train dataset is 4913\n",
      "MT_163 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_163 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_163 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_163\n",
      "Persisted eval TFRecord file for MT_163\n",
      "Started processing for MT_164\n",
      "Scaler min_max generated on training data for MT_164\n",
      "Scaler min_max persisted for MT_164\n",
      "Test dataset persisted as a time series pickle for MT_164\n",
      "MT_164 processed. The number of examples in train dataset is 4913\n",
      "MT_164 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_164 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_164 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_164\n",
      "Persisted eval TFRecord file for MT_164\n",
      "Started processing for MT_165\n",
      "Scaler min_max generated on training data for MT_165\n",
      "Scaler min_max persisted for MT_165\n",
      "Test dataset persisted as a time series pickle for MT_165\n",
      "MT_165 processed. The number of examples in train dataset is 4913\n",
      "MT_165 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_165 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_165 was adjusted to 248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persisted train TFRecord file for MT_165\n",
      "Persisted eval TFRecord file for MT_165\n",
      "Started processing for MT_166\n",
      "Scaler min_max generated on training data for MT_166\n",
      "Scaler min_max persisted for MT_166\n",
      "Test dataset persisted as a time series pickle for MT_166\n",
      "MT_166 processed. The number of examples in train dataset is 4913\n",
      "MT_166 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_166 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_166 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_166\n",
      "Persisted eval TFRecord file for MT_166\n",
      "Started processing for MT_167\n",
      "Scaler min_max generated on training data for MT_167\n",
      "Scaler min_max persisted for MT_167\n",
      "Test dataset persisted as a time series pickle for MT_167\n",
      "MT_167 processed. The number of examples in train dataset is 4913\n",
      "MT_167 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_167 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_167 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_167\n",
      "Persisted eval TFRecord file for MT_167\n",
      "Started processing for MT_168\n",
      "Scaler min_max generated on training data for MT_168\n",
      "Scaler min_max persisted for MT_168\n",
      "Test dataset persisted as a time series pickle for MT_168\n",
      "MT_168 processed. The number of examples in train dataset is 4913\n",
      "MT_168 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_168 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_168 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_168\n",
      "Persisted eval TFRecord file for MT_168\n",
      "Started processing for MT_169\n",
      "Scaler min_max generated on training data for MT_169\n",
      "Scaler min_max persisted for MT_169\n",
      "Test dataset persisted as a time series pickle for MT_169\n",
      "MT_169 processed. The number of examples in train dataset is 4913\n",
      "MT_169 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_169 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_169 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_169\n",
      "Persisted eval TFRecord file for MT_169\n",
      "Started processing for MT_170\n",
      "Scaler min_max generated on training data for MT_170\n",
      "Scaler min_max persisted for MT_170\n",
      "Test dataset persisted as a time series pickle for MT_170\n",
      "MT_170 processed. The number of examples in train dataset is 4913\n",
      "MT_170 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_170 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_170 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_170\n",
      "Persisted eval TFRecord file for MT_170\n",
      "Started processing for MT_171\n",
      "Scaler min_max generated on training data for MT_171\n",
      "Scaler min_max persisted for MT_171\n",
      "Test dataset persisted as a time series pickle for MT_171\n",
      "MT_171 processed. The number of examples in train dataset is 4913\n",
      "MT_171 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_171 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_171 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_171\n",
      "Persisted eval TFRecord file for MT_171\n",
      "Started processing for MT_172\n",
      "Scaler min_max generated on training data for MT_172\n",
      "Scaler min_max persisted for MT_172\n",
      "Test dataset persisted as a time series pickle for MT_172\n",
      "MT_172 processed. The number of examples in train dataset is 4913\n",
      "MT_172 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_172 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_172 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_172\n",
      "Persisted eval TFRecord file for MT_172\n",
      "Started processing for MT_173\n",
      "Scaler min_max generated on training data for MT_173\n",
      "Scaler min_max persisted for MT_173\n",
      "Test dataset persisted as a time series pickle for MT_173\n",
      "MT_173 processed. The number of examples in train dataset is 4913\n",
      "MT_173 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_173 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_173 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_173\n",
      "Persisted eval TFRecord file for MT_173\n",
      "Started processing for MT_174\n",
      "Scaler min_max generated on training data for MT_174\n",
      "Scaler min_max persisted for MT_174\n",
      "Test dataset persisted as a time series pickle for MT_174\n",
      "MT_174 processed. The number of examples in train dataset is 4913\n",
      "MT_174 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_174 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_174 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_174\n",
      "Persisted eval TFRecord file for MT_174\n",
      "Started processing for MT_175\n",
      "Scaler min_max generated on training data for MT_175\n",
      "Scaler min_max persisted for MT_175\n",
      "Test dataset persisted as a time series pickle for MT_175\n",
      "MT_175 processed. The number of examples in train dataset is 4913\n",
      "MT_175 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_175 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_175 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_175\n",
      "Persisted eval TFRecord file for MT_175\n",
      "Started processing for MT_176\n",
      "Scaler min_max generated on training data for MT_176\n",
      "Scaler min_max persisted for MT_176\n",
      "Test dataset persisted as a time series pickle for MT_176\n",
      "MT_176 processed. The number of examples in train dataset is 4913\n",
      "MT_176 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_176 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_176 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_176\n",
      "Persisted eval TFRecord file for MT_176\n",
      "Started processing for MT_177\n",
      "Scaler min_max generated on training data for MT_177\n",
      "Scaler min_max persisted for MT_177\n",
      "Test dataset persisted as a time series pickle for MT_177\n",
      "MT_177 processed. The number of examples in train dataset is 4913\n",
      "MT_177 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_177 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_177 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_177\n",
      "Persisted eval TFRecord file for MT_177\n",
      "Started processing for MT_178\n",
      "Scaler min_max generated on training data for MT_178\n",
      "Scaler min_max persisted for MT_178\n",
      "Test dataset persisted as a time series pickle for MT_178\n",
      "MT_178 processed. The number of examples in train dataset is 4913\n",
      "MT_178 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_178 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_178 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_178\n",
      "Persisted eval TFRecord file for MT_178\n",
      "Started processing for MT_179\n",
      "Scaler min_max generated on training data for MT_179\n",
      "Scaler min_max persisted for MT_179\n",
      "Test dataset persisted as a time series pickle for MT_179\n",
      "MT_179 processed. The number of examples in train dataset is 4913\n",
      "MT_179 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_179 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_179 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_179\n",
      "Persisted eval TFRecord file for MT_179\n",
      "Started processing for MT_180\n",
      "Scaler min_max generated on training data for MT_180\n",
      "Scaler min_max persisted for MT_180\n",
      "Test dataset persisted as a time series pickle for MT_180\n",
      "MT_180 processed. The number of examples in train dataset is 4913\n",
      "MT_180 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_180 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_180 was adjusted to 248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persisted train TFRecord file for MT_180\n",
      "Persisted eval TFRecord file for MT_180\n",
      "Started processing for MT_181\n",
      "Scaler min_max generated on training data for MT_181\n",
      "Scaler min_max persisted for MT_181\n",
      "Test dataset persisted as a time series pickle for MT_181\n",
      "MT_181 processed. The number of examples in train dataset is 4913\n",
      "MT_181 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_181 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_181 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_181\n",
      "Persisted eval TFRecord file for MT_181\n",
      "Started processing for MT_182\n",
      "Scaler min_max generated on training data for MT_182\n",
      "Scaler min_max persisted for MT_182\n",
      "Test dataset persisted as a time series pickle for MT_182\n",
      "MT_182 processed. The number of examples in train dataset is 4913\n",
      "MT_182 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_182 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_182 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_182\n",
      "Persisted eval TFRecord file for MT_182\n",
      "Started processing for MT_183\n",
      "Scaler min_max generated on training data for MT_183\n",
      "Scaler min_max persisted for MT_183\n",
      "Test dataset persisted as a time series pickle for MT_183\n",
      "MT_183 processed. The number of examples in train dataset is 4913\n",
      "MT_183 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_183 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_183 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_183\n",
      "Persisted eval TFRecord file for MT_183\n",
      "Started processing for MT_184\n",
      "Scaler min_max generated on training data for MT_184\n",
      "Scaler min_max persisted for MT_184\n",
      "Test dataset persisted as a time series pickle for MT_184\n",
      "MT_184 processed. The number of examples in train dataset is 4913\n",
      "MT_184 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_184 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_184 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_184\n",
      "Persisted eval TFRecord file for MT_184\n",
      "Started processing for MT_185\n",
      "Scaler min_max generated on training data for MT_185\n",
      "Scaler min_max persisted for MT_185\n",
      "Test dataset persisted as a time series pickle for MT_185\n",
      "MT_185 processed. The number of examples in train dataset is 4913\n",
      "MT_185 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_185 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_185 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_185\n",
      "Persisted eval TFRecord file for MT_185\n",
      "Started processing for MT_186\n",
      "Scaler min_max generated on training data for MT_186\n",
      "Scaler min_max persisted for MT_186\n",
      "Test dataset persisted as a time series pickle for MT_186\n",
      "MT_186 processed. The number of examples in train dataset is 4913\n",
      "MT_186 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_186 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_186 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_186\n",
      "Persisted eval TFRecord file for MT_186\n",
      "Started processing for MT_187\n",
      "Scaler min_max generated on training data for MT_187\n",
      "Scaler min_max persisted for MT_187\n",
      "Test dataset persisted as a time series pickle for MT_187\n",
      "MT_187 processed. The number of examples in train dataset is 4913\n",
      "MT_187 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_187 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_187 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_187\n",
      "Persisted eval TFRecord file for MT_187\n",
      "Started processing for MT_188\n",
      "Scaler min_max generated on training data for MT_188\n",
      "Scaler min_max persisted for MT_188\n",
      "Test dataset persisted as a time series pickle for MT_188\n",
      "MT_188 processed. The number of examples in train dataset is 4913\n",
      "MT_188 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_188 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_188 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_188\n",
      "Persisted eval TFRecord file for MT_188\n",
      "Started processing for MT_189\n",
      "Scaler min_max generated on training data for MT_189\n",
      "Scaler min_max persisted for MT_189\n",
      "Test dataset persisted as a time series pickle for MT_189\n",
      "MT_189 processed. The number of examples in train dataset is 4913\n",
      "MT_189 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_189 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_189 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_189\n",
      "Persisted eval TFRecord file for MT_189\n",
      "Started processing for MT_190\n",
      "Scaler min_max generated on training data for MT_190\n",
      "Scaler min_max persisted for MT_190\n",
      "Test dataset persisted as a time series pickle for MT_190\n",
      "MT_190 processed. The number of examples in train dataset is 4913\n",
      "MT_190 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_190 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_190 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_190\n",
      "Persisted eval TFRecord file for MT_190\n",
      "Started processing for MT_191\n",
      "Scaler min_max generated on training data for MT_191\n",
      "Scaler min_max persisted for MT_191\n",
      "Test dataset persisted as a time series pickle for MT_191\n",
      "MT_191 processed. The number of examples in train dataset is 4913\n",
      "MT_191 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_191 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_191 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_191\n",
      "Persisted eval TFRecord file for MT_191\n",
      "Started processing for MT_192\n",
      "Scaler min_max generated on training data for MT_192\n",
      "Scaler min_max persisted for MT_192\n",
      "Test dataset persisted as a time series pickle for MT_192\n",
      "MT_192 processed. The number of examples in train dataset is 4913\n",
      "MT_192 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_192 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_192 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_192\n",
      "Persisted eval TFRecord file for MT_192\n",
      "Started processing for MT_193\n",
      "Scaler min_max generated on training data for MT_193\n",
      "Scaler min_max persisted for MT_193\n",
      "Test dataset persisted as a time series pickle for MT_193\n",
      "MT_193 processed. The number of examples in train dataset is 4913\n",
      "MT_193 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_193 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_193 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_193\n",
      "Persisted eval TFRecord file for MT_193\n",
      "Started processing for MT_194\n",
      "Scaler min_max generated on training data for MT_194\n",
      "Scaler min_max persisted for MT_194\n",
      "Test dataset persisted as a time series pickle for MT_194\n",
      "MT_194 processed. The number of examples in train dataset is 4913\n",
      "MT_194 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_194 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_194 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_194\n",
      "Persisted eval TFRecord file for MT_194\n",
      "Started processing for MT_195\n",
      "Scaler min_max generated on training data for MT_195\n",
      "Scaler min_max persisted for MT_195\n",
      "Test dataset persisted as a time series pickle for MT_195\n",
      "MT_195 processed. The number of examples in train dataset is 4913\n",
      "MT_195 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_195 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_195 was adjusted to 248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persisted train TFRecord file for MT_195\n",
      "Persisted eval TFRecord file for MT_195\n",
      "Started processing for MT_196\n",
      "Scaler min_max generated on training data for MT_196\n",
      "Scaler min_max persisted for MT_196\n",
      "Test dataset persisted as a time series pickle for MT_196\n",
      "MT_196 processed. The number of examples in train dataset is 4913\n",
      "MT_196 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_196 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_196 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_196\n",
      "Persisted eval TFRecord file for MT_196\n",
      "Started processing for MT_197\n",
      "Scaler min_max generated on training data for MT_197\n",
      "Scaler min_max persisted for MT_197\n",
      "Test dataset persisted as a time series pickle for MT_197\n",
      "MT_197 processed. The number of examples in train dataset is 4913\n",
      "MT_197 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_197 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_197 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_197\n",
      "Persisted eval TFRecord file for MT_197\n",
      "Started processing for MT_198\n",
      "Scaler min_max generated on training data for MT_198\n",
      "Scaler min_max persisted for MT_198\n",
      "Test dataset persisted as a time series pickle for MT_198\n",
      "MT_198 processed. The number of examples in train dataset is 4913\n",
      "MT_198 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_198 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_198 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_198\n",
      "Persisted eval TFRecord file for MT_198\n",
      "Started processing for MT_199\n",
      "Scaler min_max generated on training data for MT_199\n",
      "Scaler min_max persisted for MT_199\n",
      "Test dataset persisted as a time series pickle for MT_199\n",
      "MT_199 processed. The number of examples in train dataset is 4913\n",
      "MT_199 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_199 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_199 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_199\n",
      "Persisted eval TFRecord file for MT_199\n",
      "Started processing for MT_200\n",
      "Scaler min_max generated on training data for MT_200\n",
      "Scaler min_max persisted for MT_200\n",
      "Test dataset persisted as a time series pickle for MT_200\n",
      "MT_200 processed. The number of examples in train dataset is 4913\n",
      "MT_200 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_200 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_200 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_200\n",
      "Persisted eval TFRecord file for MT_200\n",
      "Started processing for MT_201\n",
      "Scaler min_max generated on training data for MT_201\n",
      "Scaler min_max persisted for MT_201\n",
      "Test dataset persisted as a time series pickle for MT_201\n",
      "MT_201 processed. The number of examples in train dataset is 4913\n",
      "MT_201 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_201 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_201 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_201\n",
      "Persisted eval TFRecord file for MT_201\n",
      "Started processing for MT_202\n",
      "Scaler min_max generated on training data for MT_202\n",
      "Scaler min_max persisted for MT_202\n",
      "Test dataset persisted as a time series pickle for MT_202\n",
      "MT_202 processed. The number of examples in train dataset is 4913\n",
      "MT_202 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_202 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_202 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_202\n",
      "Persisted eval TFRecord file for MT_202\n",
      "Started processing for MT_203\n",
      "Scaler min_max generated on training data for MT_203\n",
      "Scaler min_max persisted for MT_203\n",
      "Test dataset persisted as a time series pickle for MT_203\n",
      "MT_203 processed. The number of examples in train dataset is 4913\n",
      "MT_203 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_203 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_203 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_203\n",
      "Persisted eval TFRecord file for MT_203\n",
      "Started processing for MT_204\n",
      "Scaler min_max generated on training data for MT_204\n",
      "Scaler min_max persisted for MT_204\n",
      "Test dataset persisted as a time series pickle for MT_204\n",
      "MT_204 processed. The number of examples in train dataset is 4913\n",
      "MT_204 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_204 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_204 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_204\n",
      "Persisted eval TFRecord file for MT_204\n",
      "Started processing for MT_205\n",
      "Scaler min_max generated on training data for MT_205\n",
      "Scaler min_max persisted for MT_205\n",
      "Test dataset persisted as a time series pickle for MT_205\n",
      "MT_205 processed. The number of examples in train dataset is 4913\n",
      "MT_205 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_205 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_205 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_205\n",
      "Persisted eval TFRecord file for MT_205\n",
      "Started processing for MT_206\n",
      "Scaler min_max generated on training data for MT_206\n",
      "Scaler min_max persisted for MT_206\n",
      "Test dataset persisted as a time series pickle for MT_206\n",
      "MT_206 processed. The number of examples in train dataset is 4913\n",
      "MT_206 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_206 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_206 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_206\n",
      "Persisted eval TFRecord file for MT_206\n",
      "Started processing for MT_207\n",
      "Scaler min_max generated on training data for MT_207\n",
      "Scaler min_max persisted for MT_207\n",
      "Test dataset persisted as a time series pickle for MT_207\n",
      "MT_207 processed. The number of examples in train dataset is 4913\n",
      "MT_207 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_207 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_207 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_207\n",
      "Persisted eval TFRecord file for MT_207\n",
      "Started processing for MT_208\n",
      "Scaler min_max generated on training data for MT_208\n",
      "Scaler min_max persisted for MT_208\n",
      "Test dataset persisted as a time series pickle for MT_208\n",
      "MT_208 processed. The number of examples in train dataset is 4913\n",
      "MT_208 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_208 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_208 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_208\n",
      "Persisted eval TFRecord file for MT_208\n",
      "Started processing for MT_209\n",
      "Scaler min_max generated on training data for MT_209\n",
      "Scaler min_max persisted for MT_209\n",
      "Test dataset persisted as a time series pickle for MT_209\n",
      "MT_209 processed. The number of examples in train dataset is 4913\n",
      "MT_209 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_209 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_209 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_209\n",
      "Persisted eval TFRecord file for MT_209\n",
      "Started processing for MT_210\n",
      "Scaler min_max generated on training data for MT_210\n",
      "Scaler min_max persisted for MT_210\n",
      "Test dataset persisted as a time series pickle for MT_210\n",
      "MT_210 processed. The number of examples in train dataset is 4913\n",
      "MT_210 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_210 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_210 was adjusted to 248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persisted train TFRecord file for MT_210\n",
      "Persisted eval TFRecord file for MT_210\n",
      "Started processing for MT_211\n",
      "Scaler min_max generated on training data for MT_211\n",
      "Scaler min_max persisted for MT_211\n",
      "Test dataset persisted as a time series pickle for MT_211\n",
      "MT_211 processed. The number of examples in train dataset is 4913\n",
      "MT_211 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_211 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_211 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_211\n",
      "Persisted eval TFRecord file for MT_211\n",
      "Started processing for MT_212\n",
      "Scaler min_max generated on training data for MT_212\n",
      "Scaler min_max persisted for MT_212\n",
      "Test dataset persisted as a time series pickle for MT_212\n",
      "MT_212 processed. The number of examples in train dataset is 4913\n",
      "MT_212 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_212 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_212 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_212\n",
      "Persisted eval TFRecord file for MT_212\n",
      "Started processing for MT_213\n",
      "Scaler min_max generated on training data for MT_213\n",
      "Scaler min_max persisted for MT_213\n",
      "Test dataset persisted as a time series pickle for MT_213\n",
      "MT_213 processed. The number of examples in train dataset is 4913\n",
      "MT_213 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_213 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_213 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_213\n",
      "Persisted eval TFRecord file for MT_213\n",
      "Started processing for MT_214\n",
      "Scaler min_max generated on training data for MT_214\n",
      "Scaler min_max persisted for MT_214\n",
      "Test dataset persisted as a time series pickle for MT_214\n",
      "MT_214 processed. The number of examples in train dataset is 4913\n",
      "MT_214 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_214 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_214 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_214\n",
      "Persisted eval TFRecord file for MT_214\n",
      "Started processing for MT_215\n",
      "Scaler min_max generated on training data for MT_215\n",
      "Scaler min_max persisted for MT_215\n",
      "Test dataset persisted as a time series pickle for MT_215\n",
      "MT_215 processed. The number of examples in train dataset is 4913\n",
      "MT_215 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_215 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_215 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_215\n",
      "Persisted eval TFRecord file for MT_215\n",
      "Started processing for MT_216\n",
      "Scaler min_max generated on training data for MT_216\n",
      "Scaler min_max persisted for MT_216\n",
      "Test dataset persisted as a time series pickle for MT_216\n",
      "MT_216 processed. The number of examples in train dataset is 4913\n",
      "MT_216 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_216 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_216 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_216\n",
      "Persisted eval TFRecord file for MT_216\n",
      "Started processing for MT_217\n",
      "Scaler min_max generated on training data for MT_217\n",
      "Scaler min_max persisted for MT_217\n",
      "Test dataset persisted as a time series pickle for MT_217\n",
      "MT_217 processed. The number of examples in train dataset is 4913\n",
      "MT_217 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_217 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_217 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_217\n",
      "Persisted eval TFRecord file for MT_217\n",
      "Started processing for MT_218\n",
      "Scaler min_max generated on training data for MT_218\n",
      "Scaler min_max persisted for MT_218\n",
      "Test dataset persisted as a time series pickle for MT_218\n",
      "MT_218 processed. The number of examples in train dataset is 4913\n",
      "MT_218 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_218 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_218 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_218\n",
      "Persisted eval TFRecord file for MT_218\n",
      "Started processing for MT_219\n",
      "Scaler min_max generated on training data for MT_219\n",
      "Scaler min_max persisted for MT_219\n",
      "Test dataset persisted as a time series pickle for MT_219\n",
      "MT_219 processed. The number of examples in train dataset is 4913\n",
      "MT_219 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_219 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_219 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_219\n",
      "Persisted eval TFRecord file for MT_219\n",
      "Started processing for MT_220\n",
      "Scaler min_max generated on training data for MT_220\n",
      "Scaler min_max persisted for MT_220\n",
      "Test dataset persisted as a time series pickle for MT_220\n",
      "MT_220 processed. The number of examples in train dataset is 4913\n",
      "MT_220 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_220 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_220 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_220\n",
      "Persisted eval TFRecord file for MT_220\n",
      "Started processing for MT_221\n",
      "Scaler min_max generated on training data for MT_221\n",
      "Scaler min_max persisted for MT_221\n",
      "Test dataset persisted as a time series pickle for MT_221\n",
      "MT_221 processed. The number of examples in train dataset is 4913\n",
      "MT_221 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_221 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_221 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_221\n",
      "Persisted eval TFRecord file for MT_221\n",
      "Started processing for MT_222\n",
      "Scaler min_max generated on training data for MT_222\n",
      "Scaler min_max persisted for MT_222\n",
      "Test dataset persisted as a time series pickle for MT_222\n",
      "MT_222 processed. The number of examples in train dataset is 4913\n",
      "MT_222 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_222 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_222 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_222\n",
      "Persisted eval TFRecord file for MT_222\n",
      "Started processing for MT_224\n",
      "Scaler min_max generated on training data for MT_224\n",
      "Scaler min_max persisted for MT_224\n",
      "Test dataset persisted as a time series pickle for MT_224\n",
      "MT_224 processed. The number of examples in train dataset is 4913\n",
      "MT_224 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_224 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_224 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_224\n",
      "Persisted eval TFRecord file for MT_224\n",
      "Started processing for MT_225\n",
      "Scaler min_max generated on training data for MT_225\n",
      "Scaler min_max persisted for MT_225\n",
      "Test dataset persisted as a time series pickle for MT_225\n",
      "MT_225 processed. The number of examples in train dataset is 4913\n",
      "MT_225 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_225 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_225 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_225\n",
      "Persisted eval TFRecord file for MT_225\n",
      "Started processing for MT_226\n",
      "Scaler min_max generated on training data for MT_226\n",
      "Scaler min_max persisted for MT_226\n",
      "Test dataset persisted as a time series pickle for MT_226\n",
      "MT_226 processed. The number of examples in train dataset is 4913\n",
      "MT_226 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_226 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_226 was adjusted to 248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persisted train TFRecord file for MT_226\n",
      "Persisted eval TFRecord file for MT_226\n",
      "Started processing for MT_227\n",
      "Scaler min_max generated on training data for MT_227\n",
      "Scaler min_max persisted for MT_227\n",
      "Test dataset persisted as a time series pickle for MT_227\n",
      "MT_227 processed. The number of examples in train dataset is 4913\n",
      "MT_227 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_227 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_227 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_227\n",
      "Persisted eval TFRecord file for MT_227\n",
      "Started processing for MT_228\n",
      "Scaler min_max generated on training data for MT_228\n",
      "Scaler min_max persisted for MT_228\n",
      "Test dataset persisted as a time series pickle for MT_228\n",
      "MT_228 processed. The number of examples in train dataset is 4913\n",
      "MT_228 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_228 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_228 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_228\n",
      "Persisted eval TFRecord file for MT_228\n",
      "Started processing for MT_229\n",
      "Scaler min_max generated on training data for MT_229\n",
      "Scaler min_max persisted for MT_229\n",
      "Test dataset persisted as a time series pickle for MT_229\n",
      "MT_229 processed. The number of examples in train dataset is 4913\n",
      "MT_229 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_229 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_229 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_229\n",
      "Persisted eval TFRecord file for MT_229\n",
      "Started processing for MT_230\n",
      "Scaler min_max generated on training data for MT_230\n",
      "Scaler min_max persisted for MT_230\n",
      "Test dataset persisted as a time series pickle for MT_230\n",
      "MT_230 processed. The number of examples in train dataset is 4913\n",
      "MT_230 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_230 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_230 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_230\n",
      "Persisted eval TFRecord file for MT_230\n",
      "Started processing for MT_231\n",
      "Scaler min_max generated on training data for MT_231\n",
      "Scaler min_max persisted for MT_231\n",
      "Test dataset persisted as a time series pickle for MT_231\n",
      "MT_231 processed. The number of examples in train dataset is 4913\n",
      "MT_231 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_231 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_231 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_231\n",
      "Persisted eval TFRecord file for MT_231\n",
      "Started processing for MT_232\n",
      "Scaler min_max generated on training data for MT_232\n",
      "Scaler min_max persisted for MT_232\n",
      "Test dataset persisted as a time series pickle for MT_232\n",
      "MT_232 processed. The number of examples in train dataset is 4913\n",
      "MT_232 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_232 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_232 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_232\n",
      "Persisted eval TFRecord file for MT_232\n",
      "Started processing for MT_233\n",
      "Scaler min_max generated on training data for MT_233\n",
      "Scaler min_max persisted for MT_233\n",
      "Test dataset persisted as a time series pickle for MT_233\n",
      "MT_233 processed. The number of examples in train dataset is 4913\n",
      "MT_233 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_233 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_233 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_233\n",
      "Persisted eval TFRecord file for MT_233\n",
      "Started processing for MT_234\n",
      "Scaler min_max generated on training data for MT_234\n",
      "Scaler min_max persisted for MT_234\n",
      "Test dataset persisted as a time series pickle for MT_234\n",
      "MT_234 processed. The number of examples in train dataset is 4913\n",
      "MT_234 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_234 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_234 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_234\n",
      "Persisted eval TFRecord file for MT_234\n",
      "Started processing for MT_235\n",
      "Scaler min_max generated on training data for MT_235\n",
      "Scaler min_max persisted for MT_235\n",
      "Test dataset persisted as a time series pickle for MT_235\n",
      "MT_235 processed. The number of examples in train dataset is 4913\n",
      "MT_235 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_235 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_235 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_235\n",
      "Persisted eval TFRecord file for MT_235\n",
      "Started processing for MT_236\n",
      "Scaler min_max generated on training data for MT_236\n",
      "Scaler min_max persisted for MT_236\n",
      "Test dataset persisted as a time series pickle for MT_236\n",
      "MT_236 processed. The number of examples in train dataset is 4913\n",
      "MT_236 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_236 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_236 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_236\n",
      "Persisted eval TFRecord file for MT_236\n",
      "Started processing for MT_237\n",
      "Scaler min_max generated on training data for MT_237\n",
      "Scaler min_max persisted for MT_237\n",
      "Test dataset persisted as a time series pickle for MT_237\n",
      "MT_237 processed. The number of examples in train dataset is 4913\n",
      "MT_237 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_237 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_237 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_237\n",
      "Persisted eval TFRecord file for MT_237\n",
      "Started processing for MT_238\n",
      "Scaler min_max generated on training data for MT_238\n",
      "Scaler min_max persisted for MT_238\n",
      "Test dataset persisted as a time series pickle for MT_238\n",
      "MT_238 processed. The number of examples in train dataset is 4913\n",
      "MT_238 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_238 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_238 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_238\n",
      "Persisted eval TFRecord file for MT_238\n",
      "Started processing for MT_239\n",
      "Scaler min_max generated on training data for MT_239\n",
      "Scaler min_max persisted for MT_239\n",
      "Test dataset persisted as a time series pickle for MT_239\n",
      "MT_239 processed. The number of examples in train dataset is 4913\n",
      "MT_239 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_239 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_239 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_239\n",
      "Persisted eval TFRecord file for MT_239\n",
      "Started processing for MT_240\n",
      "Scaler min_max generated on training data for MT_240\n",
      "Scaler min_max persisted for MT_240\n",
      "Test dataset persisted as a time series pickle for MT_240\n",
      "MT_240 processed. The number of examples in train dataset is 4913\n",
      "MT_240 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_240 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_240 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_240\n",
      "Persisted eval TFRecord file for MT_240\n",
      "Started processing for MT_241\n",
      "Scaler min_max generated on training data for MT_241\n",
      "Scaler min_max persisted for MT_241\n",
      "Test dataset persisted as a time series pickle for MT_241\n",
      "MT_241 processed. The number of examples in train dataset is 4913\n",
      "MT_241 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_241 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_241 was adjusted to 248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persisted train TFRecord file for MT_241\n",
      "Persisted eval TFRecord file for MT_241\n",
      "Started processing for MT_242\n",
      "Scaler min_max generated on training data for MT_242\n",
      "Scaler min_max persisted for MT_242\n",
      "Test dataset persisted as a time series pickle for MT_242\n",
      "MT_242 processed. The number of examples in train dataset is 4913\n",
      "MT_242 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_242 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_242 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_242\n",
      "Persisted eval TFRecord file for MT_242\n",
      "Started processing for MT_243\n",
      "Scaler min_max generated on training data for MT_243\n",
      "Scaler min_max persisted for MT_243\n",
      "Test dataset persisted as a time series pickle for MT_243\n",
      "MT_243 processed. The number of examples in train dataset is 4913\n",
      "MT_243 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_243 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_243 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_243\n",
      "Persisted eval TFRecord file for MT_243\n",
      "Started processing for MT_244\n",
      "Scaler min_max generated on training data for MT_244\n",
      "Scaler min_max persisted for MT_244\n",
      "Test dataset persisted as a time series pickle for MT_244\n",
      "MT_244 processed. The number of examples in train dataset is 4913\n",
      "MT_244 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_244 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_244 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_244\n",
      "Persisted eval TFRecord file for MT_244\n",
      "Started processing for MT_245\n",
      "Scaler min_max generated on training data for MT_245\n",
      "Scaler min_max persisted for MT_245\n",
      "Test dataset persisted as a time series pickle for MT_245\n",
      "MT_245 processed. The number of examples in train dataset is 4913\n",
      "MT_245 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_245 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_245 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_245\n",
      "Persisted eval TFRecord file for MT_245\n",
      "Started processing for MT_246\n",
      "Scaler min_max generated on training data for MT_246\n",
      "Scaler min_max persisted for MT_246\n",
      "Test dataset persisted as a time series pickle for MT_246\n",
      "MT_246 processed. The number of examples in train dataset is 4913\n",
      "MT_246 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_246 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_246 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_246\n",
      "Persisted eval TFRecord file for MT_246\n",
      "Started processing for MT_247\n",
      "Scaler min_max generated on training data for MT_247\n",
      "Scaler min_max persisted for MT_247\n",
      "Test dataset persisted as a time series pickle for MT_247\n",
      "MT_247 processed. The number of examples in train dataset is 4913\n",
      "MT_247 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_247 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_247 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_247\n",
      "Persisted eval TFRecord file for MT_247\n",
      "Started processing for MT_248\n",
      "Scaler min_max generated on training data for MT_248\n",
      "Scaler min_max persisted for MT_248\n",
      "Test dataset persisted as a time series pickle for MT_248\n",
      "MT_248 processed. The number of examples in train dataset is 4913\n",
      "MT_248 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_248 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_248 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_248\n",
      "Persisted eval TFRecord file for MT_248\n",
      "Started processing for MT_249\n",
      "Scaler min_max generated on training data for MT_249\n",
      "Scaler min_max persisted for MT_249\n",
      "Test dataset persisted as a time series pickle for MT_249\n",
      "MT_249 processed. The number of examples in train dataset is 4913\n",
      "MT_249 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_249 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_249 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_249\n",
      "Persisted eval TFRecord file for MT_249\n",
      "Started processing for MT_250\n",
      "Scaler min_max generated on training data for MT_250\n",
      "Scaler min_max persisted for MT_250\n",
      "Test dataset persisted as a time series pickle for MT_250\n",
      "MT_250 processed. The number of examples in train dataset is 4913\n",
      "MT_250 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_250 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_250 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_250\n",
      "Persisted eval TFRecord file for MT_250\n",
      "Started processing for MT_251\n",
      "Scaler min_max generated on training data for MT_251\n",
      "Scaler min_max persisted for MT_251\n",
      "Test dataset persisted as a time series pickle for MT_251\n",
      "MT_251 processed. The number of examples in train dataset is 4913\n",
      "MT_251 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_251 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_251 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_251\n",
      "Persisted eval TFRecord file for MT_251\n",
      "Started processing for MT_252\n",
      "Scaler min_max generated on training data for MT_252\n",
      "Scaler min_max persisted for MT_252\n",
      "Test dataset persisted as a time series pickle for MT_252\n",
      "MT_252 processed. The number of examples in train dataset is 4913\n",
      "MT_252 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_252 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_252 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_252\n",
      "Persisted eval TFRecord file for MT_252\n",
      "Started processing for MT_253\n",
      "Scaler min_max generated on training data for MT_253\n",
      "Scaler min_max persisted for MT_253\n",
      "Test dataset persisted as a time series pickle for MT_253\n",
      "MT_253 processed. The number of examples in train dataset is 4913\n",
      "MT_253 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_253 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_253 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_253\n",
      "Persisted eval TFRecord file for MT_253\n",
      "Started processing for MT_254\n",
      "Scaler min_max generated on training data for MT_254\n",
      "Scaler min_max persisted for MT_254\n",
      "Test dataset persisted as a time series pickle for MT_254\n",
      "MT_254 processed. The number of examples in train dataset is 4913\n",
      "MT_254 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_254 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_254 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_254\n",
      "Persisted eval TFRecord file for MT_254\n",
      "Started processing for MT_255\n",
      "Scaler min_max generated on training data for MT_255\n",
      "Scaler min_max persisted for MT_255\n",
      "Test dataset persisted as a time series pickle for MT_255\n",
      "MT_255 processed. The number of examples in train dataset is 4913\n",
      "MT_255 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_255 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_255 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_255\n",
      "Persisted eval TFRecord file for MT_255\n",
      "Started processing for MT_256\n",
      "Scaler min_max generated on training data for MT_256\n",
      "Scaler min_max persisted for MT_256\n",
      "Test dataset persisted as a time series pickle for MT_256\n",
      "MT_256 processed. The number of examples in train dataset is 4913\n",
      "MT_256 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_256 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_256 was adjusted to 248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persisted train TFRecord file for MT_256\n",
      "Persisted eval TFRecord file for MT_256\n",
      "Started processing for MT_257\n",
      "Scaler min_max generated on training data for MT_257\n",
      "Scaler min_max persisted for MT_257\n",
      "Test dataset persisted as a time series pickle for MT_257\n",
      "MT_257 processed. The number of examples in train dataset is 4913\n",
      "MT_257 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_257 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_257 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_257\n",
      "Persisted eval TFRecord file for MT_257\n",
      "Started processing for MT_258\n",
      "Scaler min_max generated on training data for MT_258\n",
      "Scaler min_max persisted for MT_258\n",
      "Test dataset persisted as a time series pickle for MT_258\n",
      "MT_258 processed. The number of examples in train dataset is 4913\n",
      "MT_258 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_258 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_258 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_258\n",
      "Persisted eval TFRecord file for MT_258\n",
      "Started processing for MT_259\n",
      "Scaler min_max generated on training data for MT_259\n",
      "Scaler min_max persisted for MT_259\n",
      "Test dataset persisted as a time series pickle for MT_259\n",
      "MT_259 processed. The number of examples in train dataset is 4913\n",
      "MT_259 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_259 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_259 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_259\n",
      "Persisted eval TFRecord file for MT_259\n",
      "Started processing for MT_260\n",
      "Scaler min_max generated on training data for MT_260\n",
      "Scaler min_max persisted for MT_260\n",
      "Test dataset persisted as a time series pickle for MT_260\n",
      "MT_260 processed. The number of examples in train dataset is 4913\n",
      "MT_260 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_260 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_260 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_260\n",
      "Persisted eval TFRecord file for MT_260\n",
      "Started processing for MT_261\n",
      "Scaler min_max generated on training data for MT_261\n",
      "Scaler min_max persisted for MT_261\n",
      "Test dataset persisted as a time series pickle for MT_261\n",
      "MT_261 processed. The number of examples in train dataset is 4913\n",
      "MT_261 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_261 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_261 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_261\n",
      "Persisted eval TFRecord file for MT_261\n",
      "Started processing for MT_262\n",
      "Scaler min_max generated on training data for MT_262\n",
      "Scaler min_max persisted for MT_262\n",
      "Test dataset persisted as a time series pickle for MT_262\n",
      "MT_262 processed. The number of examples in train dataset is 4913\n",
      "MT_262 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_262 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_262 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_262\n",
      "Persisted eval TFRecord file for MT_262\n",
      "Started processing for MT_263\n",
      "Scaler min_max generated on training data for MT_263\n",
      "Scaler min_max persisted for MT_263\n",
      "Test dataset persisted as a time series pickle for MT_263\n",
      "MT_263 processed. The number of examples in train dataset is 4913\n",
      "MT_263 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_263 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_263 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_263\n",
      "Persisted eval TFRecord file for MT_263\n",
      "Started processing for MT_264\n",
      "Scaler min_max generated on training data for MT_264\n",
      "Scaler min_max persisted for MT_264\n",
      "Test dataset persisted as a time series pickle for MT_264\n",
      "MT_264 processed. The number of examples in train dataset is 4913\n",
      "MT_264 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_264 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_264 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_264\n",
      "Persisted eval TFRecord file for MT_264\n",
      "Started processing for MT_265\n",
      "Scaler min_max generated on training data for MT_265\n",
      "Scaler min_max persisted for MT_265\n",
      "Test dataset persisted as a time series pickle for MT_265\n",
      "MT_265 processed. The number of examples in train dataset is 4913\n",
      "MT_265 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_265 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_265 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_265\n",
      "Persisted eval TFRecord file for MT_265\n",
      "Started processing for MT_266\n",
      "Scaler min_max generated on training data for MT_266\n",
      "Scaler min_max persisted for MT_266\n",
      "Test dataset persisted as a time series pickle for MT_266\n",
      "MT_266 processed. The number of examples in train dataset is 4913\n",
      "MT_266 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_266 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_266 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_266\n",
      "Persisted eval TFRecord file for MT_266\n",
      "Started processing for MT_267\n",
      "Scaler min_max generated on training data for MT_267\n",
      "Scaler min_max persisted for MT_267\n",
      "Test dataset persisted as a time series pickle for MT_267\n",
      "MT_267 processed. The number of examples in train dataset is 4913\n",
      "MT_267 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_267 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_267 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_267\n",
      "Persisted eval TFRecord file for MT_267\n",
      "Started processing for MT_268\n",
      "Scaler min_max generated on training data for MT_268\n",
      "Scaler min_max persisted for MT_268\n",
      "Test dataset persisted as a time series pickle for MT_268\n",
      "MT_268 processed. The number of examples in train dataset is 4913\n",
      "MT_268 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_268 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_268 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_268\n",
      "Persisted eval TFRecord file for MT_268\n",
      "Started processing for MT_269\n",
      "Scaler min_max generated on training data for MT_269\n",
      "Scaler min_max persisted for MT_269\n",
      "Test dataset persisted as a time series pickle for MT_269\n",
      "MT_269 processed. The number of examples in train dataset is 4913\n",
      "MT_269 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_269 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_269 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_269\n",
      "Persisted eval TFRecord file for MT_269\n",
      "Started processing for MT_270\n",
      "Scaler min_max generated on training data for MT_270\n",
      "Scaler min_max persisted for MT_270\n",
      "Test dataset persisted as a time series pickle for MT_270\n",
      "MT_270 processed. The number of examples in train dataset is 4913\n",
      "MT_270 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_270 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_270 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_270\n",
      "Persisted eval TFRecord file for MT_270\n",
      "Started processing for MT_271\n",
      "Scaler min_max generated on training data for MT_271\n",
      "Scaler min_max persisted for MT_271\n",
      "Test dataset persisted as a time series pickle for MT_271\n",
      "MT_271 processed. The number of examples in train dataset is 4913\n",
      "MT_271 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_271 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_271 was adjusted to 248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persisted train TFRecord file for MT_271\n",
      "Persisted eval TFRecord file for MT_271\n",
      "Started processing for MT_272\n",
      "Scaler min_max generated on training data for MT_272\n",
      "Scaler min_max persisted for MT_272\n",
      "Test dataset persisted as a time series pickle for MT_272\n",
      "MT_272 processed. The number of examples in train dataset is 4913\n",
      "MT_272 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_272 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_272 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_272\n",
      "Persisted eval TFRecord file for MT_272\n",
      "Started processing for MT_273\n",
      "Scaler min_max generated on training data for MT_273\n",
      "Scaler min_max persisted for MT_273\n",
      "Test dataset persisted as a time series pickle for MT_273\n",
      "MT_273 processed. The number of examples in train dataset is 4913\n",
      "MT_273 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_273 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_273 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_273\n",
      "Persisted eval TFRecord file for MT_273\n",
      "Started processing for MT_274\n",
      "Scaler min_max generated on training data for MT_274\n",
      "Scaler min_max persisted for MT_274\n",
      "Test dataset persisted as a time series pickle for MT_274\n",
      "MT_274 processed. The number of examples in train dataset is 4913\n",
      "MT_274 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_274 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_274 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_274\n",
      "Persisted eval TFRecord file for MT_274\n",
      "Started processing for MT_275\n",
      "Scaler min_max generated on training data for MT_275\n",
      "Scaler min_max persisted for MT_275\n",
      "Test dataset persisted as a time series pickle for MT_275\n",
      "MT_275 processed. The number of examples in train dataset is 4913\n",
      "MT_275 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_275 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_275 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_275\n",
      "Persisted eval TFRecord file for MT_275\n",
      "Started processing for MT_276\n",
      "Scaler min_max generated on training data for MT_276\n",
      "Scaler min_max persisted for MT_276\n",
      "Test dataset persisted as a time series pickle for MT_276\n",
      "MT_276 processed. The number of examples in train dataset is 4913\n",
      "MT_276 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_276 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_276 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_276\n",
      "Persisted eval TFRecord file for MT_276\n",
      "Started processing for MT_277\n",
      "Scaler min_max generated on training data for MT_277\n",
      "Scaler min_max persisted for MT_277\n",
      "Test dataset persisted as a time series pickle for MT_277\n",
      "MT_277 processed. The number of examples in train dataset is 4913\n",
      "MT_277 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_277 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_277 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_277\n",
      "Persisted eval TFRecord file for MT_277\n",
      "Started processing for MT_278\n",
      "Scaler min_max generated on training data for MT_278\n",
      "Scaler min_max persisted for MT_278\n",
      "Test dataset persisted as a time series pickle for MT_278\n",
      "MT_278 processed. The number of examples in train dataset is 4913\n",
      "MT_278 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_278 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_278 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_278\n",
      "Persisted eval TFRecord file for MT_278\n",
      "Started processing for MT_279\n",
      "Scaler min_max generated on training data for MT_279\n",
      "Scaler min_max persisted for MT_279\n",
      "Test dataset persisted as a time series pickle for MT_279\n",
      "MT_279 processed. The number of examples in train dataset is 4913\n",
      "MT_279 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_279 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_279 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_279\n",
      "Persisted eval TFRecord file for MT_279\n",
      "Started processing for MT_280\n",
      "Scaler min_max generated on training data for MT_280\n",
      "Scaler min_max persisted for MT_280\n",
      "Test dataset persisted as a time series pickle for MT_280\n",
      "MT_280 processed. The number of examples in train dataset is 4913\n",
      "MT_280 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_280 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_280 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_280\n",
      "Persisted eval TFRecord file for MT_280\n",
      "Started processing for MT_281\n",
      "Scaler min_max generated on training data for MT_281\n",
      "Scaler min_max persisted for MT_281\n",
      "Test dataset persisted as a time series pickle for MT_281\n",
      "MT_281 processed. The number of examples in train dataset is 4913\n",
      "MT_281 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_281 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_281 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_281\n",
      "Persisted eval TFRecord file for MT_281\n",
      "Started processing for MT_282\n",
      "Scaler min_max generated on training data for MT_282\n",
      "Scaler min_max persisted for MT_282\n",
      "Test dataset persisted as a time series pickle for MT_282\n",
      "MT_282 processed. The number of examples in train dataset is 4913\n",
      "MT_282 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_282 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_282 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_282\n",
      "Persisted eval TFRecord file for MT_282\n",
      "Started processing for MT_283\n",
      "Scaler min_max generated on training data for MT_283\n",
      "Scaler min_max persisted for MT_283\n",
      "Test dataset persisted as a time series pickle for MT_283\n",
      "MT_283 processed. The number of examples in train dataset is 4913\n",
      "MT_283 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_283 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_283 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_283\n",
      "Persisted eval TFRecord file for MT_283\n",
      "Started processing for MT_284\n",
      "Scaler min_max generated on training data for MT_284\n",
      "Scaler min_max persisted for MT_284\n",
      "Test dataset persisted as a time series pickle for MT_284\n",
      "MT_284 processed. The number of examples in train dataset is 4913\n",
      "MT_284 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_284 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_284 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_284\n",
      "Persisted eval TFRecord file for MT_284\n",
      "Started processing for MT_285\n",
      "Scaler min_max generated on training data for MT_285\n",
      "Scaler min_max persisted for MT_285\n",
      "Test dataset persisted as a time series pickle for MT_285\n",
      "MT_285 processed. The number of examples in train dataset is 4913\n",
      "MT_285 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_285 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_285 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_285\n",
      "Persisted eval TFRecord file for MT_285\n",
      "Started processing for MT_286\n",
      "Scaler min_max generated on training data for MT_286\n",
      "Scaler min_max persisted for MT_286\n",
      "Test dataset persisted as a time series pickle for MT_286\n",
      "MT_286 processed. The number of examples in train dataset is 4913\n",
      "MT_286 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_286 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_286 was adjusted to 248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persisted train TFRecord file for MT_286\n",
      "Persisted eval TFRecord file for MT_286\n",
      "Started processing for MT_287\n",
      "Scaler min_max generated on training data for MT_287\n",
      "Scaler min_max persisted for MT_287\n",
      "Test dataset persisted as a time series pickle for MT_287\n",
      "MT_287 processed. The number of examples in train dataset is 4913\n",
      "MT_287 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_287 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_287 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_287\n",
      "Persisted eval TFRecord file for MT_287\n",
      "Started processing for MT_288\n",
      "Scaler min_max generated on training data for MT_288\n",
      "Scaler min_max persisted for MT_288\n",
      "Test dataset persisted as a time series pickle for MT_288\n",
      "MT_288 processed. The number of examples in train dataset is 4913\n",
      "MT_288 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_288 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_288 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_288\n",
      "Persisted eval TFRecord file for MT_288\n",
      "Started processing for MT_289\n",
      "Scaler min_max generated on training data for MT_289\n",
      "Scaler min_max persisted for MT_289\n",
      "Test dataset persisted as a time series pickle for MT_289\n",
      "MT_289 processed. The number of examples in train dataset is 4913\n",
      "MT_289 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_289 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_289 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_289\n",
      "Persisted eval TFRecord file for MT_289\n",
      "Started processing for MT_290\n",
      "Scaler min_max generated on training data for MT_290\n",
      "Scaler min_max persisted for MT_290\n",
      "Test dataset persisted as a time series pickle for MT_290\n",
      "MT_290 processed. The number of examples in train dataset is 4913\n",
      "MT_290 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_290 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_290 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_290\n",
      "Persisted eval TFRecord file for MT_290\n",
      "Started processing for MT_291\n",
      "Scaler min_max generated on training data for MT_291\n",
      "Scaler min_max persisted for MT_291\n",
      "Test dataset persisted as a time series pickle for MT_291\n",
      "MT_291 processed. The number of examples in train dataset is 4913\n",
      "MT_291 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_291 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_291 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_291\n",
      "Persisted eval TFRecord file for MT_291\n",
      "Started processing for MT_292\n",
      "Scaler min_max generated on training data for MT_292\n",
      "Scaler min_max persisted for MT_292\n",
      "Test dataset persisted as a time series pickle for MT_292\n",
      "MT_292 processed. The number of examples in train dataset is 4913\n",
      "MT_292 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_292 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_292 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_292\n",
      "Persisted eval TFRecord file for MT_292\n",
      "Started processing for MT_293\n",
      "Scaler min_max generated on training data for MT_293\n",
      "Scaler min_max persisted for MT_293\n",
      "Test dataset persisted as a time series pickle for MT_293\n",
      "MT_293 processed. The number of examples in train dataset is 4913\n",
      "MT_293 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_293 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_293 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_293\n",
      "Persisted eval TFRecord file for MT_293\n",
      "Started processing for MT_294\n",
      "Scaler min_max generated on training data for MT_294\n",
      "Scaler min_max persisted for MT_294\n",
      "Test dataset persisted as a time series pickle for MT_294\n",
      "MT_294 processed. The number of examples in train dataset is 4913\n",
      "MT_294 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_294 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_294 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_294\n",
      "Persisted eval TFRecord file for MT_294\n",
      "Started processing for MT_295\n",
      "Scaler min_max generated on training data for MT_295\n",
      "Scaler min_max persisted for MT_295\n",
      "Test dataset persisted as a time series pickle for MT_295\n",
      "MT_295 processed. The number of examples in train dataset is 4913\n",
      "MT_295 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_295 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_295 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_295\n",
      "Persisted eval TFRecord file for MT_295\n",
      "Started processing for MT_296\n",
      "Scaler min_max generated on training data for MT_296\n",
      "Scaler min_max persisted for MT_296\n",
      "Test dataset persisted as a time series pickle for MT_296\n",
      "MT_296 processed. The number of examples in train dataset is 4913\n",
      "MT_296 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_296 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_296 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_296\n",
      "Persisted eval TFRecord file for MT_296\n",
      "Started processing for MT_297\n",
      "Scaler min_max generated on training data for MT_297\n",
      "Scaler min_max persisted for MT_297\n",
      "Test dataset persisted as a time series pickle for MT_297\n",
      "MT_297 processed. The number of examples in train dataset is 4913\n",
      "MT_297 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_297 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_297 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_297\n",
      "Persisted eval TFRecord file for MT_297\n",
      "Started processing for MT_298\n",
      "Scaler min_max generated on training data for MT_298\n",
      "Scaler min_max persisted for MT_298\n",
      "Test dataset persisted as a time series pickle for MT_298\n",
      "MT_298 processed. The number of examples in train dataset is 4913\n",
      "MT_298 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_298 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_298 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_298\n",
      "Persisted eval TFRecord file for MT_298\n",
      "Started processing for MT_299\n",
      "Scaler min_max generated on training data for MT_299\n",
      "Scaler min_max persisted for MT_299\n",
      "Test dataset persisted as a time series pickle for MT_299\n",
      "MT_299 processed. The number of examples in train dataset is 4913\n",
      "MT_299 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_299 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_299 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_299\n",
      "Persisted eval TFRecord file for MT_299\n",
      "Started processing for MT_300\n",
      "Scaler min_max generated on training data for MT_300\n",
      "Scaler min_max persisted for MT_300\n",
      "Test dataset persisted as a time series pickle for MT_300\n",
      "MT_300 processed. The number of examples in train dataset is 4913\n",
      "MT_300 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_300 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_300 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_300\n",
      "Persisted eval TFRecord file for MT_300\n",
      "Started processing for MT_301\n",
      "Scaler min_max generated on training data for MT_301\n",
      "Scaler min_max persisted for MT_301\n",
      "Test dataset persisted as a time series pickle for MT_301\n",
      "MT_301 processed. The number of examples in train dataset is 4913\n",
      "MT_301 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_301 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_301 was adjusted to 248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persisted train TFRecord file for MT_301\n",
      "Persisted eval TFRecord file for MT_301\n",
      "Started processing for MT_302\n",
      "Scaler min_max generated on training data for MT_302\n",
      "Scaler min_max persisted for MT_302\n",
      "Test dataset persisted as a time series pickle for MT_302\n",
      "MT_302 processed. The number of examples in train dataset is 4913\n",
      "MT_302 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_302 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_302 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_302\n",
      "Persisted eval TFRecord file for MT_302\n",
      "Started processing for MT_303\n",
      "Scaler min_max generated on training data for MT_303\n",
      "Scaler min_max persisted for MT_303\n",
      "Test dataset persisted as a time series pickle for MT_303\n",
      "MT_303 processed. The number of examples in train dataset is 4913\n",
      "MT_303 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_303 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_303 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_303\n",
      "Persisted eval TFRecord file for MT_303\n",
      "Started processing for MT_304\n",
      "Scaler min_max generated on training data for MT_304\n",
      "Scaler min_max persisted for MT_304\n",
      "Test dataset persisted as a time series pickle for MT_304\n",
      "MT_304 processed. The number of examples in train dataset is 4913\n",
      "MT_304 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_304 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_304 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_304\n",
      "Persisted eval TFRecord file for MT_304\n",
      "Started processing for MT_305\n",
      "Scaler min_max generated on training data for MT_305\n",
      "Scaler min_max persisted for MT_305\n",
      "Test dataset persisted as a time series pickle for MT_305\n",
      "MT_305 processed. The number of examples in train dataset is 4913\n",
      "MT_305 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_305 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_305 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_305\n",
      "Persisted eval TFRecord file for MT_305\n",
      "Started processing for MT_306\n",
      "Scaler min_max generated on training data for MT_306\n",
      "Scaler min_max persisted for MT_306\n",
      "Test dataset persisted as a time series pickle for MT_306\n",
      "MT_306 processed. The number of examples in train dataset is 4913\n",
      "MT_306 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_306 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_306 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_306\n",
      "Persisted eval TFRecord file for MT_306\n",
      "Started processing for MT_307\n",
      "Scaler min_max generated on training data for MT_307\n",
      "Scaler min_max persisted for MT_307\n",
      "Test dataset persisted as a time series pickle for MT_307\n",
      "MT_307 processed. The number of examples in train dataset is 4913\n",
      "MT_307 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_307 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_307 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_307\n",
      "Persisted eval TFRecord file for MT_307\n",
      "Started processing for MT_308\n",
      "Scaler min_max generated on training data for MT_308\n",
      "Scaler min_max persisted for MT_308\n",
      "Test dataset persisted as a time series pickle for MT_308\n",
      "MT_308 processed. The number of examples in train dataset is 4913\n",
      "MT_308 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_308 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_308 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_308\n",
      "Persisted eval TFRecord file for MT_308\n",
      "Started processing for MT_309\n",
      "Scaler min_max generated on training data for MT_309\n",
      "Scaler min_max persisted for MT_309\n",
      "Test dataset persisted as a time series pickle for MT_309\n",
      "MT_309 processed. The number of examples in train dataset is 4913\n",
      "MT_309 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_309 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_309 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_309\n",
      "Persisted eval TFRecord file for MT_309\n",
      "Started processing for MT_310\n",
      "Scaler min_max generated on training data for MT_310\n",
      "Scaler min_max persisted for MT_310\n",
      "Test dataset persisted as a time series pickle for MT_310\n",
      "MT_310 processed. The number of examples in train dataset is 4913\n",
      "MT_310 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_310 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_310 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_310\n",
      "Persisted eval TFRecord file for MT_310\n",
      "Started processing for MT_311\n",
      "Scaler min_max generated on training data for MT_311\n",
      "Scaler min_max persisted for MT_311\n",
      "Test dataset persisted as a time series pickle for MT_311\n",
      "MT_311 processed. The number of examples in train dataset is 4913\n",
      "MT_311 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_311 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_311 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_311\n",
      "Persisted eval TFRecord file for MT_311\n",
      "Started processing for MT_312\n",
      "Scaler min_max generated on training data for MT_312\n",
      "Scaler min_max persisted for MT_312\n",
      "Test dataset persisted as a time series pickle for MT_312\n",
      "MT_312 processed. The number of examples in train dataset is 4913\n",
      "MT_312 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_312 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_312 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_312\n",
      "Persisted eval TFRecord file for MT_312\n",
      "Started processing for MT_313\n",
      "Scaler min_max generated on training data for MT_313\n",
      "Scaler min_max persisted for MT_313\n",
      "Test dataset persisted as a time series pickle for MT_313\n",
      "MT_313 processed. The number of examples in train dataset is 4913\n",
      "MT_313 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_313 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_313 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_313\n",
      "Persisted eval TFRecord file for MT_313\n",
      "Started processing for MT_314\n",
      "Scaler min_max generated on training data for MT_314\n",
      "Scaler min_max persisted for MT_314\n",
      "Test dataset persisted as a time series pickle for MT_314\n",
      "MT_314 processed. The number of examples in train dataset is 4913\n",
      "MT_314 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_314 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_314 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_314\n",
      "Persisted eval TFRecord file for MT_314\n",
      "Started processing for MT_315\n",
      "Scaler min_max generated on training data for MT_315\n",
      "Scaler min_max persisted for MT_315\n",
      "Test dataset persisted as a time series pickle for MT_315\n",
      "MT_315 processed. The number of examples in train dataset is 4913\n",
      "MT_315 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_315 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_315 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_315\n",
      "Persisted eval TFRecord file for MT_315\n",
      "Started processing for MT_316\n",
      "Scaler min_max generated on training data for MT_316\n",
      "Scaler min_max persisted for MT_316\n",
      "Test dataset persisted as a time series pickle for MT_316\n",
      "MT_316 processed. The number of examples in train dataset is 4913\n",
      "MT_316 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_316 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_316 was adjusted to 248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persisted train TFRecord file for MT_316\n",
      "Persisted eval TFRecord file for MT_316\n",
      "Started processing for MT_317\n",
      "Scaler min_max generated on training data for MT_317\n",
      "Scaler min_max persisted for MT_317\n",
      "Test dataset persisted as a time series pickle for MT_317\n",
      "MT_317 processed. The number of examples in train dataset is 4913\n",
      "MT_317 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_317 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_317 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_317\n",
      "Persisted eval TFRecord file for MT_317\n",
      "Started processing for MT_318\n",
      "Scaler min_max generated on training data for MT_318\n",
      "Scaler min_max persisted for MT_318\n",
      "Test dataset persisted as a time series pickle for MT_318\n",
      "MT_318 processed. The number of examples in train dataset is 4913\n",
      "MT_318 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_318 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_318 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_318\n",
      "Persisted eval TFRecord file for MT_318\n",
      "Started processing for MT_319\n",
      "Scaler min_max generated on training data for MT_319\n",
      "Scaler min_max persisted for MT_319\n",
      "Test dataset persisted as a time series pickle for MT_319\n",
      "MT_319 processed. The number of examples in train dataset is 4913\n",
      "MT_319 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_319 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_319 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_319\n",
      "Persisted eval TFRecord file for MT_319\n",
      "Started processing for MT_320\n",
      "Scaler min_max generated on training data for MT_320\n",
      "Scaler min_max persisted for MT_320\n",
      "Test dataset persisted as a time series pickle for MT_320\n",
      "MT_320 processed. The number of examples in train dataset is 4913\n",
      "MT_320 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_320 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_320 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_320\n",
      "Persisted eval TFRecord file for MT_320\n",
      "Started processing for MT_321\n",
      "Scaler min_max generated on training data for MT_321\n",
      "Scaler min_max persisted for MT_321\n",
      "Test dataset persisted as a time series pickle for MT_321\n",
      "MT_321 processed. The number of examples in train dataset is 4913\n",
      "MT_321 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_321 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_321 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_321\n",
      "Persisted eval TFRecord file for MT_321\n",
      "Started processing for MT_322\n",
      "Scaler min_max generated on training data for MT_322\n",
      "Scaler min_max persisted for MT_322\n",
      "Test dataset persisted as a time series pickle for MT_322\n",
      "MT_322 processed. The number of examples in train dataset is 4913\n",
      "MT_322 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_322 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_322 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_322\n",
      "Persisted eval TFRecord file for MT_322\n",
      "Started processing for MT_323\n",
      "Scaler min_max generated on training data for MT_323\n",
      "Scaler min_max persisted for MT_323\n",
      "Test dataset persisted as a time series pickle for MT_323\n",
      "MT_323 processed. The number of examples in train dataset is 4913\n",
      "MT_323 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_323 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_323 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_323\n",
      "Persisted eval TFRecord file for MT_323\n",
      "Started processing for MT_324\n",
      "Scaler min_max generated on training data for MT_324\n",
      "Scaler min_max persisted for MT_324\n",
      "Test dataset persisted as a time series pickle for MT_324\n",
      "MT_324 processed. The number of examples in train dataset is 4913\n",
      "MT_324 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_324 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_324 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_324\n",
      "Persisted eval TFRecord file for MT_324\n",
      "Started processing for MT_325\n",
      "Scaler min_max generated on training data for MT_325\n",
      "Scaler min_max persisted for MT_325\n",
      "Test dataset persisted as a time series pickle for MT_325\n",
      "MT_325 processed. The number of examples in train dataset is 4913\n",
      "MT_325 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_325 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_325 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_325\n",
      "Persisted eval TFRecord file for MT_325\n",
      "Started processing for MT_326\n",
      "Scaler min_max generated on training data for MT_326\n",
      "Scaler min_max persisted for MT_326\n",
      "Test dataset persisted as a time series pickle for MT_326\n",
      "MT_326 processed. The number of examples in train dataset is 4913\n",
      "MT_326 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_326 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_326 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_326\n",
      "Persisted eval TFRecord file for MT_326\n",
      "Started processing for MT_327\n",
      "Scaler min_max generated on training data for MT_327\n",
      "Scaler min_max persisted for MT_327\n",
      "Test dataset persisted as a time series pickle for MT_327\n",
      "MT_327 processed. The number of examples in train dataset is 4913\n",
      "MT_327 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_327 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_327 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_327\n",
      "Persisted eval TFRecord file for MT_327\n",
      "Started processing for MT_328\n",
      "Scaler min_max generated on training data for MT_328\n",
      "Scaler min_max persisted for MT_328\n",
      "Test dataset persisted as a time series pickle for MT_328\n",
      "MT_328 processed. The number of examples in train dataset is 4913\n",
      "MT_328 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_328 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_328 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_328\n",
      "Persisted eval TFRecord file for MT_328\n",
      "Started processing for MT_329\n",
      "Scaler min_max generated on training data for MT_329\n",
      "Scaler min_max persisted for MT_329\n",
      "Test dataset persisted as a time series pickle for MT_329\n",
      "MT_329 processed. The number of examples in train dataset is 4913\n",
      "MT_329 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_329 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_329 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_329\n",
      "Persisted eval TFRecord file for MT_329\n",
      "Started processing for MT_330\n",
      "Scaler min_max generated on training data for MT_330\n",
      "Scaler min_max persisted for MT_330\n",
      "Test dataset persisted as a time series pickle for MT_330\n",
      "MT_330 processed. The number of examples in train dataset is 4913\n",
      "MT_330 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_330 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_330 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_330\n",
      "Persisted eval TFRecord file for MT_330\n",
      "Started processing for MT_331\n",
      "Scaler min_max generated on training data for MT_331\n",
      "Scaler min_max persisted for MT_331\n",
      "Test dataset persisted as a time series pickle for MT_331\n",
      "MT_331 processed. The number of examples in train dataset is 4913\n",
      "MT_331 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_331 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_331 was adjusted to 248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persisted train TFRecord file for MT_331\n",
      "Persisted eval TFRecord file for MT_331\n",
      "Started processing for MT_332\n",
      "Scaler min_max generated on training data for MT_332\n",
      "Scaler min_max persisted for MT_332\n",
      "Test dataset persisted as a time series pickle for MT_332\n",
      "MT_332 processed. The number of examples in train dataset is 4913\n",
      "MT_332 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_332 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_332 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_332\n",
      "Persisted eval TFRecord file for MT_332\n",
      "Started processing for MT_333\n",
      "Scaler min_max generated on training data for MT_333\n",
      "Scaler min_max persisted for MT_333\n",
      "Test dataset persisted as a time series pickle for MT_333\n",
      "MT_333 processed. The number of examples in train dataset is 4913\n",
      "MT_333 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_333 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_333 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_333\n",
      "Persisted eval TFRecord file for MT_333\n",
      "Started processing for MT_334\n",
      "Scaler min_max generated on training data for MT_334\n",
      "Scaler min_max persisted for MT_334\n",
      "Test dataset persisted as a time series pickle for MT_334\n",
      "MT_334 processed. The number of examples in train dataset is 4913\n",
      "MT_334 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_334 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_334 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_334\n",
      "Persisted eval TFRecord file for MT_334\n",
      "Started processing for MT_335\n",
      "Scaler min_max generated on training data for MT_335\n",
      "Scaler min_max persisted for MT_335\n",
      "Test dataset persisted as a time series pickle for MT_335\n",
      "MT_335 processed. The number of examples in train dataset is 4913\n",
      "MT_335 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_335 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_335 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_335\n",
      "Persisted eval TFRecord file for MT_335\n",
      "Started processing for MT_336\n",
      "Scaler min_max generated on training data for MT_336\n",
      "Scaler min_max persisted for MT_336\n",
      "Test dataset persisted as a time series pickle for MT_336\n",
      "MT_336 processed. The number of examples in train dataset is 4913\n",
      "MT_336 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_336 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_336 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_336\n",
      "Persisted eval TFRecord file for MT_336\n",
      "Started processing for MT_337\n",
      "Scaler min_max generated on training data for MT_337\n",
      "Scaler min_max persisted for MT_337\n",
      "Test dataset persisted as a time series pickle for MT_337\n",
      "MT_337 processed. The number of examples in train dataset is 4913\n",
      "MT_337 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_337 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_337 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_337\n",
      "Persisted eval TFRecord file for MT_337\n",
      "Started processing for MT_338\n",
      "Scaler min_max generated on training data for MT_338\n",
      "Scaler min_max persisted for MT_338\n",
      "Test dataset persisted as a time series pickle for MT_338\n",
      "MT_338 processed. The number of examples in train dataset is 4913\n",
      "MT_338 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_338 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_338 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_338\n",
      "Persisted eval TFRecord file for MT_338\n",
      "Started processing for MT_339\n",
      "Scaler min_max generated on training data for MT_339\n",
      "Scaler min_max persisted for MT_339\n",
      "Test dataset persisted as a time series pickle for MT_339\n",
      "MT_339 processed. The number of examples in train dataset is 4913\n",
      "MT_339 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_339 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_339 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_339\n",
      "Persisted eval TFRecord file for MT_339\n",
      "Started processing for MT_340\n",
      "Scaler min_max generated on training data for MT_340\n",
      "Scaler min_max persisted for MT_340\n",
      "Test dataset persisted as a time series pickle for MT_340\n",
      "MT_340 processed. The number of examples in train dataset is 4913\n",
      "MT_340 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_340 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_340 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_340\n",
      "Persisted eval TFRecord file for MT_340\n",
      "Started processing for MT_341\n",
      "Scaler min_max generated on training data for MT_341\n",
      "Scaler min_max persisted for MT_341\n",
      "Test dataset persisted as a time series pickle for MT_341\n",
      "MT_341 processed. The number of examples in train dataset is 4913\n",
      "MT_341 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_341 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_341 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_341\n",
      "Persisted eval TFRecord file for MT_341\n",
      "Started processing for MT_342\n",
      "Scaler min_max generated on training data for MT_342\n",
      "Scaler min_max persisted for MT_342\n",
      "Test dataset persisted as a time series pickle for MT_342\n",
      "MT_342 processed. The number of examples in train dataset is 4913\n",
      "MT_342 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_342 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_342 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_342\n",
      "Persisted eval TFRecord file for MT_342\n",
      "Started processing for MT_343\n",
      "Scaler min_max generated on training data for MT_343\n",
      "Scaler min_max persisted for MT_343\n",
      "Test dataset persisted as a time series pickle for MT_343\n",
      "MT_343 processed. The number of examples in train dataset is 4913\n",
      "MT_343 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_343 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_343 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_343\n",
      "Persisted eval TFRecord file for MT_343\n",
      "Started processing for MT_344\n",
      "Scaler min_max generated on training data for MT_344\n",
      "Scaler min_max persisted for MT_344\n",
      "Test dataset persisted as a time series pickle for MT_344\n",
      "MT_344 processed. The number of examples in train dataset is 4913\n",
      "MT_344 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_344 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_344 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_344\n",
      "Persisted eval TFRecord file for MT_344\n",
      "Started processing for MT_345\n",
      "Scaler min_max generated on training data for MT_345\n",
      "Scaler min_max persisted for MT_345\n",
      "Test dataset persisted as a time series pickle for MT_345\n",
      "MT_345 processed. The number of examples in train dataset is 4913\n",
      "MT_345 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_345 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_345 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_345\n",
      "Persisted eval TFRecord file for MT_345\n",
      "Started processing for MT_346\n",
      "Scaler min_max generated on training data for MT_346\n",
      "Scaler min_max persisted for MT_346\n",
      "Test dataset persisted as a time series pickle for MT_346\n",
      "MT_346 processed. The number of examples in train dataset is 4913\n",
      "MT_346 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_346 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_346 was adjusted to 248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persisted train TFRecord file for MT_346\n",
      "Persisted eval TFRecord file for MT_346\n",
      "Started processing for MT_347\n",
      "Scaler min_max generated on training data for MT_347\n",
      "Scaler min_max persisted for MT_347\n",
      "Test dataset persisted as a time series pickle for MT_347\n",
      "MT_347 processed. The number of examples in train dataset is 4913\n",
      "MT_347 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_347 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_347 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_347\n",
      "Persisted eval TFRecord file for MT_347\n",
      "Started processing for MT_348\n",
      "Scaler min_max generated on training data for MT_348\n",
      "Scaler min_max persisted for MT_348\n",
      "Test dataset persisted as a time series pickle for MT_348\n",
      "MT_348 processed. The number of examples in train dataset is 4913\n",
      "MT_348 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_348 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_348 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_348\n",
      "Persisted eval TFRecord file for MT_348\n",
      "Started processing for MT_349\n",
      "Scaler min_max generated on training data for MT_349\n",
      "Scaler min_max persisted for MT_349\n",
      "Test dataset persisted as a time series pickle for MT_349\n",
      "MT_349 processed. The number of examples in train dataset is 4913\n",
      "MT_349 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_349 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_349 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_349\n",
      "Persisted eval TFRecord file for MT_349\n",
      "Started processing for MT_350\n",
      "Scaler min_max generated on training data for MT_350\n",
      "Scaler min_max persisted for MT_350\n",
      "Test dataset persisted as a time series pickle for MT_350\n",
      "MT_350 processed. The number of examples in train dataset is 4913\n",
      "MT_350 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_350 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_350 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_350\n",
      "Persisted eval TFRecord file for MT_350\n",
      "Started processing for MT_351\n",
      "Scaler min_max generated on training data for MT_351\n",
      "Scaler min_max persisted for MT_351\n",
      "Test dataset persisted as a time series pickle for MT_351\n",
      "MT_351 processed. The number of examples in train dataset is 4913\n",
      "MT_351 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_351 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_351 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_351\n",
      "Persisted eval TFRecord file for MT_351\n",
      "Started processing for MT_352\n",
      "Scaler min_max generated on training data for MT_352\n",
      "Scaler min_max persisted for MT_352\n",
      "Test dataset persisted as a time series pickle for MT_352\n",
      "MT_352 processed. The number of examples in train dataset is 4913\n",
      "MT_352 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_352 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_352 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_352\n",
      "Persisted eval TFRecord file for MT_352\n",
      "Started processing for MT_353\n",
      "Scaler min_max generated on training data for MT_353\n",
      "Scaler min_max persisted for MT_353\n",
      "Test dataset persisted as a time series pickle for MT_353\n",
      "MT_353 processed. The number of examples in train dataset is 4913\n",
      "MT_353 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_353 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_353 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_353\n",
      "Persisted eval TFRecord file for MT_353\n",
      "Started processing for MT_354\n",
      "Scaler min_max generated on training data for MT_354\n",
      "Scaler min_max persisted for MT_354\n",
      "Test dataset persisted as a time series pickle for MT_354\n",
      "MT_354 processed. The number of examples in train dataset is 4913\n",
      "MT_354 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_354 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_354 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_354\n",
      "Persisted eval TFRecord file for MT_354\n",
      "Started processing for MT_355\n",
      "Scaler min_max generated on training data for MT_355\n",
      "Scaler min_max persisted for MT_355\n",
      "Test dataset persisted as a time series pickle for MT_355\n",
      "MT_355 processed. The number of examples in train dataset is 4913\n",
      "MT_355 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_355 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_355 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_355\n",
      "Persisted eval TFRecord file for MT_355\n",
      "Started processing for MT_356\n",
      "Scaler min_max generated on training data for MT_356\n",
      "Scaler min_max persisted for MT_356\n",
      "Test dataset persisted as a time series pickle for MT_356\n",
      "MT_356 processed. The number of examples in train dataset is 4913\n",
      "MT_356 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_356 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_356 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_356\n",
      "Persisted eval TFRecord file for MT_356\n",
      "Started processing for MT_357\n",
      "Scaler min_max generated on training data for MT_357\n",
      "Scaler min_max persisted for MT_357\n",
      "Test dataset persisted as a time series pickle for MT_357\n",
      "MT_357 processed. The number of examples in train dataset is 4913\n",
      "MT_357 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_357 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_357 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_357\n",
      "Persisted eval TFRecord file for MT_357\n",
      "Started processing for MT_358\n",
      "Scaler min_max generated on training data for MT_358\n",
      "Scaler min_max persisted for MT_358\n",
      "Test dataset persisted as a time series pickle for MT_358\n",
      "MT_358 processed. The number of examples in train dataset is 4913\n",
      "MT_358 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_358 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_358 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_358\n",
      "Persisted eval TFRecord file for MT_358\n",
      "Started processing for MT_359\n",
      "Scaler min_max generated on training data for MT_359\n",
      "Scaler min_max persisted for MT_359\n",
      "Test dataset persisted as a time series pickle for MT_359\n",
      "MT_359 processed. The number of examples in train dataset is 4913\n",
      "MT_359 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_359 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_359 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_359\n",
      "Persisted eval TFRecord file for MT_359\n",
      "Started processing for MT_360\n",
      "Scaler min_max generated on training data for MT_360\n",
      "Scaler min_max persisted for MT_360\n",
      "Test dataset persisted as a time series pickle for MT_360\n",
      "MT_360 processed. The number of examples in train dataset is 4913\n",
      "MT_360 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_360 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_360 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_360\n",
      "Persisted eval TFRecord file for MT_360\n",
      "Started processing for MT_361\n",
      "Scaler min_max generated on training data for MT_361\n",
      "Scaler min_max persisted for MT_361\n",
      "Test dataset persisted as a time series pickle for MT_361\n",
      "MT_361 processed. The number of examples in train dataset is 4913\n",
      "MT_361 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_361 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_361 was adjusted to 248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persisted train TFRecord file for MT_361\n",
      "Persisted eval TFRecord file for MT_361\n",
      "Started processing for MT_362\n",
      "Scaler min_max generated on training data for MT_362\n",
      "Scaler min_max persisted for MT_362\n",
      "Test dataset persisted as a time series pickle for MT_362\n",
      "MT_362 processed. The number of examples in train dataset is 4913\n",
      "MT_362 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_362 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_362 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_362\n",
      "Persisted eval TFRecord file for MT_362\n",
      "Started processing for MT_363\n",
      "Scaler min_max generated on training data for MT_363\n",
      "Scaler min_max persisted for MT_363\n",
      "Test dataset persisted as a time series pickle for MT_363\n",
      "MT_363 processed. The number of examples in train dataset is 4913\n",
      "MT_363 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_363 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_363 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_363\n",
      "Persisted eval TFRecord file for MT_363\n",
      "Started processing for MT_364\n",
      "Scaler min_max generated on training data for MT_364\n",
      "Scaler min_max persisted for MT_364\n",
      "Test dataset persisted as a time series pickle for MT_364\n",
      "MT_364 processed. The number of examples in train dataset is 4913\n",
      "MT_364 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_364 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_364 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_364\n",
      "Persisted eval TFRecord file for MT_364\n",
      "Started processing for MT_365\n",
      "Scaler min_max generated on training data for MT_365\n",
      "Scaler min_max persisted for MT_365\n",
      "Test dataset persisted as a time series pickle for MT_365\n",
      "MT_365 processed. The number of examples in train dataset is 4913\n",
      "MT_365 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_365 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_365 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_365\n",
      "Persisted eval TFRecord file for MT_365\n",
      "Started processing for MT_366\n",
      "Scaler min_max generated on training data for MT_366\n",
      "Scaler min_max persisted for MT_366\n",
      "Test dataset persisted as a time series pickle for MT_366\n",
      "MT_366 processed. The number of examples in train dataset is 4913\n",
      "MT_366 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_366 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_366 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_366\n",
      "Persisted eval TFRecord file for MT_366\n",
      "Started processing for MT_367\n",
      "Scaler min_max generated on training data for MT_367\n",
      "Scaler min_max persisted for MT_367\n",
      "Test dataset persisted as a time series pickle for MT_367\n",
      "MT_367 processed. The number of examples in train dataset is 4913\n",
      "MT_367 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_367 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_367 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_367\n",
      "Persisted eval TFRecord file for MT_367\n",
      "Started processing for MT_368\n",
      "Scaler min_max generated on training data for MT_368\n",
      "Scaler min_max persisted for MT_368\n",
      "Test dataset persisted as a time series pickle for MT_368\n",
      "MT_368 processed. The number of examples in train dataset is 4913\n",
      "MT_368 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_368 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_368 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_368\n",
      "Persisted eval TFRecord file for MT_368\n",
      "Started processing for MT_369\n",
      "Scaler min_max generated on training data for MT_369\n",
      "Scaler min_max persisted for MT_369\n",
      "Test dataset persisted as a time series pickle for MT_369\n",
      "MT_369 processed. The number of examples in train dataset is 4913\n",
      "MT_369 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_369 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_369 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_369\n",
      "Persisted eval TFRecord file for MT_369\n",
      "Started processing for MT_370\n",
      "Scaler min_max generated on training data for MT_370\n",
      "Scaler min_max persisted for MT_370\n",
      "Test dataset persisted as a time series pickle for MT_370\n",
      "MT_370 processed. The number of examples in train dataset is 4913\n",
      "MT_370 processed. The number of examples in eval dataset is 249\n",
      "For 8 cores in Cloud TPU, the number of train examples for MT_370 was adjusted to 4912\n",
      "For 8 cores in Cloud TPU, the number of eval examples for MT_370 was adjusted to 248\n",
      "Persisted train TFRecord file for MT_370\n",
      "Persisted eval TFRecord file for MT_370\n"
     ]
    }
   ],
   "source": [
    "for token_id in [token_id for token_id in token_ids if token_id not in excluded_token_ids]:\n",
    "    \n",
    "    # initialize the examples dictionary for each customer\n",
    "    examples = {\n",
    "        'train': [],\n",
    "        'eval': [],\n",
    "        # test dataset is not passed to SLDB\n",
    "        # 'test': []\n",
    "    }\n",
    "\n",
    "    # get the customer identifier\n",
    "    customer_id = 'MT_{:03d}'.format(token_id)\n",
    "    customer_id\n",
    "    print('Started processing for {}'.format(customer_id))\n",
    "\n",
    "    # a temporary dataframe with data per customer_id to build the sub-series/examples\n",
    "    # data_df = filtered_output[filtered_output['token_id'] == token_id].copy()\n",
    "    \n",
    "    # use now a reference to the dataframe in the data dictionary \n",
    "    data_df = data[customer_id]\n",
    "\n",
    "    # expand with positional encodings\n",
    "    data_df['sin_hours_from_start'] = np.sin(2*np.pi*data_df.hours_from_start/total_hours)\n",
    "    data_df['cos_hours_from_start'] = np.cos(2*np.pi*data_df.hours_from_start/total_hours)\n",
    "    data_df['sin_hour_day'] = np.sin(2*np.pi*data_df.hour_of_day/hours_in_day)\n",
    "    data_df['cos_hour_day'] = np.cos(2*np.pi*data_df.hour_of_day/hours_in_day)\n",
    "    data_df['sin_day_week'] = np.sin(2*np.pi*data_df.day_of_week/days_in_week)\n",
    "    data_df['cos_day_week'] = np.cos(2*np.pi*data_df.day_of_week/days_in_week)\n",
    "    # data_df['sin_day_month'] = np.sin(2*np.pi*data_df.day_of_month/days_in_month)\n",
    "    # data_df['cos_day_month'] = np.cos(2*np.pi*data_df.day_of_month/days_in_month)\n",
    "    # data_df['sin_day_year'] = np.sin(2*np.pi*data_df.day_of_year/days_in_year)\n",
    "    # data_df['cos_day_year'] = np.cos(2*np.pi*data_df.day_of_year/days_in_year)\n",
    "\n",
    "    # get a series for the power usage variable on the training dataset, to fit the scaler\n",
    "    lectures_train_data = data_df['power_usage'][:train_interval_end]\n",
    "\n",
    "    # fit a scaler only on train data\n",
    "    # it is required to pass the power usage time series to a (?, 1) NumPy array\n",
    "    lectures_train_data_array = np.array(lectures_train_data).reshape(-1, 1)\n",
    "    \n",
    "    # use MinMax scaler or Standard scaler\n",
    "\n",
    "    # get MinMaxScaler on train data, store it in a dictionary\n",
    "    scaler_type = 'min_max'\n",
    "    scaler = MinMaxScaler()\n",
    "    fitted_scaler = scaler.fit(lectures_train_data_array)\n",
    "    print('Scaler {} generated on training data for {}'.format(scaler_type, customer_id))\n",
    "\n",
    "    # persist the scaler\n",
    "    scaler_filename = '{}/{}_{}.save'.format(scalers_dir, scaler_type, customer_id)\n",
    "    joblib.dump(fitted_scaler, scaler_filename)\n",
    "    print('Scaler {} persisted for {}'.format(scaler_type, customer_id))\n",
    "    \n",
    "    '''\n",
    "    # get Standard on train data, store it in a dictionary\n",
    "    scaler_type = 'standard'\n",
    "    scaler = StandardScaler()\n",
    "    fitted_scaler = scaler.fit(lectures_train_data_array)\n",
    "    print('Scaler {} generated on training data for {}'.format(scaler_type, customer_id))\n",
    "\n",
    "    # persist the scaler\n",
    "    scaler_filename = '{}/{}_{}.save'.format(scalers_dir, scaler_type, customer_id)\n",
    "    joblib.dump(fitted_scaler, scaler_filename)\n",
    "    print('Scaler {} persisted for {}'.format(scaler_type, customer_id))\n",
    "    '''\n",
    "        \n",
    "    # get an array from the variable time series (seen and unseen)\n",
    "    all_data_variable_array = np.array(data_df.power_usage).reshape(-1, 1)\n",
    "\n",
    "    # apply the scaler over all data (seen and unseen)\n",
    "    # rescale, and squeeze to drop the extra dimension, then assign to the new column kw_scaled\n",
    "    data_df['kw_scaled'] = np.squeeze(fitted_scaler.transform(all_data_variable_array))\n",
    "    \n",
    "    # at this moment, the individual time series is ready to be window-rolled to produce\n",
    "    # sub-series/examples to serialize\n",
    "    \n",
    "    # BSCTRFM inference process is not direct, but iterative, therefoer\n",
    "    # no TFRecord SLDB is required for test dataset,\n",
    "    \n",
    "    # persist only the time series corresponding to the inference interval as test dataset\n",
    "    test_time_series = data_df[sldb_columns][no_lectures_seen_data - (m + t) + 1:]\n",
    "    \n",
    "    # path to persist the time series dataframe corresponding to test dataset\n",
    "    path = '{}/test/{}.pkl'.format(sldb_dir, customer_id)\n",
    "    \n",
    "    test_time_series.to_pickle(path)\n",
    "    print('Test dataset persisted as a time series pickle for {}'.format(customer_id))\n",
    "    \n",
    "    \n",
    "    # get an iterable with all the possible sub-series for training examples\n",
    "    for starting_point in np.arange(train_interval_end - (m + t) + 1):\n",
    "\n",
    "        sub_series_df = data_df[sldb_columns][starting_point:starting_point + (m + t)]\n",
    "\n",
    "        encoder_input_df = sub_series_df[encoder_input_columns][:m]\n",
    "        decoder_input_df = sub_series_df[decoder_input_columns][m-1:m-1+t]\n",
    "        target_df = sub_series_df[target_columns][m:m+t]\n",
    "        id_df = sub_series_df[id_columns][:1]\n",
    "\n",
    "        encoder_input_list = encoder_input_df.reset_index(drop=True).to_numpy().flatten().tolist()\n",
    "        decoder_input_list = decoder_input_df.reset_index(drop=True).to_numpy().flatten().tolist()\n",
    "        target_list = target_df.reset_index(drop=True).to_numpy().flatten().tolist()\n",
    "        id_list = id_df.reset_index(drop=True).to_numpy().flatten().tolist()\n",
    "\n",
    "        examples['train'].append(\n",
    "            {\n",
    "                'encoder_input': encoder_input_list,\n",
    "                'decoder_input': decoder_input_list,\n",
    "                'target': target_list,\n",
    "                'id': id_list,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    print('{} processed. The number of examples in {} dataset is {}'.\\\n",
    "          format(customer_id, 'train', len(examples['train'])))\n",
    "\n",
    "\n",
    "    # ToDo: remove evaluation step from Cloud TPU training and use all seen data for training stage\n",
    "    build_eval_set = True\n",
    "\n",
    "    if build_eval_set:\n",
    "\n",
    "        # get an iterable with all the possible sub-series for evaluation examples\n",
    "        for starting_point in np.arange(train_interval_end, no_lectures_seen_data - (m + t) + 1):\n",
    "\n",
    "            sub_series_df = data_df[sldb_columns][starting_point:starting_point + (m + t)]\n",
    "\n",
    "            encoder_input_df = sub_series_df[encoder_input_columns][:m]\n",
    "            decoder_input_df = sub_series_df[decoder_input_columns][m-1:m-1+t]\n",
    "            target_df = sub_series_df[target_columns][m:m+t]\n",
    "            id_df = sub_series_df[id_columns][:1]\n",
    "\n",
    "            encoder_input_list = encoder_input_df.reset_index(drop=True).to_numpy().flatten().tolist()\n",
    "            decoder_input_list = decoder_input_df.reset_index(drop=True).to_numpy().flatten().tolist()\n",
    "            target_list = target_df.reset_index(drop=True).to_numpy().flatten().tolist()\n",
    "            id_list = id_df.reset_index(drop=True).to_numpy().flatten().tolist()\n",
    "\n",
    "            examples['eval'].append(\n",
    "                {\n",
    "                    'encoder_input': encoder_input_list,\n",
    "                    'decoder_input': decoder_input_list,\n",
    "                    'target': target_list,\n",
    "                    'id': id_list,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        print('{} processed. The number of examples in {} dataset is {}'.\\\n",
    "              format(customer_id, 'eval', len(examples['eval'])))\n",
    "\n",
    "\n",
    "    # DO NOT PRODUCE A TEST DATASET FOR SLDB, AS INFERENCE PROCESS IS NOT DIRECT\n",
    "    # (IT IS ITERATIVE OVER UNSEEN DATA TIME SERIES)\n",
    "\n",
    "    # on each customer dataset, adjust the number of examples to the number of training cores\n",
    "    for stage in ['train', 'eval']:\n",
    "        # how many examples/rows must be removed from examples[stage] to comply with the number of cores\n",
    "        examples_to_remove = len(examples[stage])%num_cores\n",
    "\n",
    "        # remove the last 'examples_to_remove' examples from the dataset\n",
    "        for _ in np.arange(examples_to_remove):\n",
    "            examples[stage].pop(-1)\n",
    "\n",
    "        print('For {} cores in Cloud TPU, the number of {} examples for {} was adjusted to {}'.\\\n",
    "             format(num_cores, stage, customer_id, len(examples[stage])))\n",
    "\n",
    "\n",
    "    # serialize the rows in examples['train'] and, if present, examples['eval']\n",
    "    # to avoid excesive memory consumption\n",
    "\n",
    "    # write a TFRecord file for each consumer_id/stage\n",
    "    for stage in ['train', 'eval']:\n",
    "        # N_ROWS = sldb['stats'][stage]['n_rows']\n",
    "        N_ROWS = len(examples[stage])\n",
    "        filename = '{}/{}/{}.tfrecord'.format(sldb_dir, stage, customer_id)\n",
    "\n",
    "        with tf.io.TFRecordWriter(filename) as writer:\n",
    "            for row in np.arange(N_ROWS):\n",
    "\n",
    "                example = tf.train.Example(\n",
    "                    # features within the example\n",
    "                    features=tf.train.Features(\n",
    "                        # individual feature definition\n",
    "                        feature={'encoder_input':\n",
    "                                 _float_feature_from_list_of_values(\n",
    "                                     examples[stage][row]['encoder_input']),\n",
    "                                 'decoder_input':\n",
    "                                 _float_feature_from_list_of_values(\n",
    "                                     examples[stage][row]['decoder_input']),\n",
    "                                 'target':\n",
    "                                 _float_feature_from_list_of_values(\n",
    "                                     examples[stage][row]['target']),\n",
    "                                 'id':\n",
    "                                 _float_feature_from_list_of_values(\n",
    "                                     examples[stage][row]['id'])\n",
    "                                 }\n",
    "                    )\n",
    "                )\n",
    "                serialized_example = example.SerializeToString()\n",
    "                writer.write(serialized_example)\n",
    "\n",
    "            # report TFRecord file as completed\n",
    "            print('Persisted {} TFRecord file for {}'.format(stage, customer_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand the sldb dictionary with final statistics\n",
    "sldb['stats'] = {\n",
    "    'train': {\n",
    "        'n_rows': 54032,\n",
    "    },\n",
    "    'eval': {\n",
    "        'n_rows': 2728\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ts': 'LD2011-2014_SEPARATED_MT_320-MT_330',\n",
       " 'embedding': {'hourly': 168},\n",
       " 'tau': {'hourly': 1},\n",
       " 'no_targets': 168,\n",
       " 'BSCTRFM': 1,\n",
       " 'preprocessed': 1,\n",
       " 'stats': {'train': {'n_rows': 54032}, 'eval': {'n_rows': 2728}}}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sldb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_filename = '{}/sldb.json'.format(sldb_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_filename, 'w') as filename:\n",
    "    json.dump(sldb, filename, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
