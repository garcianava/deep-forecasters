{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# follow TensorFlow demo for time series windowing\n",
    "# https://www.tensorflow.org/guide/data#time_series_windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is an example provided by Google on how to use TensorFlow functionality\n",
    "# to build a supervised-learning database (time series windowing)\n",
    "# initially, this functionality will not be used for DPLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original time series is just a range from 0 to 99999\n",
    "source = tf.data.Dataset.range(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch the dataset with 7 elements\n",
    "batches = source.batch(7, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iteration over datasets is only valid in eager execution\n",
    "# replace the following cycle with a TensorFlow iterator\n",
    "\n",
    "# for batch in batches.take(5):\n",
    "#   print(batch.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-901cafa2e0b8>:2: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n"
     ]
    }
   ],
   "source": [
    "# an iterator on a dataset with only 5 rows of batches dataset\n",
    "iterator = batches.take(5).make_one_shot_iterator()\n",
    "next_element = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6]\n",
      "[ 7  8  9 10 11 12 13]\n",
      "[14 15 16 17 18 19 20]\n",
      "[21 22 23 24 25 26 27]\n",
      "[28 29 30 31 32 33 34]\n"
     ]
    }
   ],
   "source": [
    "# evaluate tensors in the temporary dataset to print them\n",
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        while True:\n",
    "            row = sess.run(next_element)\n",
    "            print(row)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now use slicing and a map transformation to get also the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_and_label(batch):\n",
    "    '''\n",
    "    feature: lectures in SLDB rows, from the first one to one before the last\n",
    "    target: lectures in SLDB rows, from the second one to the last one\n",
    "    '''\n",
    "    return batch[:-1], batch[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = batches.map(get_features_and_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = test.take(5).make_one_shot_iterator()\n",
    "next_element = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4, 5]), array([1, 2, 3, 4, 5, 6]))\n",
      "(array([ 7,  8,  9, 10, 11, 12]), array([ 8,  9, 10, 11, 12, 13]))\n",
      "(array([14, 15, 16, 17, 18, 19]), array([15, 16, 17, 18, 19, 20]))\n",
      "(array([21, 22, 23, 24, 25, 26]), array([22, 23, 24, 25, 26, 27]))\n",
      "(array([28, 29, 30, 31, 32, 33]), array([29, 30, 31, 32, 33, 34]))\n"
     ]
    }
   ],
   "source": [
    "# evaluate tensors in the temporary dataset to print them\n",
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        while True:\n",
    "            row = sess.run(next_element)\n",
    "            print(row)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now use tf.Dataset.windows for finer control of time series windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding dimension\n",
    "window_size = 10\n",
    "# offset value between rows of the SLDB\n",
    "shift = 3\n",
    "windows = source.window(window_size, shift=shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_to_batch(sub):\n",
    "    return sub.batch(window_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_windows = windows.flat_map(sub_to_batch).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = some_windows.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[ 3  4  5  6  7  8  9 10 11 12]\n",
      "[ 6  7  8  9 10 11 12 13 14 15]\n",
      "[ 9 10 11 12 13 14 15 16 17 18]\n",
      "[12 13 14 15 16 17 18 19 20 21]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        while True:\n",
    "            row = sess.run(next_element)\n",
    "            print(row)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the make windows dataset from TensorFlow demo\n",
    "\n",
    "def make_window_dataset(ds, window_size=5, shift=1, stride=1):\n",
    "    '''\n",
    "    ds: time series dataset\n",
    "    window_size: the embedding dimension\n",
    "    shift: offset value between rows\n",
    "    stride: time lag or tau\n",
    "    '''\n",
    "    windows = ds.window(window_size, shift=shift, stride=stride)\n",
    "    \n",
    "    def sub_to_batch(sub):\n",
    "        return sub.batch(window_size, drop_remainder=True)\n",
    "\n",
    "    windows = windows.flat_map(sub_to_batch)\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the function\n",
    "demo_dataset = make_window_dataset(source, window_size=10, shift = 5, stride=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  3  6  9 12 15 18 21 24 27]\n",
      "[ 5  8 11 14 17 20 23 26 29 32]\n",
      "[10 13 16 19 22 25 28 31 34 37]\n",
      "[15 18 21 24 27 30 33 36 39 42]\n",
      "[20 23 26 29 32 35 38 41 44 47]\n"
     ]
    }
   ],
   "source": [
    "iterator = demo_dataset.take(5).make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        while True:\n",
    "            row = sess.run(next_element)\n",
    "            print(row)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a more convenient example with shift=1, to use all available data\n",
    "one_window_dataset = make_window_dataset(source, window_size=10, shift = 1, stride=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  3  6  9 12 15 18 21 24 27]\n",
      "[ 1  4  7 10 13 16 19 22 25 28]\n",
      "[ 2  5  8 11 14 17 20 23 26 29]\n",
      "[ 3  6  9 12 15 18 21 24 27 30]\n",
      "[ 4  7 10 13 16 19 22 25 28 31]\n"
     ]
    }
   ],
   "source": [
    "iterator = one_window_dataset.take(5).make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        while True:\n",
    "            row = sess.run(next_element)\n",
    "            print(row)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_at_last_element(batch):\n",
    "  # shift features and labels one step relative to each other.\n",
    "  return batch[:-1], batch[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_at_nth_backwards_element(batch, n):\n",
    "    # split dataset in features and labels at n-th element\n",
    "    return batch[:-n], batch[-n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dataset = one_window_dataset.map(lambda row: split_at_nth_backwards_element(row, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 0,  3,  6,  9, 12, 15, 18, 21]), array([24, 27]))\n",
      "(array([ 1,  4,  7, 10, 13, 16, 19, 22]), array([25, 28]))\n",
      "(array([ 2,  5,  8, 11, 14, 17, 20, 23]), array([26, 29]))\n",
      "(array([ 3,  6,  9, 12, 15, 18, 21, 24]), array([27, 30]))\n",
      "(array([ 4,  7, 10, 13, 16, 19, 22, 25]), array([28, 31]))\n"
     ]
    }
   ],
   "source": [
    "iterator = split_dataset.take(5).make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        while True:\n",
    "            row = sess.run(next_element)\n",
    "            print(row)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, a function that includes the complete functionality\n",
    "# use variable names consistent within the research team\n",
    "# m: embedding dimension\n",
    "# tau: time lag\n",
    "# shift: shift value from one sample to the next one\n",
    "# n_targets: (how many steps to predict at once?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_supervised_learning_database(batch, m, tau, shift=1, n_targets=1):\n",
    "    \n",
    "    def make_window_dataset(batch, window_size, shift, stride):\n",
    "        windows = batch.window(window_size, shift=shift, stride=stride)\n",
    "\n",
    "        # tf.data.Dataset.window returns a Dataset of Datasets, must be flat_mapped\n",
    "        # use the function provided by TensorFlow developers\n",
    "        def sub_to_batch(sub):\n",
    "            return sub.batch(window_size, drop_remainder=True)\n",
    "\n",
    "        windows = windows.flat_map(sub_to_batch)\n",
    "        return windows\n",
    "    \n",
    "    windows = make_window_dataset(batch=batch, window_size=m+n_targets, shift=shift, stride=tau)\n",
    "\n",
    "    def split_at_nth_backwards_element(batch, n):\n",
    "        # split dataset in features and labels at n-th element\n",
    "        return batch[:-n], batch[-n:]\n",
    "        \n",
    "    features_and_labels = windows.map(lambda row: split_at_nth_backwards_element(row, n_targets))\n",
    "        \n",
    "    return features_and_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo SLDB: feature vector with 8 consecutive lectures that targets 3 steps ahead\n",
    "features_and_labels = make_supervised_learning_database(source, m=8, tau=1, shift=1, n_targets=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([ 8,  9, 10]))\n",
      "(array([1, 2, 3, 4, 5, 6, 7, 8]), array([ 9, 10, 11]))\n",
      "(array([2, 3, 4, 5, 6, 7, 8, 9]), array([10, 11, 12]))\n",
      "(array([ 3,  4,  5,  6,  7,  8,  9, 10]), array([11, 12, 13]))\n",
      "(array([ 4,  5,  6,  7,  8,  9, 10, 11]), array([12, 13, 14]))\n",
      "(array([ 5,  6,  7,  8,  9, 10, 11, 12]), array([13, 14, 15]))\n",
      "(array([ 6,  7,  8,  9, 10, 11, 12, 13]), array([14, 15, 16]))\n",
      "(array([ 7,  8,  9, 10, 11, 12, 13, 14]), array([15, 16, 17]))\n",
      "(array([ 8,  9, 10, 11, 12, 13, 14, 15]), array([16, 17, 18]))\n",
      "(array([ 9, 10, 11, 12, 13, 14, 15, 16]), array([17, 18, 19]))\n",
      "(array([10, 11, 12, 13, 14, 15, 16, 17]), array([18, 19, 20]))\n",
      "(array([11, 12, 13, 14, 15, 16, 17, 18]), array([19, 20, 21]))\n",
      "(array([12, 13, 14, 15, 16, 17, 18, 19]), array([20, 21, 22]))\n",
      "(array([13, 14, 15, 16, 17, 18, 19, 20]), array([21, 22, 23]))\n",
      "(array([14, 15, 16, 17, 18, 19, 20, 21]), array([22, 23, 24]))\n",
      "(array([15, 16, 17, 18, 19, 20, 21, 22]), array([23, 24, 25]))\n",
      "(array([16, 17, 18, 19, 20, 21, 22, 23]), array([24, 25, 26]))\n",
      "(array([17, 18, 19, 20, 21, 22, 23, 24]), array([25, 26, 27]))\n",
      "(array([18, 19, 20, 21, 22, 23, 24, 25]), array([26, 27, 28]))\n",
      "(array([19, 20, 21, 22, 23, 24, 25, 26]), array([27, 28, 29]))\n",
      "(array([20, 21, 22, 23, 24, 25, 26, 27]), array([28, 29, 30]))\n",
      "(array([21, 22, 23, 24, 25, 26, 27, 28]), array([29, 30, 31]))\n",
      "(array([22, 23, 24, 25, 26, 27, 28, 29]), array([30, 31, 32]))\n",
      "(array([23, 24, 25, 26, 27, 28, 29, 30]), array([31, 32, 33]))\n",
      "(array([24, 25, 26, 27, 28, 29, 30, 31]), array([32, 33, 34]))\n"
     ]
    }
   ],
   "source": [
    "iterator = features_and_labels.take(25).make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        while True:\n",
    "            row = sess.run(next_element)\n",
    "            print(row)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
