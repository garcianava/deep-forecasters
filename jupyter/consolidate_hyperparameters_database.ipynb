{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_id -- can be obtained from the directory name\n",
    "\n",
    "# executions -- can be calculated from the global predictions dataframe\n",
    "\n",
    "# embedding dimensions\n",
    "# hourly structure\n",
    "# daily structure\n",
    "# weekly structure\n",
    "# use_timestamps\n",
    "# dense structure\n",
    "# train_batch_size\n",
    "# train_steps\n",
    "# base_learning_rate\n",
    "# learning rate schedule weights --> update this parameter and make it absl-flag'able'\n",
    "# learning rate schedule steps --> update this parameter and make it absl-flag'able'\n",
    "# iterations_per_loop\n",
    "# precision\n",
    "\n",
    "# wall_time -- this is not a parameter but a result per trained model execution, it must be persisted in stats/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# a list to traverse all subdirectories in stats/\n",
    "stats_folders = os.listdir(path='/home/developer/gcp/cbidmltsf/stats')\n",
    "stats_folders.sort()\n",
    "len(stats_folders)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# copy sldb, architecture, and training parameters\n",
    "# from first model _00, to a single folder per experiment, in parameters/\n",
    "for stat_folder in stats_folders:\n",
    "    root_folder = stat_folder[:-3]\n",
    "    if saved_root_folder != root_folder:\n",
    "        # execute the batch script from stats/ to copy json files to parameters/\n",
    "        print('mkdir ../parameters/{}'.format(root_folder))\n",
    "        print('cp {}/sldb_parameters.json ../parameters/{}/'.format(stat_folder, root_folder))\n",
    "        print('cp {}/architecture_parameters.json ../parameters/{}/'.format(stat_folder, root_folder))\n",
    "        print('cp {}/training_parameters.json ../parameters/{}/'.format(stat_folder, root_folder))\n",
    "        print('')\n",
    "        saved_root_folder = root_folder"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# copy prediction results for each trained model\n",
    "# from a specific folder to a labeled json file\n",
    "# to avoid multiple, not needed folders \n",
    "# from first model _00, to a single folder per experiment, in parameters/\n",
    "for stat_folder in stats_folders:\n",
    "    # execute the batch script from stats/ to build all predictions json files in stats/\n",
    "    print('cp {}/prediction_results_on_test_tfrecord.json predictions/{}_on_test_tfrecord.json'.format(stat_folder, stat_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list to traverse all subdirectories in parameters/\n",
    "parameters_folders = os.listdir(path='/home/developer/gcp/cbidmltsf/parameters')\n",
    "parameters_folders.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parameters_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update learning rate schedule components: steps and weights\n",
    "# automatically for TPU_10 to TPU_52, manually for the rest...\n",
    "for parameters_folder in parameters_folders:\n",
    "\n",
    "    path = '/home/developer/gcp/cbidmltsf/parameters/{}/training_parameters.json'.format(parameters_folder)\n",
    "    with open(path, 'r') as json_file:\n",
    "        training_parameters = json.load(json_file)\n",
    "        # update dictionary value\n",
    "        training_parameters['lrs_steps'] = None\n",
    "        training_parameters['lrs_weights'] = None\n",
    "\n",
    "    # now update the json file\n",
    "    with open(path, 'w') as json_file:\n",
    "        json.dump(training_parameters, json_file, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DMSLSTM_TPU_10 [16, 8, 4] [64, 64, 64, 64] [32, 32] [32] True [64, 32, 16, 8] 32 16000 0.04 None None float32\n",
      "DMSLSTM_TPU_11 [8, 4, 4] [64, 64, 64, 64] [32, 32] [32] True [64, 32, 16, 8] 32 16000 0.04 None None float32\n",
      "DMSLSTM_TPU_13 [8, 4, 4] [64, 64, 64, 64] [32, 32] [32] True [64, 32, 16, 8] 32 16000 0.064 None None float32\n",
      "DMSLSTM_TPU_14 [8, 8, 4] [64, 64, 64, 64] [64, 64] [32] True [64, 32, 16, 8] 32 16000 0.064 None None float32\n",
      "DMSLSTM_TPU_15 [8, 8, 4] [64, 64, 64, 64] [64, 64] [32] False [64, 32, 16, 8] 32 16000 0.064 None None float32\n"
     ]
    }
   ],
   "source": [
    "# load relevant parameter values for model comparison\n",
    "for parameters_folder in parameters_folders[:5]:\n",
    "\n",
    "    path = '/home/developer/gcp/cbidmltsf/parameters/{}/sldb_parameters.json'.format(parameters_folder)\n",
    "    with open(path, 'r') as json_file:\n",
    "        sldb_parameters = json.load(json_file)\n",
    "\n",
    "    path = '/home/developer/gcp/cbidmltsf/parameters/{}/architecture_parameters.json'.format(parameters_folder)\n",
    "    with open(path, 'r') as json_file:\n",
    "        architecture_parameters = json.load(json_file)\n",
    "\n",
    "    path = '/home/developer/gcp/cbidmltsf/parameters/{}/training_parameters.json'.format(parameters_folder)\n",
    "    with open(path, 'r') as json_file:\n",
    "        training_parameters = json.load(json_file)\n",
    "        \n",
    "    model_id = parameters_folder\n",
    "        \n",
    "    m = [sldb_parameters['embedding']['hourly'],\n",
    "         sldb_parameters['embedding']['daily'],\n",
    "         sldb_parameters['embedding']['weekly'],\n",
    "        ]\n",
    "    \n",
    "    hourly = architecture_parameters['hourly']['structure']\n",
    "    daily = architecture_parameters['daily']['structure']\n",
    "    weekly = architecture_parameters['weekly']['structure']\n",
    "    use_timestamps = architecture_parameters['use_timestamps']\n",
    "    dense = architecture_parameters['dense']['structure']\n",
    "    \n",
    "    train_batch_size = training_parameters['train_batch_size']\n",
    "    train_steps = training_parameters['train_steps']\n",
    "    base_learning_rate = training_parameters['base_learning_rate']\n",
    "    lrs_steps = training_parameters['lrs_steps']\n",
    "    lrs_weights = training_parameters['lrs_weights']\n",
    "    precision = training_parameters['precision']\n",
    "    \n",
    "    print(parameters_folder,\n",
    "          m,\n",
    "          hourly, daily, weekly, use_timestamps, dense,\n",
    "          train_batch_size, train_steps, base_learning_rate, lrs_steps, lrs_weights, precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DMSLSTM_TPU_10']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_folders[:1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
