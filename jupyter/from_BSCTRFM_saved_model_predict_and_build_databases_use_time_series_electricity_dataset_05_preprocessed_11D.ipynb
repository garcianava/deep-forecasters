{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive inference (multi-step) for BSCTRFM models\n",
    "\n",
    "### use time series instead of SLDB arrays for easier and more efficient timestamp management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# uncomment the following line for compatibility with TensorFlow 1.15 (on GCP)\n",
    "# import tensorflow.compat.v1 as tf\n",
    "# uncomment the following line for TensorFlow 2.X (local execution)\n",
    "import tensorflow as tf\n",
    "\n",
    "# forecast model was saved in TensorFlow 1.15\n",
    "# but, in order to make predictions locally, has to be loaded with TensorFlow 2\n",
    "from tensorflow.saved_model import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# symmetric mean absolute percentage error\n",
    "def symmetric_mean_absolute_percentage_error(targets, predictions):\n",
    "    '''\n",
    "    predictions: a list with the predicted values\n",
    "    targets: a list with the actual values\n",
    "    '''\n",
    "    import numpy as np\n",
    "    # lists to NumPy arrays\n",
    "    targets, predictions = np.array(targets), np.array(predictions)\n",
    "    # verify predictions and targets have the same shape\n",
    "    if predictions.shape == targets.shape:\n",
    "            return(np.sum(2*np.abs(predictions - targets) /\n",
    "                          (np.abs(targets) + np.abs(predictions)))/predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to encode float values for serialized examples\n",
    "def _float_feature_from_list_of_values(list_of_values):\n",
    "    \"\"\"Returns a float_list from a list of floats / doubles.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=list_of_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts a set of tensors to a feature dict to a serialized example to pass it\n",
    "# to the prediction function of the saved model \n",
    "def input_tensors_to_serialized_example(encoder_input_float_tensor,\n",
    "                                        decoder_input_float_tensor,\n",
    "                                        id_float_tensor):\n",
    "    # first, pass the float tensors to NumPy array, then flatten them\n",
    "    encoder_input_flat_array = encoder_input_float_tensor.numpy().flatten()\n",
    "    decoder_input_flat_array = decoder_input_float_tensor.numpy().flatten()\n",
    "    id_flat_array = id_float_tensor.numpy().flatten()\n",
    "    \n",
    "    # second, build the protobuffer example\n",
    "    example = tf.train.Example(\n",
    "        # features within the example\n",
    "        features=tf.train.Features(\n",
    "            # feature definition\n",
    "            feature={\n",
    "                'encoder_input': _float_feature_from_list_of_values(encoder_input_flat_array),\n",
    "                'decoder_input': _float_feature_from_list_of_values(decoder_input_flat_array),\n",
    "                'id': _float_feature_from_list_of_values(id_flat_array)\n",
    "            }\n",
    "        )\n",
    "    )    \n",
    "    # third, serialize the example dictionary to a string\n",
    "    serialized_example = example.SerializeToString()\n",
    "    # fourth, wrap the serialized example as a NumPy-string array\n",
    "    numpy_example = np.array(serialized_example, dtype='S')\n",
    "    # fifth, wrap the NumPy-string array as a string tensor\n",
    "    serialized_example = tf.convert_to_tensor(numpy_example)\n",
    "\n",
    "    return serialized_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = '/home/developer/gcp/cbidmltsf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# during batch prediction, the model identifier is obtained via Abseil Flags\n",
    "# remember this notebook is based on local execution,\n",
    "# therefore model directory must be downloaded from GS before running the notebook\n",
    "model_id = 'BSCTRFM_TPU_021'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# during batch prediction, the execution identifier is obtained via Abseil Flags\n",
    "execution = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# during batch prediction, the SLDB identifier is obtained via Abseil Flags\n",
    "# THE SLDB FOR INFERENCE MUST BE THE SAME USED FOR TRAINING! (THE ONE SETUP IN THE CONFIGURATION FILE)\n",
    "sldb_id = 'LD2011-2014_SEPARATED_MT_320-MT_330_BSCTRFM_168_168_07DB_MMX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# during batch prediction, the dataset name is obtained via Abseil Flags\n",
    "dataset = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a forecast window to guide the iterative prediction process\n",
    "# start with a hourly, day-ahead process\n",
    "forecast_window = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD AN INFERENCE IDENTIFIER, BECAUSE FOR TRANSFORMER-BASED MODELS, DIFFERENT INFERENCES\n",
    "# CAN BE PRODUCED FROM A SINGLE SAVED MODEL (USUALLY TO PRODUCE DIFFERENT FORECAST WINDOWS)\n",
    "# during batch prediction, the inference identifier should be obtained via Abseil Flags\n",
    "inference = '{:03d}'.format(forecast_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a path to the SLDB json file\n",
    "data_dir = '{}/{}/{}'.format(PROJECT_ROOT, 'sldbs', sldb_id)\n",
    "\n",
    "# then get the ts_identifier from the json file in the sldb directory\n",
    "sldb_json_file = '{}/sldb.json'.format(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the json file\n",
    "with open(sldb_json_file, 'r') as inputfile:\n",
    "    sldb_dict = json.load(inputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LD2011-2014_SEPARATED_MT_320-MT_330'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and get the time series identifier\n",
    "ts_identifier = sldb_dict['ts']\n",
    "ts_identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the SLDB parameters for the forecasting model\n",
    "config_json_file = '{}/{}/{}.json'.format(PROJECT_ROOT,\n",
    "                                          'parameters',\n",
    "                                          model_id)\n",
    "\n",
    "# recover the sldb dictionary from the json file in parameters/\n",
    "with open(config_json_file, 'r') as inputfile:\n",
    "    configuration = json.load(inputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = sldb_dict['embedding']['hourly']\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = sldb_dict['no_targets']\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('BSCTRFM_TPU_021', 0, 'test', '024')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify the values of the variables for batch inference\n",
    "model_id, execution, dataset, inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a list of saved models, given the parameters in the previous cell\n",
    "saved_models = os.listdir('{}/models/{}_{:02d}/export/exporter'.format(PROJECT_ROOT, model_id, execution))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1633995397', '1633995589', '1633995770', '1633995965', '1633996143']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_models.sort()\n",
    "saved_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_columns = [\n",
    "    'kw_scaled',\n",
    "    'sin_hours_from_start',\n",
    "    'cos_hours_from_start',\n",
    "    'sin_hour_day',\n",
    "    'cos_hour_day',\n",
    "    'sin_day_week',\n",
    "    'cos_day_week',\n",
    "    # 'sin_day_month',\n",
    "    # 'cos_day_month',\n",
    "    # 'sin_day_year',\n",
    "    # 'cos_day_year'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input_columns = encoder_input_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_columns = ['token_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get the time series for the test dataset (unseen data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/developer/gcp/cbidmltsf/sldbs/LD2011-2014_SEPARATED_MT_320-MT_330_BSCTRFM_168_168_07DB_MMX/test'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the time series directory\n",
    "time_series_folder = '{}/test'.format(data_dir)\n",
    "time_series_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MT_320.pkl',\n",
       " 'MT_321.pkl',\n",
       " 'MT_322.pkl',\n",
       " 'MT_323.pkl',\n",
       " 'MT_324.pkl',\n",
       " 'MT_325.pkl',\n",
       " 'MT_326.pkl',\n",
       " 'MT_327.pkl',\n",
       " 'MT_328.pkl',\n",
       " 'MT_329.pkl',\n",
       " 'MT_330.pkl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series_list = os.listdir(time_series_folder)\n",
    "time_series_list.sort()\n",
    "time_series_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a dictionary to remain the code consistent with the SLDB building process\n",
    "# most of the times, only ts['test'] will be used for inference\n",
    "# however, ts['eval'] might also be used, as it have not really been seen by training process\n",
    "# (no tranining modification resulted from evaluation stage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rename the time series dictionary to ts_test, use the customer_id as key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_test = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dictionary to store predictions detail dataframe per customer id\n",
    "predictions_detail = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## skip the following code to avoid inference process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set customer_id, load time series and scaler on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded test time series for MT_320, which spans from 2014-08-18 01:00:00 to 2014-09-07 23:00:00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995397\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995397_MT_320_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995589\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995589_MT_320_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995770\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995770_MT_320_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995965\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995965_MT_320_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633996143\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633996143_MT_320_024_00\n",
      "Loaded test time series for MT_321, which spans from 2014-08-18 01:00:00 to 2014-09-07 23:00:00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995397\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995397_MT_321_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995589\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995589_MT_321_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995770\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995770_MT_321_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995965\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995965_MT_321_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633996143\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633996143_MT_321_024_00\n",
      "Loaded test time series for MT_322, which spans from 2014-08-18 01:00:00 to 2014-09-07 23:00:00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995397\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995397_MT_322_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995589\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995589_MT_322_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995770\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995770_MT_322_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995965\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995965_MT_322_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633996143\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633996143_MT_322_024_00\n",
      "Loaded test time series for MT_323, which spans from 2014-08-18 01:00:00 to 2014-09-07 23:00:00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995397\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995397_MT_323_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995589\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995589_MT_323_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995770\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995770_MT_323_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995965\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995965_MT_323_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633996143\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633996143_MT_323_024_00\n",
      "Loaded test time series for MT_324, which spans from 2014-08-18 01:00:00 to 2014-09-07 23:00:00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995397\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995397_MT_324_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995589\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995589_MT_324_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995770\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995770_MT_324_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995965\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995965_MT_324_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633996143\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633996143_MT_324_024_00\n",
      "Loaded test time series for MT_325, which spans from 2014-08-18 01:00:00 to 2014-09-07 23:00:00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995397\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995397_MT_325_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995589\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995589_MT_325_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995770\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995770_MT_325_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995965\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995965_MT_325_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633996143\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633996143_MT_325_024_00\n",
      "Loaded test time series for MT_326, which spans from 2014-08-18 01:00:00 to 2014-09-07 23:00:00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995397\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995397_MT_326_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995589\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995589_MT_326_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995770\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995770_MT_326_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995965\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995965_MT_326_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633996143\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633996143_MT_326_024_00\n",
      "Loaded test time series for MT_327, which spans from 2014-08-18 01:00:00 to 2014-09-07 23:00:00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995397\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995397_MT_327_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995589\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995589_MT_327_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995770\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995770_MT_327_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995965\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995965_MT_327_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633996143\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633996143_MT_327_024_00\n",
      "Loaded test time series for MT_328, which spans from 2014-08-18 01:00:00 to 2014-09-07 23:00:00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995397_MT_328_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995589\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995589_MT_328_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995770\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995770_MT_328_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995965\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995965_MT_328_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633996143\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633996143_MT_328_024_00\n",
      "Loaded test time series for MT_329, which spans from 2014-08-18 01:00:00 to 2014-09-07 23:00:00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995397\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995397_MT_329_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995589\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995589_MT_329_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995770\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995770_MT_329_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995965\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995965_MT_329_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633996143\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633996143_MT_329_024_00\n",
      "Loaded test time series for MT_330, which spans from 2014-08-18 01:00:00 to 2014-09-07 23:00:00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995397\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995397_MT_330_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995589\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995589_MT_330_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995770\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995770_MT_330_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633995965\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633995965_MT_330_024_00\n",
      "Exported model path is /home/developer/gcp/cbidmltsf/models/BSCTRFM_TPU_021_00/export/exporter/1633996143\n",
      "Persisted predictions detail of BSCTRFM_TPU_021_00_1633996143_MT_330_024_00\n"
     ]
    }
   ],
   "source": [
    "# a second inference identifier to run more than one inference\n",
    "# on the same combination model_id, execution, inference;\n",
    "# to produce different inference processes because predict_fn is stochastic\n",
    "event = 0\n",
    "\n",
    "for customer_id in ['MT_320', 'MT_321', 'MT_322', 'MT_323', 'MT_324', 'MT_325',\n",
    "                    'MT_326', 'MT_327', 'MT_328', 'MT_329', 'MT_330']:\n",
    "    \n",
    "    # read the time series for the current customer\n",
    "    ts_test[customer_id] = pd.read_pickle('{}/test/{}.pkl'.format(data_dir, customer_id))\n",
    "\n",
    "    # for consistency, rename the column 'date' as 'timestamp'\n",
    "    ts_test[customer_id] = ts_test[customer_id].rename(columns={\"date\": \"timestamp\"})\n",
    "    # set the column 'timestamp' as index\n",
    "    ts_test[customer_id] = ts_test[customer_id].set_index('timestamp')\n",
    "\n",
    "    # report start and end timestamp for the loaded time series\n",
    "    print('Loaded test time series for {}, which spans from {} to {}'.\\\n",
    "         format(customer_id,\n",
    "                str(ts_test[customer_id].index[:1][0]),\n",
    "                str(ts_test[customer_id].index[-1:][0])))\n",
    "\n",
    "    scaler_type = 'min_max'\n",
    "    \n",
    "    if scaler_type == 'min_max':\n",
    "        # build a path to the scaler of the time series\n",
    "        scaler_path = '{}/scalers/min_max_{}.save'.format(data_dir, customer_id)\n",
    "        # and load it\n",
    "        scaler = joblib.load(scaler_path)\n",
    "\n",
    "\n",
    "    '''\n",
    "    if scaler_type == 'standard':\n",
    "        # build a path to the scaler of the time series\n",
    "        scaler_path = '{}/scalers/standard_{}.save'.format(data_dir, customer_id)\n",
    "        # and load it\n",
    "        scaler = joblib.load(scaler_path)\n",
    "    '''    \n",
    "        \n",
    "        \n",
    "    # pass the saved model identifier (it determines the number of training epochs)\n",
    "    # and avoid using the latest saved model by default\n",
    "    for saved_model_id in saved_models:\n",
    "\n",
    "        # a columns list for the predictions dataframe\n",
    "        pred_df_columns = ['model_id',\n",
    "                           'execution',\n",
    "                           'dataset',\n",
    "                           'inference',\n",
    "                           'customer_id',\n",
    "                           'string_timestamps',\n",
    "                           'predictions',\n",
    "                           'targets']\n",
    "\n",
    "        # build the predictions dataframe as a key-value pair of the dictionary\n",
    "        predictions_detail[customer_id] = pd.DataFrame(columns=pred_df_columns)\n",
    "\n",
    "        # use model identifier and execution number to build the model directory string\n",
    "        model_dir = '{}_{:02d}'.format(model_id, execution)\n",
    "\n",
    "        # get the path to the saved model main directory\n",
    "        saved_model_path = '{}/{}/{}/export/exporter'.format(PROJECT_ROOT,\n",
    "                                                             'models',\n",
    "                                                             model_dir)\n",
    "\n",
    "        # get all the files in the saved model path, to find the most recent one\n",
    "        # all_files = os.listdir(saved_model_path)\n",
    "        # get the path to the most recent saved model\n",
    "        # latest_saved_model_id = sorted(all_files)[-1]\n",
    "\n",
    "        # build the full path for the latest saved model dir\n",
    "        export_dir = '{}/{}'.format(saved_model_path, saved_model_id)\n",
    "        print ('Exported model path is {}'.format(export_dir))\n",
    "\n",
    "        # load the saved model and the prediction function\n",
    "        imported = load(export_dir=export_dir, tags='serve')\n",
    "        predict_fn = imported.signatures[\"serving_default\"]\n",
    "\n",
    "        # iterate on a set of valid rows of the test dataset\n",
    "        starting_point = 0 # based on the inference dataset\n",
    "        span = 1 + 6*24 # number of days in the test dataset, expressed in hours\n",
    "        dataset_row_indexes_list = starting_point + np.arange(span)\n",
    "\n",
    "        for start_index in dataset_row_indexes_list:\n",
    "\n",
    "            # define first prediction interval with start- and end-index\n",
    "            # given the interval time_series[start_index:end_index]\n",
    "            # the conditioning range is the union of the encoder-input and the decoder-input\n",
    "            # and the prediction range is only the last lecture in the interval,\n",
    "            # by means of a recursive inference process\n",
    "            # on each step the last prediction is added to the decoder input\n",
    "            # and the prediction range grows one step into the future\n",
    "\n",
    "            # get the end-index of this recursive inference interval\n",
    "            end_index = start_index + (m + t)\n",
    "\n",
    "            # initialize a list to store recurrent predictions for this interval\n",
    "            predictions_list = list()\n",
    "\n",
    "            for i in np.arange(forecast_window):\n",
    "\n",
    "                # build the inference interval as a sub-series of the dataset\n",
    "                sub_series = ts_test[customer_id][start_index + i : end_index + i]\n",
    "\n",
    "                # important: build sources as copies of the sub-series (and therefore of the global time series)\n",
    "                # to avoid overwriting the original dataset\n",
    "\n",
    "                # the encoder input source\n",
    "                encoder_input = sub_series[encoder_input_columns][:m].copy()\n",
    "\n",
    "                # the decoder input source\n",
    "                # decoder_input = sub_series[m-1:-1].copy()\n",
    "                decoder_input = sub_series[decoder_input_columns][m-1:m-1+t].copy()\n",
    "\n",
    "                # the id (integer) for the customer\n",
    "                id_input = sub_series[id_columns][:1].copy()\n",
    "\n",
    "                # on first step (i=0), the decoder input carries only true values\n",
    "                # and the predictions list is empty\n",
    "                # on subsequent steps, the decoder input includes all previous predictions\n",
    "                # (stored in the predictions list)\n",
    "                if i > 0:\n",
    "                    decoder_input['kw_scaled'][-i:] = predictions_list\n",
    "\n",
    "                # the target source, for metrics calculation\n",
    "                # the first part of the sub-series is the encoder input, and\n",
    "                # the second part of the sub-series is the target (only the variable column!)\n",
    "                target = sub_series['kw_scaled'][m:].copy()\n",
    "\n",
    "                # build source tensors from the sub-series    \n",
    "                encoder_input_tensor = tf.expand_dims(encoder_input, axis=0)\n",
    "                decoder_input_tensor = tf.expand_dims(decoder_input, axis=0)\n",
    "                id_tensor = tf.expand_dims(id_input, axis=0)\n",
    "\n",
    "                # make input example for the prediction function\n",
    "                input_example = input_tensors_to_serialized_example(encoder_input_tensor,\n",
    "                                                                    decoder_input_tensor,\n",
    "                                                                    id_tensor)\n",
    "\n",
    "                # get the output of the prediction function as a dictionary\n",
    "                predict_output_dict = predict_fn(input_example)\n",
    "\n",
    "                # get the prediction output tensor\n",
    "                predict_output_tensor = predict_output_dict['forecast']\n",
    "\n",
    "                # get the most recent prediction\n",
    "                most_recent_prediction = predict_output_tensor[0, :, 0].numpy()[-1]\n",
    "\n",
    "                # append the most recent prediction timestep to the predictions list\n",
    "                predictions_list.append(most_recent_prediction)\n",
    "\n",
    "                # pass the predictions list to an array\n",
    "                # current_predictions_array = np.array(predictions_list).reshape(-1, 1)\n",
    "                # get the targets vector to be compared with the current predictions array\n",
    "                # current_targets = np.array(target[-i-1:]).reshape(-1, 1)\n",
    "\n",
    "                # calculate SMAPE on the rescaled variable\n",
    "                # rescaled_predictions = min_max_scaler.inverse_transform(current_predictions_array)\n",
    "                # rescaled_targets = min_max_scaler.inverse_transform(current_targets)\n",
    "\n",
    "                # current_smape = symmetric_mean_absolute_percentage_error(\n",
    "                #     rescaled_targets, rescaled_predictions)\n",
    "                # print('On row {}, SMAPE for the first {} rescaled prediction(s) is {}'.format(start_index,\n",
    "                #                                                                               i + 1,\n",
    "                #                                                                               current_smape))        \n",
    "\n",
    "            # iterative predictions over the forecast window reside in predictions_list\n",
    "            # convert list to array, then expand feature dimension with value 1\n",
    "            predicted_values = np.array(predictions_list).reshape(-1, 1)\n",
    "\n",
    "            # inverse-scale predictions\n",
    "            rescaled_predicted_values = scaler.inverse_transform(predicted_values)\n",
    "\n",
    "            # and the true values remain in the prediction tensor, pass them to a NumPy array\n",
    "            # for the true values array, expand feature dimension with value 1\n",
    "            true_values = np.array(target[-i-1:]).reshape(-1, 1)\n",
    "\n",
    "            # inverse-scale true values\n",
    "            rescaled_true_values = scaler.inverse_transform(true_values)\n",
    "\n",
    "            # a temporary dataframe built from the data in the current row\n",
    "            df = pd.DataFrame(columns=pred_df_columns)\n",
    "            df['model_id'] = [model_id]\n",
    "            df['execution'] = [execution]\n",
    "            df['dataset'] = [dataset]\n",
    "            df['inference'] = [inference]\n",
    "            df['customer_id'] = [customer_id]\n",
    "            df['string_timestamps']= [pd.to_datetime(target.index[-i-1:]).astype(str).tolist()]\n",
    "            df['predictions'] = [np.squeeze(rescaled_predicted_values).tolist()]\n",
    "            df['targets'] = [np.squeeze(rescaled_true_values).tolist()]\n",
    "\n",
    "            # calculate mean absolute error and normalized deviation\n",
    "            mae = mean_absolute_error(rescaled_true_values, rescaled_predicted_values)\n",
    "            df['mae'] = mae\n",
    "\n",
    "            true_values_average = np.mean(rescaled_true_values)\n",
    "            df['nd'] = mae/true_values_average\n",
    "\n",
    "            # calculate root mean squared error and normalized root mean squared error\n",
    "            rmse = sqrt(mean_squared_error(rescaled_true_values, rescaled_predicted_values))\n",
    "            df['rmse'] = rmse\n",
    "            df['nrmse'] = rmse/true_values_average\n",
    "\n",
    "            df['smape'] = symmetric_mean_absolute_percentage_error(rescaled_true_values,\n",
    "                                                                   rescaled_predicted_values)\n",
    "\n",
    "            # append the temporary dataframe to the predictions detail dataframe\n",
    "            predictions_detail[customer_id] = pd.concat([predictions_detail[customer_id], df])\n",
    "\n",
    "\n",
    "        # reset the index of final dataframe, once all of its rows (dataset) have been processed\n",
    "        predictions_detail[customer_id] = predictions_detail[customer_id].reset_index(drop=True)\n",
    "\n",
    "\n",
    "        # hard-wired switcher to persist dataframe\n",
    "        persist_detail = True\n",
    "        \n",
    "        if persist_detail:\n",
    "            # build a path to persist the dataframe to database/predictions_detail/\n",
    "            detail_pickle_path = '{}/{}/{}/{}_{:02d}_{}_{}_{}_{:02d}.pkl'.format(\n",
    "                PROJECT_ROOT,\n",
    "                'database',\n",
    "                'predictions_detail',\n",
    "                model_id,\n",
    "                execution,\n",
    "                saved_model_id,\n",
    "                # for electricity dataset, replace dataset with customer_id\n",
    "                customer_id,\n",
    "                inference,\n",
    "                event)\n",
    "\n",
    "            # persist the Pandas dataframe to database/predictions_detail/\n",
    "            predictions_detail[customer_id].to_pickle(detail_pickle_path)\n",
    "            print(\n",
    "                'Persisted predictions detail of {}_{:02d}_{}_{}_{}_{:02d}'.format(model_id,\n",
    "                                                                                   execution,\n",
    "                                                                                   saved_model_id,\n",
    "                                                                                   customer_id,\n",
    "                                                                                   inference,\n",
    "                                                                                   event)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
