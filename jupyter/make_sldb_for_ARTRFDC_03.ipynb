{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the code to build SLDBs for the autoregressive transformer architecture.\n",
    "## It superseedes the make_sldb.py script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the variable 'labels' with 'targets', as the latter is more adequate for regression problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "import json\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale datasets to improve neural networks performance\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files in the time series directory\n",
    "# scaler.save\n",
    "# ts.json\n",
    "# ts.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files in the SLDB directory:\n",
    "# train.tfrecord\n",
    "# eval.tfrecord\n",
    "# test.tfrecord\n",
    "# sldb.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dictionary to configure the SLDB\n",
    "# ToDo: transfer this dictionary to dplstm/configs/sldb_config.py\n",
    "\n",
    "# modify the dictionary structure:\n",
    "# no_targets must be the same for all components, then move it to an upper level\n",
    "# remove components and use the same structure as in architecture_parameters\n",
    "\n",
    "# ToDo: build all sldb dictionaries on the basis of list-type parameters,\n",
    "#  by iterating on them to avoid comments on the non-used resolutions, like\n",
    "#  m = [8, 8, 8], tau = [1, 24, 168], no_targets = [24] or\n",
    "#  m = [256], tau = [1], no_targets = [24]\n",
    "\n",
    "\n",
    "sldb = {\n",
    "    'ts': 'CPE04115_H_kw_20201021084001',\n",
    "    'embedding': {\n",
    "        'hourly': 168\n",
    "    },\n",
    "    'tau': {\n",
    "        'hourly': 1\n",
    "    },\n",
    "    'no_targets': 168\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time series was built and persisted in a different code\n",
    "# SLDB constructions begins here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the required time series\n",
    "time_series_folder = '/home/developer/gcp/cbidmltsf/timeseries/{}'.format(sldb['ts'])\n",
    "pickle_filename = '{}/ts.pkl'.format(time_series_folder)\n",
    "ts_df = pd.read_pickle(pickle_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kw_scaled</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01 00:00:00</th>\n",
       "      <td>0.274317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 01:00:00</th>\n",
       "      <td>0.217363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 02:00:00</th>\n",
       "      <td>0.168545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 03:00:00</th>\n",
       "      <td>0.122996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 04:00:00</th>\n",
       "      <td>0.080440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-31 19:00:00</th>\n",
       "      <td>0.652287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-31 20:00:00</th>\n",
       "      <td>0.656872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-31 21:00:00</th>\n",
       "      <td>0.690028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-31 22:00:00</th>\n",
       "      <td>0.609612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-31 23:00:00</th>\n",
       "      <td>0.487964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22629 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     kw_scaled\n",
       "timestamp                     \n",
       "2016-01-01 00:00:00   0.274317\n",
       "2016-01-01 01:00:00   0.217363\n",
       "2016-01-01 02:00:00   0.168545\n",
       "2016-01-01 03:00:00   0.122996\n",
       "2016-01-01 04:00:00   0.080440\n",
       "...                        ...\n",
       "2018-07-31 19:00:00   0.652287\n",
       "2018-07-31 20:00:00   0.656872\n",
       "2018-07-31 21:00:00   0.690028\n",
       "2018-07-31 22:00:00   0.609612\n",
       "2018-07-31 23:00:00   0.487964\n",
       "\n",
       "[22629 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand time series dataframe with six columns for sine-cosine positional encoding over hour, day, month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare sine-cosine positional encoding for the time series\n",
    "hours_in_day = 24\n",
    "days_in_month = 30\n",
    "months_in_year = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build arrays with indexes hour, day, and month\n",
    "timestamp_hour = np.array(ts_df.index.hour)\n",
    "timestamp_day = np.array(ts_df.index.day)\n",
    "timestamp_month = np.array(ts_df.index.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build arrays with positional encoding components and cast them to float32\n",
    "sin_hour = np.sin(2*np.pi*timestamp_hour/hours_in_day).astype(np.float32)\n",
    "cos_hour = np.cos(2*np.pi*timestamp_hour/hours_in_day).astype(np.float32)\n",
    "\n",
    "sin_day = np.sin(2*np.pi*timestamp_day/days_in_month).astype(np.float32)\n",
    "cos_day = np.cos(2*np.pi*timestamp_day/days_in_month).astype(np.float32)\n",
    "\n",
    "sin_month = np.sin(2*np.pi*timestamp_month/months_in_year).astype(np.float32)\n",
    "cos_month = np.cos(2*np.pi*timestamp_month/months_in_year).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now expand the time series dataframe with positional encoding components\n",
    "# pass the pos encoding arrays to dataframe as lists\n",
    "ts_df['sin_hour'] = list(sin_hour)\n",
    "ts_df['cos_hour'] = list(cos_hour)\n",
    "ts_df['sin_day'] = list(sin_day)\n",
    "ts_df['cos_day'] = list(cos_day)\n",
    "ts_df['sin_month'] = list(sin_month)\n",
    "ts_df['cos_month'] = list(cos_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kw_scaled</th>\n",
       "      <th>sin_hour</th>\n",
       "      <th>cos_hour</th>\n",
       "      <th>sin_day</th>\n",
       "      <th>cos_day</th>\n",
       "      <th>sin_month</th>\n",
       "      <th>cos_month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01 00:00:00</th>\n",
       "      <td>0.274317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 01:00:00</th>\n",
       "      <td>0.217363</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 02:00:00</th>\n",
       "      <td>0.168545</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 03:00:00</th>\n",
       "      <td>0.122996</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 04:00:00</th>\n",
       "      <td>0.080440</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     kw_scaled  sin_hour  cos_hour   sin_day   cos_day  \\\n",
       "timestamp                                                                \n",
       "2016-01-01 00:00:00   0.274317  0.000000  1.000000  0.207912  0.978148   \n",
       "2016-01-01 01:00:00   0.217363  0.258819  0.965926  0.207912  0.978148   \n",
       "2016-01-01 02:00:00   0.168545  0.500000  0.866025  0.207912  0.978148   \n",
       "2016-01-01 03:00:00   0.122996  0.707107  0.707107  0.207912  0.978148   \n",
       "2016-01-01 04:00:00   0.080440  0.866025  0.500000  0.207912  0.978148   \n",
       "\n",
       "                     sin_month  cos_month  \n",
       "timestamp                                  \n",
       "2016-01-01 00:00:00        0.5   0.866025  \n",
       "2016-01-01 01:00:00        0.5   0.866025  \n",
       "2016-01-01 02:00:00        0.5   0.866025  \n",
       "2016-01-01 03:00:00        0.5   0.866025  \n",
       "2016-01-01 04:00:00        0.5   0.866025  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# review the final time series dataframe\n",
    "ts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation stage is not used for TPU-based training,\n",
    "# however, evaluation dataset might be useful to get stats from CPU-based training\n",
    "stages = ['train', 'eval', 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data set into train/eval/test at time series level\n",
    "# to avoid data overlapping at SLDB level\n",
    "split = np.array([0.8, 0.9, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get indexes of the scaled time series for train, validation, and test thresholds\n",
    "# train_eval_limit = np.int(ts_df.count()*split[0])\n",
    "# eval_test_limit = np.int(ts_df.count()*split[1])\n",
    "\n",
    "# use the number of rows in the time series (as it has now more than a column, and count() returns a vector)\n",
    "train_eval_limit = np.int(ts_df.shape[0]*split[0])\n",
    "eval_test_limit = np.int(ts_df.shape[0]*split[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dictionary to manage the time series for the different model stages\n",
    "ts = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18103 lectures in train time series from 2016-01-01 00:00:00 to 2018-01-24 08:00:00\n"
     ]
    }
   ],
   "source": [
    "# get the time series portion for train set\n",
    "ts['train'] = ts_df[:train_eval_limit]\n",
    "print('{0} lectures in train time series from {1} to {2}'.format(ts['train'].count()[0],\n",
    "                                                                 ts['train'].index[0],\n",
    "                                                                 ts['train'].index[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2263 lectures in eval time series from 2018-01-24 09:00:00 to 2018-04-28 16:00:00\n"
     ]
    }
   ],
   "source": [
    "# get the time series portion for eval set\n",
    "ts['eval'] = ts_df[train_eval_limit:eval_test_limit]\n",
    "print('{0} lectures in eval time series from {1} to {2}'.format(ts['eval'].count()[0],\n",
    "                                                                ts['eval'].index[0],\n",
    "                                                                ts['eval'].index[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2263 lectures in test time series from 2018-04-28 17:00:00 to 2018-07-31 23:00:00\n"
     ]
    }
   ],
   "source": [
    "# get the time series portion for test set\n",
    "ts['test'] = ts_df[eval_test_limit:]\n",
    "print('{} lectures in test time series from {} to {}'.format(ts['test'].count()[0],\n",
    "                                                             ts['test'].index[0],\n",
    "                                                             ts['test'].index[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start prototype for building SLDB for transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18103, 7)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start with time series for training set\n",
    "# how many lectures-columns in time series?\n",
    "ts['train'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kw_scaled</th>\n",
       "      <th>sin_hour</th>\n",
       "      <th>cos_hour</th>\n",
       "      <th>sin_day</th>\n",
       "      <th>cos_day</th>\n",
       "      <th>sin_month</th>\n",
       "      <th>cos_month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01 00:00:00</th>\n",
       "      <td>0.274317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 01:00:00</th>\n",
       "      <td>0.217363</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>9.659258e-01</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 02:00:00</th>\n",
       "      <td>0.168545</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 03:00:00</th>\n",
       "      <td>0.122996</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 04:00:00</th>\n",
       "      <td>0.080440</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.207912</td>\n",
       "      <td>0.978148</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-24 04:00:00</th>\n",
       "      <td>0.073374</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-0.951057</td>\n",
       "      <td>0.309017</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-24 05:00:00</th>\n",
       "      <td>0.084031</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>-0.951057</td>\n",
       "      <td>0.309017</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-24 06:00:00</th>\n",
       "      <td>0.180768</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>-0.951057</td>\n",
       "      <td>0.309017</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-24 07:00:00</th>\n",
       "      <td>0.264623</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-2.588190e-01</td>\n",
       "      <td>-0.951057</td>\n",
       "      <td>0.309017</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-24 08:00:00</th>\n",
       "      <td>0.305140</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-0.951057</td>\n",
       "      <td>0.309017</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18103 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     kw_scaled  sin_hour      cos_hour   sin_day   cos_day  \\\n",
       "timestamp                                                                    \n",
       "2016-01-01 00:00:00   0.274317  0.000000  1.000000e+00  0.207912  0.978148   \n",
       "2016-01-01 01:00:00   0.217363  0.258819  9.659258e-01  0.207912  0.978148   \n",
       "2016-01-01 02:00:00   0.168545  0.500000  8.660254e-01  0.207912  0.978148   \n",
       "2016-01-01 03:00:00   0.122996  0.707107  7.071068e-01  0.207912  0.978148   \n",
       "2016-01-01 04:00:00   0.080440  0.866025  5.000000e-01  0.207912  0.978148   \n",
       "...                        ...       ...           ...       ...       ...   \n",
       "2018-01-24 04:00:00   0.073374  0.866025  5.000000e-01 -0.951057  0.309017   \n",
       "2018-01-24 05:00:00   0.084031  0.965926  2.588190e-01 -0.951057  0.309017   \n",
       "2018-01-24 06:00:00   0.180768  1.000000  6.123234e-17 -0.951057  0.309017   \n",
       "2018-01-24 07:00:00   0.264623  0.965926 -2.588190e-01 -0.951057  0.309017   \n",
       "2018-01-24 08:00:00   0.305140  0.866025 -5.000000e-01 -0.951057  0.309017   \n",
       "\n",
       "                     sin_month  cos_month  \n",
       "timestamp                                  \n",
       "2016-01-01 00:00:00        0.5   0.866025  \n",
       "2016-01-01 01:00:00        0.5   0.866025  \n",
       "2016-01-01 02:00:00        0.5   0.866025  \n",
       "2016-01-01 03:00:00        0.5   0.866025  \n",
       "2016-01-01 04:00:00        0.5   0.866025  \n",
       "...                        ...        ...  \n",
       "2018-01-24 04:00:00        0.5   0.866025  \n",
       "2018-01-24 05:00:00        0.5   0.866025  \n",
       "2018-01-24 06:00:00        0.5   0.866025  \n",
       "2018-01-24 07:00:00        0.5   0.866025  \n",
       "2018-01-24 08:00:00        0.5   0.866025  \n",
       "\n",
       "[18103 rows x 7 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review this link to pass directly from NumPy arrays to TFRecord\n",
    "# https://stackoverflow.com/questions/45427637/numpy-to-tfrecords-is-there-a-more-simple-way-to-handle-batch-inputs-from-tfrec/45428167#45428167"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SLDB for transformer has the following features in each row:\n",
    "# source tensor: kw_scaled, sin_hour, cos_hour, sin_day, cos_day, sin_month, cos_month (?, 168, 7)\n",
    "# target tensor: kw_scaled, sin_hour, cos_hour, sin_day, cos_day, sin_month, cos_month (?, 168, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data structure to convert to TFRecords: list of NumPy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build all the possible sub-series of sldb['embedding']['hourly'] elements (the embedding dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = sldb['embedding']['hourly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a sub-dictionary for SLDB stats\n",
    "sldb['stats'] = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created for train stage with 17935 total rows.\n",
      "Dataset created for eval stage with 2095 total rows.\n",
      "Dataset created for test stage with 2095 total rows.\n"
     ]
    }
   ],
   "source": [
    "# a dictionary to store row arrays lists for all the stages\n",
    "results = dict()\n",
    "\n",
    "# iterate on stages\n",
    "for stage in ['train', 'eval', 'test']:\n",
    "    \n",
    "    # a temporal, full-size, list to store source/target tensors (n_rows, m, 7)\n",
    "    row_arrays_list = list()\n",
    "    \n",
    "    for start_value in range(ts[stage].shape[0] - m + 1):\n",
    "        # start_value, end_value are the indexes in the dataframe that define the time window sub-series\n",
    "        end_value = start_value + m\n",
    "        # get the time window sub-series\n",
    "        sub_series = ts[stage][start_value: end_value]\n",
    "        # pass the sub-series to a NumPy array of shape [m, features] V.gr. [168, 7]\n",
    "        # discard the timestamp index before\n",
    "        row_array = sub_series.reset_index(drop=True).to_numpy()\n",
    "        # stack all the generated row arrays in a master list\n",
    "        row_arrays_list.append(row_array)\n",
    "        \n",
    "    # report stage completion\n",
    "    print('Dataset created for {} stage with {} total rows.'.format(stage, len(row_arrays_list)-1))\n",
    "    \n",
    "    # given the nature of the autoregressive transformer\n",
    "    # (target is source, shifted once to the right):\n",
    "    # row 0 is the source and row 1 is the target\n",
    "    # row 1 is the source and row 2 is the target\n",
    "    # ...\n",
    "    # row n-1 is the source and row n is the target\n",
    "    \n",
    "    # add a sub-dictionary for stage results\n",
    "    results[stage] = dict()\n",
    "    # then, source and target lists are easy to build\n",
    "    results[stage]['source'] = row_arrays_list[:-1]   # from the first row to the one before the last\n",
    "    results[stage]['target'] = row_arrays_list[1:]    # from the second row to the last one\n",
    "    \n",
    "    # add a sub-dictionary for stage stats\n",
    "    sldb['stats'][stage] = dict()\n",
    "    # pass number of rows to SLDB statistics dictionary\n",
    "    # the number of rows in source and target is equivalent, then use any of them\n",
    "    if len(results[stage]['source']) == len(results[stage]['target']):\n",
    "        sldb['stats'][stage]['n_rows'] = len(results[stage]['source'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ts': 'CPE04115_H_kw_20201021084001',\n",
       " 'embedding': {'hourly': 168},\n",
       " 'tau': {'hourly': 1},\n",
       " 'no_targets': 168,\n",
       " 'stats': {'test': {'n_rows': 2095},\n",
       "  'train': {'n_rows': 17935},\n",
       "  'eval': {'n_rows': 2095}}}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sldb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to encode float values for serialized examples\n",
    "def _float_feature_from_list_of_values(list_of_values):\n",
    "    \"\"\"Returns a float_list from a list of floats / doubles.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=list_of_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ARTRFDC_168'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a string with the basic specifications of the SLDB, as part of the SLDB identifier\n",
    "sldb_specs = 'ARTRFDC_{:03d}'.format(sldb['embedding']['hourly'])\n",
    "\n",
    "sldb_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CPE04115_H_kw_20201021084001_ARTRFDC_168'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build a time-based identifer for the SLDB\n",
    "sldb_identifier = '{}_{}'.format(sldb['ts'], sldb_specs)\n",
    "sldb_identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/developer/gcp/cbidmltsf/sldbs/CPE04115_H_kw_20201021084001_ARTRFDC_168'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sldb_dir = '/home/developer/gcp/cbidmltsf/sldbs/{}'.format(sldb_identifier)\n",
    "sldb_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /home/developer/gcp/cbidmltsf/sldbs/CPE04115_H_kw_20201021084001_ARTRFDC_168 was created.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir(sldb_dir)\n",
    "    print('Directory {} was created.'.format(sldb_dir))\n",
    "except FileExistsError:\n",
    "    print('Error: directory {} already exists.'.format(sldb_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168, 7)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['train']['source'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stage in stages:\n",
    "    N_ROWS = sldb['stats'][stage]['n_rows']\n",
    "    filename = '{}/{}.tfrecord'.format(sldb_dir, stage)\n",
    "\n",
    "    with tf.io.TFRecordWriter(filename) as writer:\n",
    "        for row in np.arange(N_ROWS):\n",
    "            example = tf.train.Example(\n",
    "                # features within the example\n",
    "                features=tf.train.Features(\n",
    "                    # individual feature definition\n",
    "                    feature={'source': _float_feature_from_list_of_values(results[stage]['source'][row].flatten()),\n",
    "                             'target': _float_feature_from_list_of_values(results[stage]['target'][row].flatten())\n",
    "                             # ToDo: persist source or target timestamps to be used during prediction\n",
    "                             # 'timestamp': _bytes_feature_from_list_of_values(tfrecords[stage]['timestamps'][row])\n",
    "                             }\n",
    "                )\n",
    "            )\n",
    "            serialized_example = example.SerializeToString()\n",
    "            writer.write(serialized_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a path for the json file\n",
    "json_filename = '{}/sldb.json'.format(sldb_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persist the final, compact dictionary to JSON\n",
    "with open(json_filename, 'w') as filename:\n",
    "    json.dump(sldb, filename, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building synchronization state...\n",
      "Starting synchronization...\n",
      "Copying file:///home/developer/gcp/cbidmltsf/sldbs/CPE04115_H_kw_20201021084001_ARTRFDC_168/eval.tfrecord [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/developer/gcp/cbidmltsf/sldbs/CPE04115_H_kw_20201021084001_ARTRFDC_168/sldb.json [Content-Type=application/json]...\n",
      "Copying file:///home/developer/gcp/cbidmltsf/sldbs/CPE04115_H_kw_20201021084001_ARTRFDC_168/test.tfrecord [Content-Type=application/octet-stream]...\n",
      "Copying file:///home/developer/gcp/cbidmltsf/sldbs/CPE04115_H_kw_20201021084001_ARTRFDC_168/train.tfrecord [Content-Type=application/octet-stream]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "/ [4 files][199.8 MiB/199.8 MiB]  596.8 KiB/s                                   \n",
      "Operation completed over 4 objects/199.8 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "# do not forget to sync sldbs/ from local to GS after the previous operations!\n",
    "!gsutil rsync -d -r /home/developer/gcp/cbidmltsf/sldbs gs://cbidmltsf/sldbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
