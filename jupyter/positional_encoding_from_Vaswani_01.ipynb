{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a demo array (1, 4, 16) for input\n",
    "demo_input = np.zeros([1, 4, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=4>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the number of timesteps per row\n",
    "T = tf.shape(demo_input)[1]\n",
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 1), dtype=float32, numpy=\n",
       "array([[0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.]], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = tf.reshape(tf.range(0.0, T, dtype=tf.float32), [-1, 1])\n",
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=64>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repr_dim = tf.shape(demo_input)[-1]\n",
    "repr_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  2.,  4.,  6.,  8., 10., 12., 14., 16., 18., 20., 22., 24.,\n",
       "       26., 28., 30., 32., 34., 36., 38., 40., 42., 44., 46., 48., 50.,\n",
       "       52., 54., 56., 58., 60., 62.], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = np.arange(0, repr_dim, 2, np.float32)\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 1.33352143e+00, 1.77827941e+00, 2.37137371e+00,\n",
       "        3.16227766e+00, 4.21696503e+00, 5.62341325e+00, 7.49894209e+00,\n",
       "        1.00000000e+01, 1.33352143e+01, 1.77827941e+01, 2.37137371e+01,\n",
       "        3.16227766e+01, 4.21696503e+01, 5.62341325e+01, 7.49894209e+01,\n",
       "        1.00000000e+02, 1.33352143e+02, 1.77827941e+02, 2.37137371e+02,\n",
       "        3.16227766e+02, 4.21696503e+02, 5.62341325e+02, 7.49894209e+02,\n",
       "        1.00000000e+03, 1.33352143e+03, 1.77827941e+03, 2.37137371e+03,\n",
       "        3.16227766e+03, 4.21696503e+03, 5.62341325e+03, 7.49894209e+03]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denom = np.reshape(np.power(10000.0, i/repr_dim), [1, -1])\n",
    "denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4, 64), dtype=float32, numpy=\n",
       "array([[[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "          1.0000000e+00,  1.0000000e+00,  1.0000000e+00,  1.0000000e+00,\n",
       "          1.0000000e+00,  1.0000000e+00,  1.0000000e+00,  1.0000000e+00,\n",
       "          1.0000000e+00,  1.0000000e+00,  1.0000000e+00,  1.0000000e+00,\n",
       "          1.0000000e+00,  1.0000000e+00,  1.0000000e+00,  1.0000000e+00,\n",
       "          1.0000000e+00,  1.0000000e+00,  1.0000000e+00,  1.0000000e+00,\n",
       "          1.0000000e+00,  1.0000000e+00,  1.0000000e+00,  1.0000000e+00,\n",
       "          1.0000000e+00,  1.0000000e+00,  1.0000000e+00,  1.0000000e+00,\n",
       "          1.0000000e+00,  1.0000000e+00,  1.0000000e+00,  1.0000000e+00],\n",
       "        [ 8.4147096e-01,  6.8156135e-01,  5.3316844e-01,  4.0930894e-01,\n",
       "          3.1098360e-01,  2.3492107e-01,  1.7689219e-01,  1.3295726e-01,\n",
       "          9.9833421e-02,  7.4919149e-02,  5.6204494e-02,  4.2157151e-02,\n",
       "          3.1617507e-02,  2.3711514e-02,  1.7781857e-02,  1.3334820e-02,\n",
       "          9.9998331e-03,  7.4988720e-03,  5.6233834e-03,  4.2169522e-03,\n",
       "          3.1622725e-03,  2.3713715e-03,  1.7782785e-03,  1.3335211e-03,\n",
       "          9.9999993e-04,  7.4989413e-04,  5.6234124e-04,  4.2169649e-04,\n",
       "          3.1622779e-04,  2.3713738e-04,  1.7782794e-04,  1.3335215e-04,\n",
       "          5.4030228e-01,  7.3176098e-01,  8.4600914e-01,  9.1239583e-01,\n",
       "          9.5041525e-01,  9.7201443e-01,  9.8423022e-01,  9.9112177e-01,\n",
       "          9.9500418e-01,  9.9718964e-01,  9.9841928e-01,  9.9911100e-01,\n",
       "          9.9950004e-01,  9.9971884e-01,  9.9984187e-01,  9.9991107e-01,\n",
       "          9.9994999e-01,  9.9997187e-01,  9.9998420e-01,  9.9999112e-01,\n",
       "          9.9999499e-01,  9.9999720e-01,  9.9999839e-01,  9.9999911e-01,\n",
       "          9.9999952e-01,  9.9999970e-01,  9.9999982e-01,  9.9999994e-01,\n",
       "          9.9999994e-01,  1.0000000e+00,  1.0000000e+00,  1.0000000e+00],\n",
       "        [ 9.0929741e-01,  9.9747998e-01,  9.0213072e-01,  7.4690354e-01,\n",
       "          5.9112710e-01,  4.5669335e-01,  3.4820527e-01,  2.6355368e-01,\n",
       "          1.9866933e-01,  1.4941721e-01,  1.1223131e-01,  8.4239349e-02,\n",
       "          6.3203402e-02,  4.7409695e-02,  3.5558090e-02,  2.6667269e-02,\n",
       "          1.9998666e-02,  1.4997322e-02,  1.1246589e-02,  8.4338300e-03,\n",
       "          6.3245133e-03,  4.7427299e-03,  3.5565514e-03,  2.6670396e-03,\n",
       "          1.9999987e-03,  1.4997878e-03,  1.1246824e-03,  8.4339286e-04,\n",
       "          6.3245551e-04,  4.7427474e-04,  3.5565588e-04,  2.6670430e-04,\n",
       "         -4.1614681e-01,  7.0948265e-02,  4.3146282e-01,  6.6493237e-01,\n",
       "          8.0657840e-01,  8.8962418e-01,  9.3741834e-01,  9.6464473e-01,\n",
       "          9.8006660e-01,  9.8877424e-01,  9.9368209e-01,  9.9644554e-01,\n",
       "          9.9800068e-01,  9.9887550e-01,  9.9936759e-01,  9.9964434e-01,\n",
       "          9.9980003e-01,  9.9988753e-01,  9.9993676e-01,  9.9996442e-01,\n",
       "          9.9997997e-01,  9.9998873e-01,  9.9999368e-01,  9.9999642e-01,\n",
       "          9.9999797e-01,  9.9999887e-01,  9.9999934e-01,  9.9999964e-01,\n",
       "          9.9999982e-01,  9.9999988e-01,  9.9999994e-01,  9.9999994e-01],\n",
       "        [ 1.4112000e-01,  7.7827263e-01,  9.9325317e-01,  9.5363444e-01,\n",
       "          8.1264889e-01,  6.5290397e-01,  5.0853616e-01,  3.8947034e-01,\n",
       "          2.9552022e-01,  2.2307542e-01,  1.6790330e-01,  1.2617177e-01,\n",
       "          9.4726093e-02,  7.1081221e-02,  5.3323083e-02,  3.9994974e-02,\n",
       "          2.9995499e-02,  2.2494929e-02,  1.6869439e-02,  1.2650558e-02,\n",
       "          9.4866911e-03,  7.1140612e-03,  5.3348131e-03,  4.0005534e-03,\n",
       "          2.9999956e-03,  2.2496807e-03,  1.6870232e-03,  1.2650891e-03,\n",
       "          9.4868318e-04,  7.1141211e-04,  5.3348386e-04,  4.0005645e-04,\n",
       "         -9.8999250e-01, -6.2792653e-01, -1.1596616e-01,  3.0096731e-01,\n",
       "          5.8275366e-01,  7.5744069e-01,  8.6104065e-01,  9.2103899e-01,\n",
       "          9.5533651e-01,  9.7480118e-01,  9.8580348e-01,  9.9200839e-01,\n",
       "          9.9550337e-01,  9.9747056e-01,  9.9857730e-01,  9.9919987e-01,\n",
       "          9.9955004e-01,  9.9974698e-01,  9.9985772e-01,  9.9991995e-01,\n",
       "          9.9995500e-01,  9.9997467e-01,  9.9998575e-01,  9.9999201e-01,\n",
       "          9.9999553e-01,  9.9999750e-01,  9.9999857e-01,  9.9999923e-01,\n",
       "          9.9999952e-01,  9.9999976e-01,  9.9999988e-01,  9.9999994e-01]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = tf.expand_dims(tf.concat([tf.sin(pos / denom), tf.cos(pos / denom)], 1), 0)\n",
    "enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4, 64), dtype=float32, numpy=\n",
       "array([[[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "          1.0000000e+00,  1.0000000e+00,  1.0000000e+00,  1.0000000e+00,\n",
       "          1.0000000e+00,  1.0000000e+00,  1.0000000e+00,  1.0000000e+00,\n",
       "          1.0000000e+00,  1.0000000e+00,  1.0000000e+00,  1.0000000e+00,\n",
       "          1.0000000e+00,  1.0000000e+00,  1.0000000e+00,  1.0000000e+00,\n",
       "          1.0000000e+00,  1.0000000e+00,  1.0000000e+00,  1.0000000e+00,\n",
       "          1.0000000e+00,  1.0000000e+00,  1.0000000e+00,  1.0000000e+00,\n",
       "          1.0000000e+00,  1.0000000e+00,  1.0000000e+00,  1.0000000e+00,\n",
       "          1.0000000e+00,  1.0000000e+00,  1.0000000e+00,  1.0000000e+00],\n",
       "        [ 8.4147096e-01,  6.8156135e-01,  5.3316844e-01,  4.0930894e-01,\n",
       "          3.1098360e-01,  2.3492107e-01,  1.7689219e-01,  1.3295726e-01,\n",
       "          9.9833421e-02,  7.4919149e-02,  5.6204494e-02,  4.2157151e-02,\n",
       "          3.1617507e-02,  2.3711514e-02,  1.7781857e-02,  1.3334820e-02,\n",
       "          9.9998331e-03,  7.4988720e-03,  5.6233834e-03,  4.2169522e-03,\n",
       "          3.1622725e-03,  2.3713715e-03,  1.7782785e-03,  1.3335211e-03,\n",
       "          9.9999993e-04,  7.4989413e-04,  5.6234124e-04,  4.2169649e-04,\n",
       "          3.1622779e-04,  2.3713738e-04,  1.7782794e-04,  1.3335215e-04,\n",
       "          5.4030228e-01,  7.3176098e-01,  8.4600914e-01,  9.1239583e-01,\n",
       "          9.5041525e-01,  9.7201443e-01,  9.8423022e-01,  9.9112177e-01,\n",
       "          9.9500418e-01,  9.9718964e-01,  9.9841928e-01,  9.9911100e-01,\n",
       "          9.9950004e-01,  9.9971884e-01,  9.9984187e-01,  9.9991107e-01,\n",
       "          9.9994999e-01,  9.9997187e-01,  9.9998420e-01,  9.9999112e-01,\n",
       "          9.9999499e-01,  9.9999720e-01,  9.9999839e-01,  9.9999911e-01,\n",
       "          9.9999952e-01,  9.9999970e-01,  9.9999982e-01,  9.9999994e-01,\n",
       "          9.9999994e-01,  1.0000000e+00,  1.0000000e+00,  1.0000000e+00],\n",
       "        [ 9.0929741e-01,  9.9747998e-01,  9.0213072e-01,  7.4690354e-01,\n",
       "          5.9112710e-01,  4.5669335e-01,  3.4820527e-01,  2.6355368e-01,\n",
       "          1.9866933e-01,  1.4941721e-01,  1.1223131e-01,  8.4239349e-02,\n",
       "          6.3203402e-02,  4.7409695e-02,  3.5558090e-02,  2.6667269e-02,\n",
       "          1.9998666e-02,  1.4997322e-02,  1.1246589e-02,  8.4338300e-03,\n",
       "          6.3245133e-03,  4.7427299e-03,  3.5565514e-03,  2.6670396e-03,\n",
       "          1.9999987e-03,  1.4997878e-03,  1.1246824e-03,  8.4339286e-04,\n",
       "          6.3245551e-04,  4.7427474e-04,  3.5565588e-04,  2.6670430e-04,\n",
       "         -4.1614681e-01,  7.0948265e-02,  4.3146282e-01,  6.6493237e-01,\n",
       "          8.0657840e-01,  8.8962418e-01,  9.3741834e-01,  9.6464473e-01,\n",
       "          9.8006660e-01,  9.8877424e-01,  9.9368209e-01,  9.9644554e-01,\n",
       "          9.9800068e-01,  9.9887550e-01,  9.9936759e-01,  9.9964434e-01,\n",
       "          9.9980003e-01,  9.9988753e-01,  9.9993676e-01,  9.9996442e-01,\n",
       "          9.9997997e-01,  9.9998873e-01,  9.9999368e-01,  9.9999642e-01,\n",
       "          9.9999797e-01,  9.9999887e-01,  9.9999934e-01,  9.9999964e-01,\n",
       "          9.9999982e-01,  9.9999988e-01,  9.9999994e-01,  9.9999994e-01],\n",
       "        [ 1.4112000e-01,  7.7827263e-01,  9.9325317e-01,  9.5363444e-01,\n",
       "          8.1264889e-01,  6.5290397e-01,  5.0853616e-01,  3.8947034e-01,\n",
       "          2.9552022e-01,  2.2307542e-01,  1.6790330e-01,  1.2617177e-01,\n",
       "          9.4726093e-02,  7.1081221e-02,  5.3323083e-02,  3.9994974e-02,\n",
       "          2.9995499e-02,  2.2494929e-02,  1.6869439e-02,  1.2650558e-02,\n",
       "          9.4866911e-03,  7.1140612e-03,  5.3348131e-03,  4.0005534e-03,\n",
       "          2.9999956e-03,  2.2496807e-03,  1.6870232e-03,  1.2650891e-03,\n",
       "          9.4868318e-04,  7.1141211e-04,  5.3348386e-04,  4.0005645e-04,\n",
       "         -9.8999250e-01, -6.2792653e-01, -1.1596616e-01,  3.0096731e-01,\n",
       "          5.8275366e-01,  7.5744069e-01,  8.6104065e-01,  9.2103899e-01,\n",
       "          9.5533651e-01,  9.7480118e-01,  9.8580348e-01,  9.9200839e-01,\n",
       "          9.9550337e-01,  9.9747056e-01,  9.9857730e-01,  9.9919987e-01,\n",
       "          9.9955004e-01,  9.9974698e-01,  9.9985772e-01,  9.9991995e-01,\n",
       "          9.9995500e-01,  9.9997467e-01,  9.9998575e-01,  9.9999201e-01,\n",
       "          9.9999553e-01,  9.9999750e-01,  9.9999857e-01,  9.9999923e-01,\n",
       "          9.9999952e-01,  9.9999976e-01,  9.9999988e-01,  9.9999994e-01]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.tile(enc, [tf.shape(demo_input)[0], 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/huseinzol05/Stock-Prediction-Models/blob/master/deep-learning/16.attention-is-all-you-need.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinusoidal_position_encoding(inputs, mask, repr_dim):\n",
    "    T = tf.shape(inputs)[1]\n",
    "    pos = tf.reshape(tf.range(0.0, tf.to_float(T), dtype=tf.float32), [-1, 1])\n",
    "    i = np.arange(0, repr_dim, 2, np.float32)\n",
    "    denom = np.reshape(np.power(10000.0, i / repr_dim), [1, -1])\n",
    "    enc = tf.expand_dims(tf.concat([tf.sin(pos / denom), tf.cos(pos / denom)], 1), 0)\n",
    "    return tf.tile(enc, [tf.shape(inputs)[0], 1, 1]) * tf.expand_dims(tf.to_float(mask), -1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
