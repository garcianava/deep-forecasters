{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer-decoder with no Seq2Seq component (autoregressive)\n",
    "\n",
    "# no value embedding\n",
    "# sine-cosine positional encoding on the hour, day, and month of timestamp\n",
    "# modified transformer-encoder layer for masked self-attention\n",
    "\n",
    "# conduct an architecture test similar to the one on the transformer-encoder in\n",
    "# deep_transformer_model_for_tsf_XX.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required for TFA MultiHeadAttention\n",
    "import typing\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MHA class from TensorFlow AddOns source\n",
    "# it is compatible with TF 1.15 for CloudTPU usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    r\"\"\"MultiHead Attention layer.\n",
    "    Defines the MultiHead Attention operation as described in\n",
    "    [Attention Is All You Need](https://arxiv.org/abs/1706.03762) which takes\n",
    "    in the tensors `query`, `key`, and `value`, and returns the dot-product attention\n",
    "    between them:\n",
    "    >>> mha = MultiHeadAttention(head_size=128, num_heads=12)\n",
    "    >>> query = np.random.rand(3, 5, 4) # (batch_size, query_elements, query_depth)\n",
    "    >>> key = np.random.rand(3, 6, 5) # (batch_size, key_elements, key_depth)\n",
    "    >>> value = np.random.rand(3, 6, 6) # (batch_size, key_elements, value_depth)\n",
    "    >>> attention = mha([query, key, value]) # (batch_size, query_elements, value_depth)\n",
    "    >>> attention.shape\n",
    "    TensorShape([3, 5, 6])\n",
    "    If `value` is not given then internally `value = key` will be used:\n",
    "    >>> mha = MultiHeadAttention(head_size=128, num_heads=12)\n",
    "    >>> query = np.random.rand(3, 5, 5) # (batch_size, query_elements, query_depth)\n",
    "    >>> key = np.random.rand(3, 6, 10) # (batch_size, key_elements, key_depth)\n",
    "    >>> attention = mha([query, key]) # (batch_size, query_elements, key_depth)\n",
    "    >>> attention.shape\n",
    "    TensorShape([3, 5, 10])\n",
    "    Args:\n",
    "        head_size: int, dimensionality of the `query`, `key` and `value` tensors\n",
    "            after the linear transformation.\n",
    "        num_heads: int, number of attention heads.\n",
    "        output_size: int, dimensionality of the output space, if `None` then the\n",
    "            input dimension of `value` or `key` will be used,\n",
    "            default `None`.\n",
    "        dropout: float, `rate` parameter for the dropout layer that is\n",
    "            applied to attention after softmax,\n",
    "        default `0`.\n",
    "        use_projection_bias: bool, whether to use a bias term after the linear\n",
    "            output projection.\n",
    "        return_attn_coef: bool, if `True`, return the attention coefficients as\n",
    "            an additional output argument.\n",
    "        kernel_initializer: initializer, initializer for the kernel weights.\n",
    "        kernel_regularizer: regularizer, regularizer for the kernel weights.\n",
    "        kernel_constraint: constraint, constraint for the kernel weights.\n",
    "        bias_initializer: initializer, initializer for the bias weights.\n",
    "        bias_regularizer: regularizer, regularizer for the bias weights.\n",
    "        bias_constraint: constraint, constraint for the bias weights.\n",
    "    Call Args:\n",
    "        inputs:  List of `[query, key, value]` where\n",
    "            * `query`: Tensor of shape `(..., query_elements, query_depth)`\n",
    "            * `key`: `Tensor of shape '(..., key_elements, key_depth)`\n",
    "            * `value`: Tensor of shape `(..., key_elements, value_depth)`, optional, if not given `key` will be used.\n",
    "        mask: a binary Tensor of shape `[batch_size?, num_heads?, query_elements, key_elements]`\n",
    "        which specifies which query elements can attend to which key elements,\n",
    "        `1` indicates attention and `0` indicates no attention.\n",
    "    Output shape:\n",
    "        * `(..., query_elements, output_size)` if `output_size` is given, else\n",
    "        * `(..., query_elements, value_depth)` if `value` is given, else\n",
    "        * `(..., query_elements, key_depth)`\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        head_size: int,\n",
    "        num_heads: int,\n",
    "        output_size: int = None,\n",
    "        dropout: float = 0.0,\n",
    "        use_projection_bias: bool = True,\n",
    "        return_attn_coef: bool = False,\n",
    "        kernel_initializer: typing.Union[str, typing.Callable] = \"glorot_uniform\",\n",
    "        kernel_regularizer: typing.Union[str, typing.Callable] = None,\n",
    "        kernel_constraint: typing.Union[str, typing.Callable] = None,\n",
    "        bias_initializer: typing.Union[str, typing.Callable] = \"zeros\",\n",
    "        bias_regularizer: typing.Union[str, typing.Callable] = None,\n",
    "        bias_constraint: typing.Union[str, typing.Callable] = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        warnings.warn(\n",
    "            \"`MultiHeadAttention` will be deprecated in Addons 0.13. \"\n",
    "            \"Please use `tf.keras.layers.MultiHeadAttention` instead.\",\n",
    "            DeprecationWarning,\n",
    "        )\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        if output_size is not None and output_size < 1:\n",
    "            raise ValueError(\"output_size must be a positive number\")\n",
    "\n",
    "        self.head_size = head_size\n",
    "        self.num_heads = num_heads\n",
    "        self.output_size = output_size\n",
    "        self.use_projection_bias = use_projection_bias\n",
    "        self.return_attn_coef = return_attn_coef\n",
    "\n",
    "        self.kernel_initializer = tf.keras.initializers.get(kernel_initializer)\n",
    "        self.kernel_regularizer = tf.keras.regularizers.get(kernel_regularizer)\n",
    "        self.kernel_constraint = tf.keras.constraints.get(kernel_constraint)\n",
    "        self.bias_initializer = tf.keras.initializers.get(bias_initializer)\n",
    "        self.bias_regularizer = tf.keras.regularizers.get(bias_regularizer)\n",
    "        self.bias_constraint = tf.keras.constraints.get(bias_constraint)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "        self._dropout_rate = dropout\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        num_query_features = input_shape[0][-1]\n",
    "        num_key_features = input_shape[1][-1]\n",
    "        num_value_features = (\n",
    "            input_shape[2][-1] if len(input_shape) > 2 else num_key_features\n",
    "        )\n",
    "        output_size = (\n",
    "            self.output_size if self.output_size is not None else num_value_features\n",
    "        )\n",
    "\n",
    "        self.query_kernel = self.add_weight(\n",
    "            name=\"query_kernel\",\n",
    "            shape=[self.num_heads, num_query_features, self.head_size],\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            constraint=self.kernel_constraint,\n",
    "        )\n",
    "        self.key_kernel = self.add_weight(\n",
    "            name=\"key_kernel\",\n",
    "            shape=[self.num_heads, num_key_features, self.head_size],\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            constraint=self.kernel_constraint,\n",
    "        )\n",
    "        self.value_kernel = self.add_weight(\n",
    "            name=\"value_kernel\",\n",
    "            shape=[self.num_heads, num_value_features, self.head_size],\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            constraint=self.kernel_constraint,\n",
    "        )\n",
    "        self.projection_kernel = self.add_weight(\n",
    "            name=\"projection_kernel\",\n",
    "            shape=[self.num_heads, self.head_size, output_size],\n",
    "            initializer=self.kernel_initializer,\n",
    "            regularizer=self.kernel_regularizer,\n",
    "            constraint=self.kernel_constraint,\n",
    "        )\n",
    "\n",
    "        if self.use_projection_bias:\n",
    "            self.projection_bias = self.add_weight(\n",
    "                name=\"projection_bias\",\n",
    "                shape=[output_size],\n",
    "                initializer=self.bias_initializer,\n",
    "                regularizer=self.bias_regularizer,\n",
    "                constraint=self.bias_constraint,\n",
    "            )\n",
    "        else:\n",
    "            self.projection_bias = None\n",
    "\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "\n",
    "        # einsum nomenclature\n",
    "        # ------------------------\n",
    "        # N = query elements\n",
    "        # M = key/value elements\n",
    "        # H = heads\n",
    "        # I = input features\n",
    "        # O = output features\n",
    "\n",
    "        query = inputs[0]\n",
    "        key = inputs[1]\n",
    "        value = inputs[2] if len(inputs) > 2 else key\n",
    "\n",
    "        # verify shapes\n",
    "        if key.shape[-2] != value.shape[-2]:\n",
    "            raise ValueError(\n",
    "                \"the number of elements in 'key' must be equal to the same as the number of elements in 'value'\"\n",
    "            )\n",
    "\n",
    "        if mask is not None:\n",
    "            if len(mask.shape) < 2:\n",
    "                raise ValueError(\"'mask' must have atleast 2 dimensions\")\n",
    "            if query.shape[-2] != mask.shape[-2]:\n",
    "                raise ValueError(\n",
    "                    \"mask's second to last dimension must be equal to the number of elements in 'query'\"\n",
    "                )\n",
    "            if key.shape[-2] != mask.shape[-1]:\n",
    "                raise ValueError(\n",
    "                    \"mask's last dimension must be equal to the number of elements in 'key'\"\n",
    "                )\n",
    "\n",
    "        # Linear transformations\n",
    "        query = tf.einsum(\"...NI , HIO -> ...NHO\", query, self.query_kernel)\n",
    "        key = tf.einsum(\"...MI , HIO -> ...MHO\", key, self.key_kernel)\n",
    "        value = tf.einsum(\"...MI , HIO -> ...MHO\", value, self.value_kernel)\n",
    "\n",
    "        # Scale dot-product, doing the division to either query or key\n",
    "        # instead of their product saves some computation\n",
    "        depth = tf.constant(self.head_size, dtype=query.dtype)\n",
    "        query /= tf.sqrt(depth)\n",
    "\n",
    "        # Calculate dot product attention\n",
    "        logits = tf.einsum(\"...NHO,...MHO->...HNM\", query, key)\n",
    "\n",
    "        # apply mask\n",
    "        if mask is not None:\n",
    "            mask = tf.cast(mask, tf.float32)\n",
    "\n",
    "            # possibly expand on the head dimension so broadcasting works\n",
    "            if len(mask.shape) != len(logits.shape):\n",
    "                mask = tf.expand_dims(mask, -3)\n",
    "\n",
    "            logits += -10e9 * (1.0 - mask)\n",
    "\n",
    "        attn_coef = tf.nn.softmax(logits)\n",
    "\n",
    "        # attention dropout\n",
    "        attn_coef_dropout = self.dropout(attn_coef, training=training)\n",
    "\n",
    "        # attention * value\n",
    "        multihead_output = tf.einsum(\"...HNM,...MHI->...NHI\", attn_coef_dropout, value)\n",
    "\n",
    "        # Run the outputs through another linear projection layer. Recombining heads\n",
    "        # is automatically done.\n",
    "        output = tf.einsum(\n",
    "            \"...NHI,HIO->...NO\", multihead_output, self.projection_kernel\n",
    "        )\n",
    "\n",
    "        if self.projection_bias is not None:\n",
    "            output += self.projection_bias\n",
    "\n",
    "        if self.return_attn_coef:\n",
    "            return output, attn_coef\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        num_value_features = (\n",
    "            input_shape[2][-1] if len(input_shape) > 2 else input_shape[1][-1]\n",
    "        )\n",
    "        output_size = (\n",
    "            self.output_size if self.output_size is not None else num_value_features\n",
    "        )\n",
    "\n",
    "        output_shape = input_shape[0][:-1] + (output_size,)\n",
    "\n",
    "        if self.return_attn_coef:\n",
    "            num_query_elements = input_shape[0][-2]\n",
    "            num_key_elements = input_shape[1][-2]\n",
    "            attn_coef_shape = input_shape[0][:-2] + (\n",
    "                self.num_heads,\n",
    "                num_query_elements,\n",
    "                num_key_elements,\n",
    "            )\n",
    "\n",
    "            return output_shape, attn_coef_shape\n",
    "        else:\n",
    "            return output_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "\n",
    "        config.update(\n",
    "            head_size=self.head_size,\n",
    "            num_heads=self.num_heads,\n",
    "            output_size=self.output_size,\n",
    "            dropout=self._dropout_rate,\n",
    "            use_projection_bias=self.use_projection_bias,\n",
    "            return_attn_coef=self.return_attn_coef,\n",
    "            kernel_initializer=tf.keras.initializers.serialize(self.kernel_initializer),\n",
    "            kernel_regularizer=tf.keras.regularizers.serialize(self.kernel_regularizer),\n",
    "            kernel_constraint=tf.keras.constraints.serialize(self.kernel_constraint),\n",
    "            bias_initializer=tf.keras.initializers.serialize(self.bias_initializer),\n",
    "            bias_regularizer=tf.keras.regularizers.serialize(self.bias_regularizer),\n",
    "            bias_constraint=tf.keras.constraints.serialize(self.bias_constraint),\n",
    "        )\n",
    "\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the autoregressive version of the transformer-decoder does not use the Seq2Seq intermediate layer\n",
    "# as there is no transformer-encoder component sending hidden states, therefore\n",
    "# having only a self-attention layer and a position-wise feed-forward layer,\n",
    "# the autoregressive transformer-decoder is, in fact, a transformer-encoder\n",
    "\n",
    "# the only important modification is the masked self-attention layer\n",
    "\n",
    "# masked self-attention layer seems to be already implemented in\n",
    "# MHA module from TensorFlow AddOns, then will be added to the EncoderLayer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base transformer encoder layer from # https://keras.io/examples/nlp/text_classification_with_transformer/\n",
    "# modified to include masked self attention\n",
    "\n",
    "# ToDo: get the number of timesteps from the input shape\n",
    "# in the meantime, pass this value as an argument for the encoder layer\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, n_timesteps, embed_dim, num_heads, ff_dim, dropout=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        # multi-head attention initialization\n",
    "        self.attention_layer = MultiHeadAttention(head_size=embed_dim, num_heads=num_heads)\n",
    "        self.ff_layer = tf.keras.Sequential(\n",
    "            [tf.keras.layers.Dense(ff_dim, activation=\"relu\"),\n",
    "             tf.keras.layers.Dense(embed_dim)]\n",
    "        )\n",
    "        self.add_norm_layer_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.add_norm_layer_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout_1 = tf.keras.layers.Dropout(dropout)\n",
    "        self.dropout_2 = tf.keras.layers.Dropout(dropout)\n",
    "        # mask for self-attention\n",
    "        self.mask = tf.convert_to_tensor(np.tril(np.ones([n_timesteps, n_timesteps]), 0), dtype=tf.float32)\n",
    "\n",
    "        \n",
    "    def call(self, inputs, training):\n",
    "        # mask for self-attention is passed to MHA on call\n",
    "        attention_output = self.attention_layer([inputs, inputs], mask=self.mask)\n",
    "        attention_output = self.dropout_1(attention_output, training=training)\n",
    "        input_to_ffn = self.add_norm_layer_1(inputs + attention_output)\n",
    "        ffn_output = self.ff_layer(input_to_ffn)\n",
    "        ffn_output = self.dropout_2(ffn_output, training=training)\n",
    "        return self.add_norm_layer_2(input_to_ffn + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.read_pickle(\"/home/developer/gcp/cbidmltsf/timeseries/CPE04115_H_kw_20201021084001/ts.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kw_scaled</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01 00:00:00</th>\n",
       "      <td>0.274317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 01:00:00</th>\n",
       "      <td>0.217363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 02:00:00</th>\n",
       "      <td>0.168545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 03:00:00</th>\n",
       "      <td>0.122996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 04:00:00</th>\n",
       "      <td>0.080440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     kw_scaled\n",
       "timestamp                     \n",
       "2016-01-01 00:00:00   0.274317\n",
       "2016-01-01 01:00:00   0.217363\n",
       "2016-01-01 02:00:00   0.168545\n",
       "2016-01-01 03:00:00   0.122996\n",
       "2016-01-01 04:00:00   0.080440"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22629"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# length of time series\n",
    "total_lectures = ts['kw_scaled'].count()\n",
    "total_lectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a training dataset\n",
    "# features: m consecutive lectures with their timestamps\n",
    "# target: m consecutive lectures (lectures in features, shifted by 1 to the future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the embedding dimension, the lenght of tranining, evaluation, and test datasets\n",
    "# use the most of the 22K+ lectures in the original time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length of input sequence, hours in a week\n",
    "m = 168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare sine-cosine positional encoding for the input sequence\n",
    "hours_in_day = 24\n",
    "days_in_month = 30\n",
    "months_in_year = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15840.3,  4525.8,  2262.9])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_lectures*np.array([0.7, 0.2, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the previous dataset split, use the following indexes for building datasets\n",
    "\n",
    "# 15000 rows in training dataset\n",
    "train_start = 0\n",
    "train_end = 15000\n",
    "\n",
    "# 4000 rows in evaluation dataset\n",
    "eval_start = 16000\n",
    "eval_end = 20000\n",
    "\n",
    "# 1000 rows in test dataset\n",
    "test_start = 21000\n",
    "test_end = 22000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a collection of examples for training\n",
    "# use a range on the time series index\n",
    "\n",
    "train_range = np.arange(train_start, train_end)\n",
    "\n",
    "features_list = list()\n",
    "targets_list = list()\n",
    "\n",
    "for start in train_range:\n",
    "    end = start + m\n",
    "    values = np.expand_dims(ts[start:end]['kw_scaled'].values, axis=1)\n",
    "    target_values = np.expand_dims(ts[1+start:1+end]['kw_scaled'].values, axis=1)\n",
    "    \n",
    "    timestamps_hour = ts[start:end].index.hour\n",
    "    timestamps_day = ts[start:end].index.day\n",
    "    timestamps_month = ts[start:end].index.month\n",
    "    \n",
    "    sin_hour = np.expand_dims(np.sin(2*np.pi*timestamps_hour/hours_in_day), axis=1)\n",
    "    cos_hour = np.expand_dims(np.sin(2*np.pi*timestamps_hour/hours_in_day), axis=1)\n",
    "    sin_day = np.expand_dims(np.sin(2*np.pi*timestamps_day/days_in_month), axis=1)\n",
    "    cos_day = np.expand_dims(np.cos(2*np.pi*timestamps_day/days_in_month), axis=1)\n",
    "    sin_month = np.expand_dims(np.sin(2*np.pi*timestamps_month/months_in_year), axis=1)\n",
    "    cos_month = np.expand_dims(np.cos(2*np.pi*timestamps_month/months_in_year), axis=1)\n",
    "    \n",
    "    feature_row = np.concatenate((values, sin_hour, cos_hour, sin_day, cos_day, sin_month, cos_month), axis=1)    \n",
    "\n",
    "    features_list.append(feature_row)\n",
    "    targets_list.append(target_values)\n",
    "\n",
    "x_train = np.array(features_list)\n",
    "y_train = np.array(targets_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the training NumPy arrays\n",
    "with open('data/x_train.npy', 'wb') as filename:\n",
    "    np.save(filename, x_train)\n",
    "\n",
    "with open('data/y_train.npy', 'wb') as filename:\n",
    "    np.save(filename, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training NumPy arrays\n",
    "with open('data/x_train.npy', 'rb') as filename:\n",
    "    x_train = np.load(filename)\n",
    "\n",
    "with open('data/y_train.npy', 'rb') as filename:\n",
    "    y_train = np.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15000, 168, 7), (15000, 168, 1))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a collection of examples for evaluation\n",
    "# use a range on the time series index\n",
    "eval_range = np.arange(eval_start, eval_end)\n",
    "\n",
    "features_list = list()\n",
    "targets_list = list()\n",
    "\n",
    "for start in eval_range:\n",
    "    end = start + m\n",
    "    values = np.expand_dims(ts[start:end]['kw_scaled'].values, axis=1)\n",
    "    target_values = np.expand_dims(ts[1+start:1+end]['kw_scaled'].values, axis=1)\n",
    "    \n",
    "    timestamps_hour = ts[start:end].index.hour\n",
    "    timestamps_day = ts[start:end].index.day\n",
    "    timestamps_month = ts[start:end].index.month\n",
    "    \n",
    "    sin_hour = np.expand_dims(np.sin(2*np.pi*timestamps_hour/hours_in_day), axis=1)\n",
    "    cos_hour = np.expand_dims(np.sin(2*np.pi*timestamps_hour/hours_in_day), axis=1)\n",
    "    sin_day = np.expand_dims(np.sin(2*np.pi*timestamps_day/days_in_month), axis=1)\n",
    "    cos_day = np.expand_dims(np.cos(2*np.pi*timestamps_day/days_in_month), axis=1)\n",
    "    sin_month = np.expand_dims(np.sin(2*np.pi*timestamps_month/months_in_year), axis=1)\n",
    "    cos_month = np.expand_dims(np.cos(2*np.pi*timestamps_month/months_in_year), axis=1)\n",
    "    \n",
    "    feature_row = np.concatenate((values, sin_hour, cos_hour, sin_day, cos_day, sin_month, cos_month), axis=1)    \n",
    "\n",
    "    features_list.append(feature_row)\n",
    "    targets_list.append(target_values)\n",
    "\n",
    "x_eval = np.array(features_list)\n",
    "y_eval = np.array(targets_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the evaluation NumPy arrays\n",
    "with open('data/x_eval.npy', 'wb') as filename:\n",
    "    np.save(filename, x_eval)\n",
    "\n",
    "with open('data/y_eval.npy', 'wb') as filename:\n",
    "    np.save(filename, y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the evaluation NumPy arrays\n",
    "with open('data/x_eval.npy', 'rb') as filename:\n",
    "    x_eval = np.load(filename)\n",
    "\n",
    "with open('data/y_eval.npy', 'rb') as filename:\n",
    "    y_eval = np.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4000, 168, 7), (4000, 168, 1))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_eval.shape, y_eval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a collection of examples for test\n",
    "# use a range on the time series index\n",
    "test_range = np.arange(test_start, test_end)\n",
    "\n",
    "features_list = list()\n",
    "targets_list = list()\n",
    "\n",
    "for start in test_range:\n",
    "    end = start + m\n",
    "    values = np.expand_dims(ts[start:end]['kw_scaled'].values, axis=1)\n",
    "    target_values = np.expand_dims(ts[1+start:1+end]['kw_scaled'].values, axis=1)\n",
    "    \n",
    "    timestamps_hour = ts[start:end].index.hour\n",
    "    timestamps_day = ts[start:end].index.day\n",
    "    timestamps_month = ts[start:end].index.month\n",
    "    \n",
    "    sin_hour = np.expand_dims(np.sin(2*np.pi*timestamps_hour/hours_in_day), axis=1)\n",
    "    cos_hour = np.expand_dims(np.sin(2*np.pi*timestamps_hour/hours_in_day), axis=1)\n",
    "    sin_day = np.expand_dims(np.sin(2*np.pi*timestamps_day/days_in_month), axis=1)\n",
    "    cos_day = np.expand_dims(np.cos(2*np.pi*timestamps_day/days_in_month), axis=1)\n",
    "    sin_month = np.expand_dims(np.sin(2*np.pi*timestamps_month/months_in_year), axis=1)\n",
    "    cos_month = np.expand_dims(np.cos(2*np.pi*timestamps_month/months_in_year), axis=1)\n",
    "    \n",
    "    feature_row = np.concatenate((values, sin_hour, cos_hour, sin_day, cos_day, sin_month, cos_month), axis=1)    \n",
    "\n",
    "    features_list.append(feature_row)\n",
    "    targets_list.append(target_values)\n",
    "\n",
    "x_test = np.array(features_list)\n",
    "y_test = np.array(targets_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the test NumPy arrays\n",
    "with open('data/x_test.npy', 'wb') as filename:\n",
    "    np.save(filename, x_test)\n",
    "    \n",
    "with open('data/y_test.npy', 'wb') as filename:\n",
    "    np.save(filename, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the test NumPy arrays\n",
    "with open('data/x_test.npy', 'rb') as filename:\n",
    "    x_test = np.load(filename)\n",
    "\n",
    "with open('data/y_test.npy', 'rb') as filename:\n",
    "    y_test = np.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 168, 7), (1000, 168, 1))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# architecture details according to the Klingenbrunn experiment\n",
    "# (including notes to further modifications on the basic autoregressive model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of timesteps is the length of the input sequence,\n",
    "# is the embedding dimension from SLDB\n",
    "num_timesteps = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of features is the active load value (main feature)\n",
    "# plus the six components of the sine-cosine positional encoding on hour, day, month\n",
    "\n",
    "# important: there is no value embedding, therefore d_model is very low\n",
    "d_model = 7\n",
    "\n",
    "# ToDo: use value embedding to a high-dimensional space and compare results\n",
    "# ToDo: use a different positional encoding system and compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as long as there is no value embedding, neither convolutional nor dense layers are required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 168, 7) dtype=float32 (created by layer 'input_1')>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input layer for Keras functional\n",
    "input_layer = tf.keras.layers.Input(shape=(num_timesteps, d_model))\n",
    "input_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 168, 7) dtype=float32 (created by layer 'input_1')>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_to_transformer_block = input_layer\n",
    "input_to_transformer_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 2\n",
    "ff_dim = 1024\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/developer/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:74: DeprecationWarning: `MultiHeadAttention` will be deprecated in Addons 0.13. Please use `tf.keras.layers.MultiHeadAttention` instead.\n"
     ]
    }
   ],
   "source": [
    "encoder_layer_1 = EncoderLayer(n_timesteps=num_timesteps,\n",
    "                               embed_dim=d_model,\n",
    "                               num_heads=num_heads,\n",
    "                               ff_dim=ff_dim,\n",
    "                               dropout=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/developer/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:74: DeprecationWarning: `MultiHeadAttention` will be deprecated in Addons 0.13. Please use `tf.keras.layers.MultiHeadAttention` instead.\n"
     ]
    }
   ],
   "source": [
    "encoder_layer_2 = EncoderLayer(n_timesteps=num_timesteps,\n",
    "                               embed_dim=d_model,\n",
    "                               num_heads=num_heads,\n",
    "                               ff_dim=ff_dim,\n",
    "                               dropout=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 168, 7) dtype=float32 (created by layer 'encoder_layer')>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_from_encoder_1 = encoder_layer_1(input_to_transformer_block)\n",
    "output_from_encoder_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 168, 7) dtype=float32 (created by layer 'encoder_layer_1')>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_from_encoder_2 = encoder_layer_2(output_from_encoder_1)\n",
    "output_from_encoder_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klingenbrunn uses a linear layer to decode the output_from_encoder\n",
    "# from (?, num_timesteps, num_features) to (?, num_timesteps, 1)\n",
    "\n",
    "# the equivalent operation in TensorFlow is a TimeDistributed Dense layer to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "units_in_first_dense = 1\n",
    "first_dense = tf.keras.layers.Dense(units_in_first_dense, activation=\"sigmoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 168, 1) dtype=float32 (created by layer 'time_distributed')>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distributed_first_dense = tf.keras.layers.TimeDistributed(first_dense)(output_from_encoder_2)\n",
    "distributed_first_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=input_layer, outputs=distributed_first_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\"adam\", \"mse\", metrics=[tf.keras.metrics.RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 65s 134ms/step - loss: 0.0213 - root_mean_squared_error: 0.1425 - val_loss: 0.0028 - val_root_mean_squared_error: 0.0528\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 62s 133ms/step - loss: 0.0055 - root_mean_squared_error: 0.0742 - val_loss: 0.0024 - val_root_mean_squared_error: 0.0487\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 62s 132ms/step - loss: 0.0040 - root_mean_squared_error: 0.0636 - val_loss: 0.0024 - val_root_mean_squared_error: 0.0495\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 62s 133ms/step - loss: 0.0035 - root_mean_squared_error: 0.0591 - val_loss: 0.0022 - val_root_mean_squared_error: 0.0470\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 62s 133ms/step - loss: 0.0032 - root_mean_squared_error: 0.0564 - val_loss: 0.0023 - val_root_mean_squared_error: 0.0478\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 62s 133ms/step - loss: 0.0029 - root_mean_squared_error: 0.0540 - val_loss: 0.0023 - val_root_mean_squared_error: 0.0481\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 68s 145ms/step - loss: 0.0027 - root_mean_squared_error: 0.0522 - val_loss: 0.0024 - val_root_mean_squared_error: 0.0493\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 72s 153ms/step - loss: 0.0026 - root_mean_squared_error: 0.0510 - val_loss: 0.0023 - val_root_mean_squared_error: 0.0475\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 77s 164ms/step - loss: 0.0024 - root_mean_squared_error: 0.0495 - val_loss: 0.0024 - val_root_mean_squared_error: 0.0493\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 76s 161ms/step - loss: 0.0024 - root_mean_squared_error: 0.0486 - val_loss: 0.0022 - val_root_mean_squared_error: 0.0469\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train, batch_size=32, epochs=10, validation_data=(x_eval, y_eval)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference process on unseen data, that means on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a forecast window to guide the iterative prediction process\n",
    "# start with a hourly, day-ahead process\n",
    "forecast_window = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use naming conventions from Klingenbrunn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 168, 7])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the true active load values, plus the six positional encodings\n",
    "# in the first row of the test dataset features (original ts indexes are 21000-21167)\n",
    "src = tf.expand_dims(x_test[0, :, :], axis=0)\n",
    "src.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the true active load values, plus the six positional encodings\n",
    "# in the forecast-window-sized timesteps following the source (original ts indexes are 21168-21191)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 24, 7])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = tf.expand_dims(x_test[168, :forecast_window, :], axis=0)\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify that active load values in the source and the target are contiguous in the time series\n",
    "# that means, target is composed with the first timesteps of features\n",
    "# in the rows 168-191 of test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26612255, 0.23641237, 0.24432548, 0.32326286, 0.36856605,\n",
       "       0.45449848, 0.56519907, 0.68640037, 0.74005594, 0.84452149,\n",
       "       0.86219931, 0.86331182, 0.87358708, 0.94115296, 0.89783385,\n",
       "       0.90333212, 0.8544241 , 0.89447384, 0.90186633, 0.83024086,\n",
       "       0.67798756, 0.54712923, 0.42006322, 0.33738621])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[168:192, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(24,), dtype=float64, numpy=\n",
       "array([0.26612255, 0.23641237, 0.24432548, 0.32326286, 0.36856605,\n",
       "       0.45449848, 0.56519907, 0.68640037, 0.74005594, 0.84452149,\n",
       "       0.86219931, 0.86331182, 0.87358708, 0.94115296, 0.89783385,\n",
       "       0.90333212, 0.8544241 , 0.89447384, 0.90186633, 0.83024086,\n",
       "       0.67798756, 0.54712923, 0.42006322, 0.33738621])>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[0, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# therefore, source and target tensors are ready for inference process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_input_model = src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not use the all_predictions array from Klingenbrunn, just the predictions on the forecast window\n",
    "predictions_list = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once tested, put the following lines on an iterative cycle\n",
    "# for i in range(forecast_window -1): ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first pass\n",
    "i = 0\n",
    "\n",
    "# src is the feature set of the first row in the test dataset (1, 168, 7)\n",
    "# target is the set of n=forecast_window features at the end of the test dataset\n",
    "# that means the 24 values to predict, along with their positional encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(\n",
    "    next_input_model, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10,\n",
    "    workers=1, use_multiprocessing=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 168, 1)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of prediction is prediction_batch_size, n_timesteps, value_feature_only (no positional encodings) \n",
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the value of the most recent prediction (last timestep) into the predictions list\n",
    "predictions_list.append(prediction[:, -1, :][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 167, 6])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from source tensor, get the positional encodings for ti+1 to t167 (that is 168-i-1 values)\n",
    "pos_encoding_old_values = src[:, i+1:, 1:]\n",
    "pos_encoding_old_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 1, 6])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from target tensor, get the positional encodings for t168 to t168+i (that is i+1 values)\n",
    "pos_encoding_new_val = target[:, :i+1, 1:]\n",
    "pos_encoding_new_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 168, 6])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build new positional encodings with 168 values\n",
    "pos_encodings = tf.concat([pos_encoding_old_values, pos_encoding_new_val], axis=1)\n",
    "pos_encodings = tf.cast(pos_encodings, dtype=tf.float32)\n",
    "pos_encodings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 167, 1])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the values feature for the next input to the model\n",
    "# pop i+1 values at the beginning of the previous input\n",
    "value_feature_old_values = tf.expand_dims(src[:, i+1:, 0], axis=-1)\n",
    "value_feature_old_values = tf.cast(value_feature_old_values, dtype=tf.float32)\n",
    "value_feature_old_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33857653], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# current predictions_list to NumPy array\n",
    "value_feature_new_values = np.array(predictions_list[:i+1])\n",
    "value_feature_new_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.33857653], dtype=float32)>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# current prediction array to tensor\n",
    "value_feature_new_values = tf.convert_to_tensor(value_feature_new_values)\n",
    "value_feature_new_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.33857653]], dtype=float32)>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expand dimensions of current prediction tensor to single-value feature\n",
    "value_feature_new_values = tf.expand_dims(value_feature_new_values, axis=-1)\n",
    "value_feature_new_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 1), dtype=float32, numpy=array([[[0.33857653]]], dtype=float32)>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expand dimensions of current prediction tensor to single-value batch\n",
    "value_feature_new_values = tf.expand_dims(value_feature_new_values, axis=0)\n",
    "value_feature_new_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 168, 1])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_input_model = tf.concat([value_feature_old_values, value_feature_new_values], axis=1)\n",
    "next_input_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 168, 7])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_input_model = tf.concat([next_input_model, pos_encodings], axis=2)\n",
    "next_input_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second pass\n",
    "i = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(\n",
    "    next_input_model, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10,\n",
    "    workers=1, use_multiprocessing=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 168, 1)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of prediction is prediction_batch_size, n_timesteps, value_feature_only (no positional encodings) \n",
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the value of the most recent prediction (last timestep) into the predictions list\n",
    "predictions_list.append(prediction[:, -1, :][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.33857653, 0.4081602]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 166, 6])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from source tensor, get the positional encodings for ti+1 to t167 (that is 168-i-1 values)\n",
    "pos_encoding_old_values = src[:, i+1:, 1:]\n",
    "pos_encoding_old_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 2, 6])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from target tensor, get the positional encodings for t168 to t168+i (that is i+1 values)\n",
    "pos_encoding_new_val = target[:, :i+1, 1:]\n",
    "pos_encoding_new_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 168, 6])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build new positional encodings with 168 values\n",
    "pos_encodings = tf.concat([pos_encoding_old_values, pos_encoding_new_val], axis=1)\n",
    "pos_encodings = tf.cast(pos_encodings, dtype=tf.float32)\n",
    "pos_encodings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 166, 1])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the values feature for the next input to the model\n",
    "# pop i+1 values at the beginning of the previous input\n",
    "value_feature_old_values = tf.expand_dims(src[:, i+1:, 0], axis=-1)\n",
    "value_feature_old_values = tf.cast(value_feature_old_values, dtype=tf.float32)\n",
    "value_feature_old_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33857653, 0.4081602 ], dtype=float32)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# current predictions_list to NumPy array\n",
    "value_feature_new_values = np.array(predictions_list[:i+1])\n",
    "value_feature_new_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.33857653, 0.4081602 ], dtype=float32)>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_feature_new_values = tf.convert_to_tensor(value_feature_new_values)\n",
    "value_feature_new_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[0.33857653],\n",
       "       [0.4081602 ]], dtype=float32)>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expand dimensions of current prediction tensor to single-value feature\n",
    "value_feature_new_values = tf.expand_dims(value_feature_new_values, axis=-1)\n",
    "value_feature_new_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 1), dtype=float32, numpy=\n",
       "array([[[0.33857653],\n",
       "        [0.4081602 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expand dimensions of current prediction tensor to single-value batch\n",
    "value_feature_new_values = tf.expand_dims(value_feature_new_values, axis=0)\n",
    "value_feature_new_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 168, 1])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_input_model = tf.concat([value_feature_old_values, value_feature_new_values], axis=1)\n",
    "next_input_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 168, 7])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_input_model = tf.concat([next_input_model, pos_encodings], axis=2)\n",
    "next_input_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the iterative cycle has been successfully tested, build the final code in a new notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
