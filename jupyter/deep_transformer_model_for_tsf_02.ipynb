{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer implementation in Keras and TensorFlow 1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base code for transformer block implements multi-head attention from Keras, only on TF 2X\n",
    "# question: is it possible to change it to use multi-head attention from TF AddOns, on TF 1.15?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT!\n",
    "# there is no support for TensorFlow addons on TF 1.15\n",
    "# code must be used from Python source\n",
    "# then, complete the Transformer model using Keras MHA layer, on TF 2.4\n",
    "\n",
    "# or just try using tf.compat.v1.keras.layers.MultiHeadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second experiment:\n",
    "# TensorFlow 2.4\n",
    "# ScaledDotProduct and InterpretableMultiHeadAttention from Temporal Fusion Transformer project\n",
    "# Transformer-encoder only (autoencoder option)\n",
    "# value embedding with Conv1D\n",
    "# basic positional encoding with Keras embedding\n",
    "# encoder layer with MHA\n",
    "# encoder output to linear to multi-step target (TimeDistributed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get datasets for selected substation, load them as NumPy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('data/256_to_24_train_hourly.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.load('data/256_to_24_train_targets.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17824, 256), (17824, 24))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_eval = np.load('data/256_to_24_eval_hourly.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_eval = np.load('data/256_to_24_eval_targets.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1984, 256), (1984, 24))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_eval.shape, y_eval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use number of timesteps in the input sequence as the limit for positional encoding\n",
    "num_timesteps = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'input_1')>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input layer for Keras functional\n",
    "# use embedding dimension from SLDB as the input dimensionality\n",
    "input_layer = layers.Input(shape=(num_timesteps,))\n",
    "input_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 256, 1) dtype=float32 (created by layer 'tf.expand_dims')>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a layer to expand dimensions of input tensor,\n",
    "# required to project to a d_model space with a convolutional layer\n",
    "expanded_input_layer = tf.expand_dims(input_layer, axis=2)\n",
    "expanded_input_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 256, 32) dtype=float32 (created by layer 'conv1d')>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a simple Conv1D layer to project time series data (scalar) to d_model\n",
    "value_embedding_layer = layers.Conv1D(filters=32,\n",
    "                                      kernel_size=3,\n",
    "                                      activation=\"relu\",\n",
    "                                      padding=\"same\")(expanded_input_layer)\n",
    "value_embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with a simple position encoding\n",
    "# for instance, the one in Keras Transformer-encoder block for text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256,), dtype=int32, numpy=\n",
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "       247, 248, 249, 250, 251, 252, 253, 254, 255], dtype=int32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions_to_encode = tf.range(start=0, limit=num_timesteps, delta=1)\n",
    "positions_to_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensionality of Q, K, V\n",
    "embed_dim = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 32), dtype=float32, numpy=\n",
       "array([[-0.00638062,  0.03770306,  0.02036254, ...,  0.04426051,\n",
       "        -0.02193693,  0.00117866],\n",
       "       [ 0.00312021, -0.01591484,  0.02912844, ..., -0.0019648 ,\n",
       "        -0.02728313,  0.01884855],\n",
       "       [ 0.03301282, -0.01530141,  0.0404519 , ...,  0.01020054,\n",
       "         0.02359128, -0.01728591],\n",
       "       ...,\n",
       "       [-0.00277444, -0.00080197,  0.04465133, ..., -0.02851502,\n",
       "         0.03069988,  0.00379462],\n",
       "       [ 0.02876401, -0.03478192, -0.0308387 , ..., -0.03859157,\n",
       "        -0.0405895 ,  0.00187563],\n",
       "       [-0.01709599, -0.02897664,  0.02532138, ...,  0.03900309,\n",
       "        -0.03712968, -0.00220356]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_embedding_layer = layers.Embedding(input_dim=num_timesteps,\n",
    "                                            output_dim=embed_dim) (positions_to_encode)\n",
    "position_embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 256, 32) dtype=float32 (created by layer 'tf.__operators__.add')>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_to_transformer_block = value_embedding_layer + position_embedding_layer\n",
    "input_to_transformer_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of attention heads\n",
    "num_heads = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden layer size in feed forward network inside transformer\n",
    "ff_dim = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropout rate inside the transformer block\n",
    "rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment the following cell, use InterpretableMultiHeadAttention from TFT project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer_block = TransformerBlock(embed_dim=embed_dim,\n",
    "#                                      num_heads=num_heads,\n",
    "#                                      ff_dim=ff_dim,\n",
    "#                                      rate=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_from_transformer_block = transformer_block(input_to_transformer_block)\n",
    "# output_from_transformer_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_attention_layer = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 256, 32) dtype=float32 (created by layer 'multi_head_attention_1')>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_output_layer = transformer_attention_layer(input_to_transformer_block,\n",
    "                                                     input_to_transformer_block)\n",
    "attention_output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_dropout_1 = layers.Dropout(rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 256, 32) dtype=float32 (created by layer 'dropout')>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_dropout_1_layer = transformer_dropout_1(attention_output_layer)\n",
    "attention_dropout_1_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_layernorm_1 = layers.LayerNormalization(epsilon=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 256, 32) dtype=float32 (created by layer 'layer_normalization_1')>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layernorm_1_output_layer = transformer_layernorm_1(input_to_transformer_block + attention_output_layer)\n",
    "layernorm_1_output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_ffn_layer = keras.Sequential(\n",
    "    [layers.Dense(units=ff_dim,\n",
    "                  activation=\"relu\"),\n",
    "     layers.Dense(units=embed_dim)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 256, 32) dtype=float32 (created by layer 'sequential')>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffn_output_layer = transformer_ffn_layer(layernorm_1_output_layer)\n",
    "ffn_output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_dropout_2 = layers.Dropout(rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 256, 32) dtype=float32 (created by layer 'dropout_2')>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout_2_layer_output = transformer_dropout_2(ffn_output_layer)\n",
    "dropout_2_layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_layernorm_2 = layers.LayerNormalization(epsilon=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 256, 32) dtype=float32 (created by layer 'layer_normalization_3')>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_from_transformer_block = transformer_layernorm_2(\n",
    "    layernorm_1_output_layer + dropout_2_layer_output)\n",
    "output_from_transformer_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing the output from transformer block towards the target\n",
    "# case 1: based on TransformerBlock example at\n",
    "# https://keras.io/examples/nlp/text_classification_with_transformer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 32) dtype=float32 (created by layer 'global_average_pooling1d')>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_from_pooling = layers.GlobalAveragePooling1D()(output_from_transformer_block)\n",
    "output_from_pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_targets = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 24, 32) dtype=float32 (created by layer 'repeat_vector')>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeated = layers.RepeatVector(num_targets)(output_from_pooling)\n",
    "repeated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_dropout = layers.Dropout(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 24, 32) dtype=float32 (created by layer 'time_distributed')>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distributed_first_dropout = layers.TimeDistributed(first_dropout)(repeated)\n",
    "distributed_first_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "units_in_first_dense = 16\n",
    "first_dense = layers.Dense(units_in_first_dense, activation=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 24, 16) dtype=float32 (created by layer 'time_distributed_1')>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distributed_first_dense = layers.TimeDistributed(first_dense)(distributed_first_dropout)\n",
    "distributed_first_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_dropout = layers.Dropout(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 24, 16) dtype=float32 (created by layer 'time_distributed_2')>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distributed_second_dropout = layers.TimeDistributed(second_dropout)(distributed_first_dense)\n",
    "distributed_second_dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "units_in_second_dense = 1\n",
    "second_dense = layers.Dense(units_in_second_dense, activation=\"sigmoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 24, 1) dtype=float32 (created by layer 'time_distributed_3')>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distributed_second_dense = layers.TimeDistributed(second_dense)(distributed_second_dropout)\n",
    "distributed_second_dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=input_layer, outputs=distributed_second_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\"adam\", \"mse\", metrics=[tf.keras.metrics.RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "557/557 [==============================] - 59s 104ms/step - loss: 0.0438 - root_mean_squared_error: 0.2091 - val_loss: 0.0432 - val_root_mean_squared_error: 0.2077\n",
      "Epoch 2/2\n",
      "557/557 [==============================] - 61s 109ms/step - loss: 0.0410 - root_mean_squared_error: 0.2025 - val_loss: 0.0437 - val_root_mean_squared_error: 0.2090\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train, batch_size=32, epochs=2, validation_data=(x_eval, y_eval)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
